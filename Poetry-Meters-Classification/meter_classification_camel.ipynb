{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12e46f-23c8-4181-9e24-a0276dc12dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy==1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da4c2c-e801-4fa6-8676-c04e551ee88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.12\n",
    "!pip install pyarabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b7f2d-e4a6-4dc1-9a9f-eb0d99dc95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd9b83-c345-489a-ba9d-c27dc601972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c51d229-d74c-4ce9-9910-786a65f81dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd46459-397c-4680-aa71-61f421963385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 13:13:36.115766: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 13:13:36.553201: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 13:13:37.092876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# cell-1  \n",
    "#load and clean the data (removing diacritics and unwanted text)\n",
    "\n",
    "df = pd.read_csv('AraPoems_Dataset.csv')\n",
    "df.fillna('', inplace=True)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "def remove_diacritics(a):    \n",
    "    return araby.strip_diacritics(a)\n",
    "\n",
    "df['first_hemistich'] = df['first_hemistich'].apply(remove_diacritics)\n",
    "df['second_hemistich'] = df['second_hemistich'].apply(remove_diacritics)\n",
    "\n",
    "def normalizeBeforeTraining(df):\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('النابغـة: ', '')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('الـربيع: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('عبيــد: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('امـرؤ القيسـ: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('امرؤ القيس: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(جلال الــــدين الــــرومي):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(لـوك الفيلسـوف الإنكليزي):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(كانت الفيلسوف الألماني ):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(بركســــــــــــــــون):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الحـــــــــــــــور):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الشــــــــــــــاعر):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الإنســـــــــــــــان):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('العلم):', '', regex=False)\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(العشــــــــــــــــق):', '', regex=False)\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الزهــــــــــــــــــرة):', '', regex=False)\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('التوأم اليشكري: ', '', regex=False)  \n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('آ', 'أ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('آ', 'أ')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('[/\":?،؟]', '')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('[/\":?،؟]', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('  ', ' ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('  ', ' ')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('  ', ' ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('  ', ' ')\n",
    "\n",
    "\n",
    "normalizeBeforeTraining(df)\n",
    "df.drop(df[(df['first_hemistich'] == '') & (df['second_hemistich'] == '')].index, inplace=True)\n",
    "\n",
    "#if first_hemistich == '', then copy the text from second_hemistich. then delete the text in the second_hemistich\n",
    "df['first_hemistich'] = df.apply(lambda x: x['second_hemistich'] if x['first_hemistich'] == '' else x['first_hemistich'], axis=1)\n",
    "df['second_hemistich'] = df.apply(lambda x: '' if x['first_hemistich'] == x['second_hemistich'] else x['second_hemistich'], axis=1)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(len(df))\n",
    "# display(df[:10])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e68754b-15f2-4e08-b38a-ea0ccd974d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1911853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1529482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "382371"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-2 \n",
    "# preparing data for finetuning\n",
    "\n",
    "\n",
    "df['second_hemistich'].replace('', 'E', inplace=True)\n",
    "dfc = df[['first_hemistich', 'second_hemistich', 'meter', 'link']].copy()\n",
    "dfc['text'] = dfc['first_hemistich'] + ' S ' + dfc['second_hemistich']\n",
    "\n",
    "#removing verses without a meter\n",
    "dfc = dfc[dfc['meter'] != ''] \n",
    "dfc = dfc[dfc['meter'] != 'unspecified']\n",
    "dfc = dfc[dfc['meter'] != 'mixed']\n",
    "\n",
    "\n",
    "\n",
    "classic = ['taweel', 'kamel', 'baseet', 'khafif', 'wafer', 'rajaz', 'ramel', 'mutaqarib',\n",
    "           'saree', 'munsarih', 'mujtath', 'hazaj', 'madeed', 'mutadarak', 'muqtadab', 'mudari'] \n",
    "\n",
    "#including only verses with classical meters\n",
    "# dfc = dfc[dfc['meter'].isin(classic)]\n",
    "\n",
    "dfc.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfc['meter'] = dfc['meter'].astype('category')\n",
    "# display(dfc['meter'].unique())\n",
    "\n",
    "dfc['label'] = dfc['meter'].cat.codes #assign cat_value for each meter type\n",
    "dftrain, dftest = train_test_split(dfc, test_size=0.20, random_state=42, stratify=dfc['label'])\n",
    "ytrain = to_categorical(dftrain['label']).astype('int32')\n",
    "ytest = to_categorical(dftest['label']).astype('int32')\n",
    "\n",
    "max_sequence_length = 32\n",
    "train_batch_size = 256\n",
    "classes_num = len(dfc['meter'].unique())\n",
    "\n",
    "display(len(dfc))\n",
    "display(len(dftrain))\n",
    "display(len(dftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdae2e7c-370e-407c-a87a-2e61f782f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 13:14:19.173831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:19.239698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:19.239813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:19.241465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:19.241566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:19.241649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:20.216627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:20.216753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:20.216839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 13:14:20.216911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21654 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-09-14 13:14:21.123320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#cell-3\n",
    "#loading the tokenizer and the model\n",
    "\n",
    "from transformers import AutoTokenizer,TFBertModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('CAMeL-Lab/bert-base-arabic-camelbert-ca')\n",
    "bert = TFBertModel.from_pretrained('CAMeL-Lab/bert-base-arabic-camelbert-ca', from_pt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd261fd0-0b55-46b6-8f5a-67f213baeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-4\n",
    "#tokenizing the data\n",
    "\n",
    "xtrain = tokenizer(\n",
    "    text=dftrain['text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_sequence_length,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "xtest = tokenizer(\n",
    "    text=dftest['text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_sequence_length,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8e3243-381f-4745-8b60-4f96974f7336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       "array([    2,  2914,   277,   151,  2890,  1110,    83, 31553,  8365,\n",
       "           9, 25033,   122,    85,  4147,  5444,   678,   321, 40125,\n",
       "           3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0], dtype=int32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(xtest)\n",
    "display(xtest['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac648a8-7bf9-40b6-bc13-9f2aeaddf783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109081344   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 32,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 28)           21532       ['tf_bert_model[0][1]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,102,876\n",
      "Trainable params: 109,102,876\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#cell-5\n",
    "# building classifier model\n",
    "\n",
    "input_ids = Input(shape=(max_sequence_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_sequence_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "output = bert([input_ids, input_mask])[1] #pooled_output\n",
    "output = tf.keras.layers.Dense(classes_num, activation='softmax', name='output')(output)\n",
    "   \n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=output)\n",
    "\n",
    "optimizer = Adam(learning_rate=5e-05)\n",
    "\n",
    "\n",
    "loss =CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy('balanced_accuracy'),\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c8469d-06ca-4f95-8dfc-8d72bc656a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_973126/403206910.py:1: experimental_run_functions_eagerly (from tensorflow.python.eager.polymorphic_function.quarantine) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a65491c-3faf-48ce-9e1a-750781892ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "5975/5975 [==============================] - 1981s 332ms/step - loss: 0.2157 - balanced_accuracy: 0.9386 - val_loss: 0.1298 - val_balanced_accuracy: 0.9660\n",
      "Epoch 2/6\n",
      "5975/5975 [==============================] - 1968s 329ms/step - loss: 0.1212 - balanced_accuracy: 0.9672 - val_loss: 0.1173 - val_balanced_accuracy: 0.9694\n",
      "Epoch 3/6\n",
      "5975/5975 [==============================] - 1964s 329ms/step - loss: 0.0975 - balanced_accuracy: 0.9740 - val_loss: 0.1150 - val_balanced_accuracy: 0.9705\n",
      "Epoch 4/6\n",
      "5975/5975 [==============================] - 1970s 330ms/step - loss: 0.0820 - balanced_accuracy: 0.9784 - val_loss: 0.1120 - val_balanced_accuracy: 0.9714\n",
      "Epoch 5/6\n",
      "5975/5975 [==============================] - 1968s 329ms/step - loss: 0.0699 - balanced_accuracy: 0.9817 - val_loss: 0.1123 - val_balanced_accuracy: 0.9720\n",
      "Epoch 6/6\n",
      "5975/5975 [==============================] - 1970s 330ms/step - loss: 0.0605 - balanced_accuracy: 0.9844 - val_loss: 0.1131 - val_balanced_accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "#train the model (all meters)\n",
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':xtrain['input_ids'],'attention_mask':xtrain['attention_mask']}, y = ytrain,\n",
    "    validation_data = ({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']}, \n",
    "    ytest), epochs=6, batch_size=train_batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c3f32b-4936-4324-b48b-a7f4eb0f03f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11950/11950 [==============================] - 648s 54ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9889    0.9925    0.9907     53009\n",
      "           1     0.7889    0.6061    0.6855      1480\n",
      "           2     0.8775    0.9148    0.8957       587\n",
      "           3     0.8208    0.8233    0.8220      1686\n",
      "           4     0.0000    0.0000    0.0000        10\n",
      "           5     0.8245    0.8532    0.8386      1833\n",
      "           6     0.9826    0.9873    0.9849     81382\n",
      "           7     0.0000    0.0000    0.0000        12\n",
      "           8     0.9894    0.9843    0.9868     34821\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "          10     0.9334    0.8621    0.8963      1755\n",
      "          11     0.7628    0.4630    0.5763       257\n",
      "          12     0.6154    0.5517    0.5818       377\n",
      "          13     0.7275    0.6833    0.7047      7682\n",
      "          14     0.6667    0.3333    0.4444        72\n",
      "          15     0.9149    0.9476    0.9310      3871\n",
      "          16     0.9692    0.9648    0.9670      5973\n",
      "          17     0.9281    0.8158    0.8683       190\n",
      "          18     0.8685    0.8816    0.8750      1326\n",
      "          19     0.9807    0.9817    0.9812     13905\n",
      "          20     0.9491    0.9303    0.9396     22267\n",
      "          21     0.9283    0.9636    0.9456     17971\n",
      "          22     1.0000    0.3333    0.5000         3\n",
      "          23     0.9440    0.9746    0.9591     12252\n",
      "          24     0.8257    0.4762    0.6040       189\n",
      "          25     0.9954    0.9946    0.9950     88553\n",
      "          26     0.9862    0.9875    0.9868     30891\n",
      "          27     0.3750    0.1875    0.2500        16\n",
      "\n",
      "   micro avg     0.9723    0.9723    0.9723    382371\n",
      "   macro avg     0.7730    0.6962    0.7218    382371\n",
      "weighted avg     0.9717    0.9723    0.9719    382371\n",
      " samples avg     0.9723    0.9723    0.9723    382371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation (all meters)\n",
    "\n",
    "pred = model.predict({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']})\n",
    "\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "y_pred = to_categorical(y_pred, num_classes=classes_num).astype('int32')\n",
    "\n",
    "print(classification_report(ytest, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9fd3a-da11-415d-9f69-27e33f7dce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75fa1f45-ca47-499a-be0c-80a552c0539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "5783/5783 [==============================] - 1897s 328ms/step - loss: 0.1327 - balanced_accuracy: 0.9621 - val_loss: 0.0749 - val_balanced_accuracy: 0.9807\n",
      "Epoch 2/6\n",
      "5783/5783 [==============================] - 1847s 319ms/step - loss: 0.0702 - balanced_accuracy: 0.9819 - val_loss: 0.0703 - val_balanced_accuracy: 0.9824\n",
      "Epoch 3/6\n",
      "5783/5783 [==============================] - 1847s 319ms/step - loss: 0.0567 - balanced_accuracy: 0.9861 - val_loss: 0.0653 - val_balanced_accuracy: 0.9844\n",
      "Epoch 4/6\n",
      "5783/5783 [==============================] - 1850s 320ms/step - loss: 0.0487 - balanced_accuracy: 0.9884 - val_loss: 0.0662 - val_balanced_accuracy: 0.9843\n",
      "Epoch 5/6\n",
      "5783/5783 [==============================] - 1865s 322ms/step - loss: 0.0431 - balanced_accuracy: 0.9901 - val_loss: 0.0622 - val_balanced_accuracy: 0.9855\n",
      "Epoch 6/6\n",
      "5783/5783 [==============================] - 1914s 331ms/step - loss: 0.0392 - balanced_accuracy: 0.9911 - val_loss: 0.0644 - val_balanced_accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "#train the model (classical meters)\n",
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':xtrain['input_ids'],'attention_mask':xtrain['attention_mask']}, y = ytrain,\n",
    "    validation_data = ({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']}, \n",
    "    ytest), epochs=6, batch_size=train_batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150ba65a-e966-4b63-b3ec-e8f04bb33de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11565/11565 [==============================] - 648s 56ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9926    0.9938     53009\n",
      "           1     0.8430    0.8876    0.8647      1833\n",
      "           2     0.9875    0.9873    0.9874     81382\n",
      "           3     0.9912    0.9882    0.9897     34821\n",
      "           4     0.9225    0.8889    0.9054      1755\n",
      "           5     0.7500    0.2500    0.3750        72\n",
      "           6     0.9589    0.9579    0.9584      3871\n",
      "           7     0.9674    0.9684    0.9679      5973\n",
      "           8     0.9869    0.7947    0.8805       190\n",
      "           9     0.9108    0.8937    0.9022      1326\n",
      "          10     0.9796    0.9875    0.9835     13905\n",
      "          11     0.9408    0.9599    0.9503     22267\n",
      "          12     0.9793    0.9733    0.9763     17971\n",
      "          13     0.9710    0.9638    0.9674     12252\n",
      "          14     0.9961    0.9958    0.9959     88553\n",
      "          15     0.9886    0.9881    0.9883     30891\n",
      "\n",
      "   micro avg     0.9850    0.9850    0.9850    370071\n",
      "   macro avg     0.9480    0.9049    0.9179    370071\n",
      "weighted avg     0.9850    0.9850    0.9850    370071\n",
      " samples avg     0.9850    0.9850    0.9850    370071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation (classical meters)\n",
    "\n",
    "pred = model.predict({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']})\n",
    "\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "y_pred = to_categorical(y_pred, num_classes=classes_num).astype('int32')\n",
    "\n",
    "print(classification_report(ytest, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4547a78-e197-4212-8211-700f28a017c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b334a-63ed-4bf2-a31c-7b78073be5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea7339e2-eb16-4e53-b7e8-d61654aa18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# classifier_path = 'finetuned/classic_meters_classifierTF_camel.h5'\n",
    "classifier_path = 'finetuned/all_meters_classifierTF_camel.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5185399-536e-4687-aa72-093cdcc76c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving finetuned model locally\n",
    "\n",
    "model.save_weights(classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7cc85-d431-483b-9ceb-f0eb0c12f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a11ab3-0772-4547-aac4-14b9753f9864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
