{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd8754f-edd9-480e-9ba6-091ce5ac1542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 06:35:26.942741: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 06:35:26.969083: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 06:35:27.432919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "61502"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 49201\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12301\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, BertModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('poemsDataset.csv')\n",
    "df.fillna('', inplace=True)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "def remove_diacritics(a):    \n",
    "    return araby.strip_diacritics(a)\n",
    "\n",
    "df['first_hemistich'] = df['first_hemistich'].apply(remove_diacritics)\n",
    "df['second_hemistich'] = df['second_hemistich'].apply(remove_diacritics)\n",
    "\n",
    "def normalizeBeforeTraining(df):\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('النابغـة: ', '')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('الـربيع: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('عبيــد: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('امـرؤ القيسـ: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('امرؤ القيس: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(جلال الــــدين الــــرومي):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(لـوك الفيلسـوف الإنكليزي):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(كانت الفيلسوف الألماني ):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(بركســــــــــــــــون):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الحـــــــــــــــور):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الشــــــــــــــاعر):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الإنســـــــــــــــان):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('العلم):', '', regex=False)\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(العشــــــــــــــــق):', '', regex=False)\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الزهــــــــــــــــــرة):', '', regex=False)\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('التوأم اليشكري: ', '', regex=False)  \n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('آ', 'أ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('آ', 'أ')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('[/\":?،؟]', '')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('[/\":?،؟]', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('  ', ' ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('  ', ' ')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('  ', ' ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('  ', ' ')\n",
    "\n",
    "\n",
    "normalizeBeforeTraining(df)\n",
    "df.drop(df[(df['first_hemistich'] == '') & (df['second_hemistich'] == '')].index, inplace=True)\n",
    "\n",
    "#if first_hemistich == '', then copy the text from second_hemistich. then delete the text in the second_hemistich\n",
    "df['first_hemistich'] = df.apply(lambda x: x['second_hemistich'] if x['first_hemistich'] == '' else x['first_hemistich'], axis=1)\n",
    "df['second_hemistich'] = df.apply(lambda x: '' if x['first_hemistich'] == x['second_hemistich'] else x['second_hemistich'], axis=1)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(len(df))\n",
    "# display(df[:10])\n",
    "print('done')\n",
    "\n",
    "\n",
    "df['second_hemistich'].replace('', 'E', inplace=True)\n",
    "dfc = df[['first_hemistich', 'second_hemistich', 'meter', 'link']].copy()\n",
    "dfc['text'] = dfc['first_hemistich'] + ' S ' + dfc['second_hemistich']\n",
    "\n",
    "#removing verses without a meter\n",
    "dfc = dfc[dfc['meter'] != ''] \n",
    "dfc = dfc[dfc['meter'] != 'unspecified']\n",
    "dfc = dfc[dfc['meter'] != 'mixed']\n",
    "\n",
    "\n",
    "\n",
    "classic = ['taweel', 'kamel', 'baseet', 'khafif', 'wafer', 'rajaz', 'ramel', 'mutaqarib',\n",
    "           'saree', 'munsarih', 'mujtath', 'hazaj', 'madeed', 'mutadarak', 'muqtadab', 'mudari'] \n",
    "\n",
    "# including only verses with non-classical meters\n",
    "dfc = dfc[~dfc['meter'].isin(classic)]\n",
    "\n",
    "dfc.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfc['meter'] = dfc['meter'].astype('category')\n",
    "# display(dfc['meter'].unique())\n",
    "\n",
    "dfc['label'] = dfc['meter'].cat.codes \n",
    "\n",
    "\n",
    "df = dfc[['text', 'label']]\n",
    "\n",
    "classes_num = len(dfc['label'].unique())\n",
    "# classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv01, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv01 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:21, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.840200</td>\n",
       "      <td>0.719320</td>\n",
       "      <td>0.781237</td>\n",
       "      <td>0.225388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.665300</td>\n",
       "      <td>0.641442</td>\n",
       "      <td>0.791562</td>\n",
       "      <td>0.266050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.619700</td>\n",
       "      <td>0.588865</td>\n",
       "      <td>0.810341</td>\n",
       "      <td>0.347279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.550300</td>\n",
       "      <td>0.536937</td>\n",
       "      <td>0.834079</td>\n",
       "      <td>0.363527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.422400</td>\n",
       "      <td>0.572427</td>\n",
       "      <td>0.831884</td>\n",
       "      <td>0.372549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.506284</td>\n",
       "      <td>0.845297</td>\n",
       "      <td>0.392271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.496134</td>\n",
       "      <td>0.841558</td>\n",
       "      <td>0.388213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.357700</td>\n",
       "      <td>0.537662</td>\n",
       "      <td>0.845622</td>\n",
       "      <td>0.384566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.243300</td>\n",
       "      <td>0.558245</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>0.400998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.249800</td>\n",
       "      <td>0.537505</td>\n",
       "      <td>0.850012</td>\n",
       "      <td>0.395597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.848305</td>\n",
       "      <td>0.389163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.611591</td>\n",
       "      <td>0.840745</td>\n",
       "      <td>0.407120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.120900</td>\n",
       "      <td>0.655326</td>\n",
       "      <td>0.847492</td>\n",
       "      <td>0.402597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.625159</td>\n",
       "      <td>0.847167</td>\n",
       "      <td>0.412158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.599954</td>\n",
       "      <td>0.855621</td>\n",
       "      <td>0.412117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.698375</td>\n",
       "      <td>0.850663</td>\n",
       "      <td>0.419338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.734327</td>\n",
       "      <td>0.855703</td>\n",
       "      <td>0.426623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.717175</td>\n",
       "      <td>0.849443</td>\n",
       "      <td>0.423143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.713668</td>\n",
       "      <td>0.851232</td>\n",
       "      <td>0.429403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.826173</td>\n",
       "      <td>0.853914</td>\n",
       "      <td>0.442240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.813460</td>\n",
       "      <td>0.853752</td>\n",
       "      <td>0.443618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.844385</td>\n",
       "      <td>0.859117</td>\n",
       "      <td>0.460692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.830819</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.472784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.861401</td>\n",
       "      <td>0.856191</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.910492</td>\n",
       "      <td>0.857816</td>\n",
       "      <td>0.466746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.921997</td>\n",
       "      <td>0.856434</td>\n",
       "      <td>0.467803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.960268</td>\n",
       "      <td>0.856922</td>\n",
       "      <td>0.478377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.959132</td>\n",
       "      <td>0.860255</td>\n",
       "      <td>0.478716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.957909</td>\n",
       "      <td>0.860418</td>\n",
       "      <td>0.472605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.955202</td>\n",
       "      <td>0.858142</td>\n",
       "      <td>0.484821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv01, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv01 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:19, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.838600</td>\n",
       "      <td>0.700112</td>\n",
       "      <td>0.786278</td>\n",
       "      <td>0.228714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.663700</td>\n",
       "      <td>0.635878</td>\n",
       "      <td>0.796846</td>\n",
       "      <td>0.247995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.614700</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.812536</td>\n",
       "      <td>0.337352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>0.561891</td>\n",
       "      <td>0.825299</td>\n",
       "      <td>0.347843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.592419</td>\n",
       "      <td>0.826518</td>\n",
       "      <td>0.359629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.534760</td>\n",
       "      <td>0.837330</td>\n",
       "      <td>0.352729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>0.491003</td>\n",
       "      <td>0.845704</td>\n",
       "      <td>0.386085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.534892</td>\n",
       "      <td>0.845704</td>\n",
       "      <td>0.399182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.556640</td>\n",
       "      <td>0.849281</td>\n",
       "      <td>0.391919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.562623</td>\n",
       "      <td>0.846517</td>\n",
       "      <td>0.397310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.536158</td>\n",
       "      <td>0.843509</td>\n",
       "      <td>0.399897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.647726</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>0.398240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.631351</td>\n",
       "      <td>0.849118</td>\n",
       "      <td>0.405047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.603395</td>\n",
       "      <td>0.849199</td>\n",
       "      <td>0.408373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.608804</td>\n",
       "      <td>0.851394</td>\n",
       "      <td>0.408831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.722355</td>\n",
       "      <td>0.847655</td>\n",
       "      <td>0.435243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.742435</td>\n",
       "      <td>0.853183</td>\n",
       "      <td>0.413607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.784219</td>\n",
       "      <td>0.839281</td>\n",
       "      <td>0.433930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.772373</td>\n",
       "      <td>0.846923</td>\n",
       "      <td>0.432641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.850320</td>\n",
       "      <td>0.853833</td>\n",
       "      <td>0.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.862263</td>\n",
       "      <td>0.851882</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.882197</td>\n",
       "      <td>0.855215</td>\n",
       "      <td>0.455390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.890537</td>\n",
       "      <td>0.849687</td>\n",
       "      <td>0.454232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.915630</td>\n",
       "      <td>0.852126</td>\n",
       "      <td>0.452417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.946398</td>\n",
       "      <td>0.853427</td>\n",
       "      <td>0.453410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.918600</td>\n",
       "      <td>0.858548</td>\n",
       "      <td>0.463853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.964263</td>\n",
       "      <td>0.857898</td>\n",
       "      <td>0.456493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.975393</td>\n",
       "      <td>0.857491</td>\n",
       "      <td>0.452721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.962703</td>\n",
       "      <td>0.855947</td>\n",
       "      <td>0.456644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.975974</td>\n",
       "      <td>0.856434</td>\n",
       "      <td>0.456458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv01, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv01 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:20, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.838600</td>\n",
       "      <td>0.700112</td>\n",
       "      <td>0.786278</td>\n",
       "      <td>0.228714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.663700</td>\n",
       "      <td>0.635878</td>\n",
       "      <td>0.796846</td>\n",
       "      <td>0.247995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.614700</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.812536</td>\n",
       "      <td>0.337352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>0.561891</td>\n",
       "      <td>0.825299</td>\n",
       "      <td>0.347843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.592419</td>\n",
       "      <td>0.826518</td>\n",
       "      <td>0.359629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.534760</td>\n",
       "      <td>0.837330</td>\n",
       "      <td>0.352729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>0.491003</td>\n",
       "      <td>0.845704</td>\n",
       "      <td>0.386085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.534892</td>\n",
       "      <td>0.845704</td>\n",
       "      <td>0.399182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.556640</td>\n",
       "      <td>0.849281</td>\n",
       "      <td>0.391919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.562623</td>\n",
       "      <td>0.846517</td>\n",
       "      <td>0.397310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.536158</td>\n",
       "      <td>0.843509</td>\n",
       "      <td>0.399897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.647726</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>0.398240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.631351</td>\n",
       "      <td>0.849118</td>\n",
       "      <td>0.405047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.603395</td>\n",
       "      <td>0.849199</td>\n",
       "      <td>0.408373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.608804</td>\n",
       "      <td>0.851394</td>\n",
       "      <td>0.408831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.722355</td>\n",
       "      <td>0.847655</td>\n",
       "      <td>0.435243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.742435</td>\n",
       "      <td>0.853183</td>\n",
       "      <td>0.413607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.784219</td>\n",
       "      <td>0.839281</td>\n",
       "      <td>0.433930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.772373</td>\n",
       "      <td>0.846923</td>\n",
       "      <td>0.432641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.850320</td>\n",
       "      <td>0.853833</td>\n",
       "      <td>0.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.862263</td>\n",
       "      <td>0.851882</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.882197</td>\n",
       "      <td>0.855215</td>\n",
       "      <td>0.455390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.890537</td>\n",
       "      <td>0.849687</td>\n",
       "      <td>0.454232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.915630</td>\n",
       "      <td>0.852126</td>\n",
       "      <td>0.452417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.946398</td>\n",
       "      <td>0.853427</td>\n",
       "      <td>0.453410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.918600</td>\n",
       "      <td>0.858548</td>\n",
       "      <td>0.463853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.964263</td>\n",
       "      <td>0.857898</td>\n",
       "      <td>0.456493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.975393</td>\n",
       "      <td>0.857491</td>\n",
       "      <td>0.452721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.962703</td>\n",
       "      <td>0.855947</td>\n",
       "      <td>0.456644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.975974</td>\n",
       "      <td>0.856434</td>\n",
       "      <td>0.456458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:19, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.909300</td>\n",
       "      <td>0.767405</td>\n",
       "      <td>0.763027</td>\n",
       "      <td>0.183963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.693932</td>\n",
       "      <td>0.785546</td>\n",
       "      <td>0.231774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.647255</td>\n",
       "      <td>0.794082</td>\n",
       "      <td>0.257714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.622873</td>\n",
       "      <td>0.812454</td>\n",
       "      <td>0.293926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.601543</td>\n",
       "      <td>0.821315</td>\n",
       "      <td>0.341981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.561234</td>\n",
       "      <td>0.819446</td>\n",
       "      <td>0.335037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.477900</td>\n",
       "      <td>0.517749</td>\n",
       "      <td>0.834973</td>\n",
       "      <td>0.364987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.592713</td>\n",
       "      <td>0.821153</td>\n",
       "      <td>0.353448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.589483</td>\n",
       "      <td>0.834891</td>\n",
       "      <td>0.359787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.558351</td>\n",
       "      <td>0.839769</td>\n",
       "      <td>0.377506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.547979</td>\n",
       "      <td>0.838306</td>\n",
       "      <td>0.385079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.611410</td>\n",
       "      <td>0.838306</td>\n",
       "      <td>0.375788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.618149</td>\n",
       "      <td>0.844078</td>\n",
       "      <td>0.381568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>0.378754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.618546</td>\n",
       "      <td>0.844809</td>\n",
       "      <td>0.387318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.389342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.720055</td>\n",
       "      <td>0.841314</td>\n",
       "      <td>0.406518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.739915</td>\n",
       "      <td>0.836599</td>\n",
       "      <td>0.411806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.732987</td>\n",
       "      <td>0.843509</td>\n",
       "      <td>0.417699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.798157</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.406176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.775700</td>\n",
       "      <td>0.840176</td>\n",
       "      <td>0.421251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.789648</td>\n",
       "      <td>0.843021</td>\n",
       "      <td>0.418757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.814215</td>\n",
       "      <td>0.844809</td>\n",
       "      <td>0.443932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.922585</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.412987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.931956</td>\n",
       "      <td>0.846517</td>\n",
       "      <td>0.426364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.949202</td>\n",
       "      <td>0.842371</td>\n",
       "      <td>0.425463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.923145</td>\n",
       "      <td>0.847329</td>\n",
       "      <td>0.437927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.932950</td>\n",
       "      <td>0.845135</td>\n",
       "      <td>0.436938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.432402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.984738</td>\n",
       "      <td>0.843590</td>\n",
       "      <td>0.436576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:20, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.909300</td>\n",
       "      <td>0.767405</td>\n",
       "      <td>0.763027</td>\n",
       "      <td>0.183963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.693932</td>\n",
       "      <td>0.785546</td>\n",
       "      <td>0.231774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.647255</td>\n",
       "      <td>0.794082</td>\n",
       "      <td>0.257714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.622873</td>\n",
       "      <td>0.812454</td>\n",
       "      <td>0.293926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.601543</td>\n",
       "      <td>0.821315</td>\n",
       "      <td>0.341981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.561234</td>\n",
       "      <td>0.819446</td>\n",
       "      <td>0.335037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.477900</td>\n",
       "      <td>0.517749</td>\n",
       "      <td>0.834973</td>\n",
       "      <td>0.364987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.592713</td>\n",
       "      <td>0.821153</td>\n",
       "      <td>0.353448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.589483</td>\n",
       "      <td>0.834891</td>\n",
       "      <td>0.359787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.558351</td>\n",
       "      <td>0.839769</td>\n",
       "      <td>0.377506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.547979</td>\n",
       "      <td>0.838306</td>\n",
       "      <td>0.385079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.611410</td>\n",
       "      <td>0.838306</td>\n",
       "      <td>0.375788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.618149</td>\n",
       "      <td>0.844078</td>\n",
       "      <td>0.381568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>0.378754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.618546</td>\n",
       "      <td>0.844809</td>\n",
       "      <td>0.387318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.389342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.720055</td>\n",
       "      <td>0.841314</td>\n",
       "      <td>0.406518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.739915</td>\n",
       "      <td>0.836599</td>\n",
       "      <td>0.411806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.732987</td>\n",
       "      <td>0.843509</td>\n",
       "      <td>0.417699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.798157</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.406176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.775700</td>\n",
       "      <td>0.840176</td>\n",
       "      <td>0.421251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.789648</td>\n",
       "      <td>0.843021</td>\n",
       "      <td>0.418757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.814215</td>\n",
       "      <td>0.844809</td>\n",
       "      <td>0.443932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.922585</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.412987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.931956</td>\n",
       "      <td>0.846517</td>\n",
       "      <td>0.426364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.949202</td>\n",
       "      <td>0.842371</td>\n",
       "      <td>0.425463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.923145</td>\n",
       "      <td>0.847329</td>\n",
       "      <td>0.437927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.932950</td>\n",
       "      <td>0.845135</td>\n",
       "      <td>0.436938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.432402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.984738</td>\n",
       "      <td>0.843590</td>\n",
       "      <td>0.436576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:19, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.909300</td>\n",
       "      <td>0.767405</td>\n",
       "      <td>0.763027</td>\n",
       "      <td>0.183963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.693932</td>\n",
       "      <td>0.785546</td>\n",
       "      <td>0.231774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.647255</td>\n",
       "      <td>0.794082</td>\n",
       "      <td>0.257714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.622873</td>\n",
       "      <td>0.812454</td>\n",
       "      <td>0.293926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.601543</td>\n",
       "      <td>0.821315</td>\n",
       "      <td>0.341981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.561234</td>\n",
       "      <td>0.819446</td>\n",
       "      <td>0.335037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.477900</td>\n",
       "      <td>0.517749</td>\n",
       "      <td>0.834973</td>\n",
       "      <td>0.364987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.592713</td>\n",
       "      <td>0.821153</td>\n",
       "      <td>0.353448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.589483</td>\n",
       "      <td>0.834891</td>\n",
       "      <td>0.359787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.558351</td>\n",
       "      <td>0.839769</td>\n",
       "      <td>0.377506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.547979</td>\n",
       "      <td>0.838306</td>\n",
       "      <td>0.385079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.611410</td>\n",
       "      <td>0.838306</td>\n",
       "      <td>0.375788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.618149</td>\n",
       "      <td>0.844078</td>\n",
       "      <td>0.381568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>0.378754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.618546</td>\n",
       "      <td>0.844809</td>\n",
       "      <td>0.387318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.389342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.720055</td>\n",
       "      <td>0.841314</td>\n",
       "      <td>0.406518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.739915</td>\n",
       "      <td>0.836599</td>\n",
       "      <td>0.411806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.732987</td>\n",
       "      <td>0.843509</td>\n",
       "      <td>0.417699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.798157</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.406176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.775700</td>\n",
       "      <td>0.840176</td>\n",
       "      <td>0.421251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.789648</td>\n",
       "      <td>0.843021</td>\n",
       "      <td>0.418757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.814215</td>\n",
       "      <td>0.844809</td>\n",
       "      <td>0.443932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.922585</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.412987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.931956</td>\n",
       "      <td>0.846517</td>\n",
       "      <td>0.426364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.949202</td>\n",
       "      <td>0.842371</td>\n",
       "      <td>0.425463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.923145</td>\n",
       "      <td>0.847329</td>\n",
       "      <td>0.437927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.932950</td>\n",
       "      <td>0.845135</td>\n",
       "      <td>0.436938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.432402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.984738</td>\n",
       "      <td>0.843590</td>\n",
       "      <td>0.436576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-ca, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-ca and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:00, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.621669</td>\n",
       "      <td>0.802780</td>\n",
       "      <td>0.254368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.839932</td>\n",
       "      <td>0.367785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.474653</td>\n",
       "      <td>0.848955</td>\n",
       "      <td>0.415827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.458082</td>\n",
       "      <td>0.861393</td>\n",
       "      <td>0.418012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.481237</td>\n",
       "      <td>0.863832</td>\n",
       "      <td>0.431737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.450582</td>\n",
       "      <td>0.859849</td>\n",
       "      <td>0.432487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>0.418572</td>\n",
       "      <td>0.869523</td>\n",
       "      <td>0.444711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.476846</td>\n",
       "      <td>0.872775</td>\n",
       "      <td>0.434387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.444017</td>\n",
       "      <td>0.878546</td>\n",
       "      <td>0.456026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.879441</td>\n",
       "      <td>0.460192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.424262</td>\n",
       "      <td>0.881392</td>\n",
       "      <td>0.455520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.509130</td>\n",
       "      <td>0.881798</td>\n",
       "      <td>0.519086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.512990</td>\n",
       "      <td>0.878303</td>\n",
       "      <td>0.534844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.502769</td>\n",
       "      <td>0.883668</td>\n",
       "      <td>0.515370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.533488</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.528978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.610643</td>\n",
       "      <td>0.884725</td>\n",
       "      <td>0.509061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.638982</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.540545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.600144</td>\n",
       "      <td>0.876352</td>\n",
       "      <td>0.546848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.627354</td>\n",
       "      <td>0.883912</td>\n",
       "      <td>0.541456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.654991</td>\n",
       "      <td>0.885944</td>\n",
       "      <td>0.533603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.664105</td>\n",
       "      <td>0.886513</td>\n",
       "      <td>0.552660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.634009</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.553570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.689222</td>\n",
       "      <td>0.885863</td>\n",
       "      <td>0.569865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.787758</td>\n",
       "      <td>0.885944</td>\n",
       "      <td>0.534308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.730031</td>\n",
       "      <td>0.888952</td>\n",
       "      <td>0.536162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.889359</td>\n",
       "      <td>0.545951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.756550</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>0.568399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.771268</td>\n",
       "      <td>0.888302</td>\n",
       "      <td>0.553911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.791404</td>\n",
       "      <td>0.890009</td>\n",
       "      <td>0.555142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.787715</td>\n",
       "      <td>0.889277</td>\n",
       "      <td>0.554604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-ca, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-ca and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:00, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.621669</td>\n",
       "      <td>0.802780</td>\n",
       "      <td>0.254368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.839932</td>\n",
       "      <td>0.367785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.474653</td>\n",
       "      <td>0.848955</td>\n",
       "      <td>0.415827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.458082</td>\n",
       "      <td>0.861393</td>\n",
       "      <td>0.418012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.481237</td>\n",
       "      <td>0.863832</td>\n",
       "      <td>0.431737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.450582</td>\n",
       "      <td>0.859849</td>\n",
       "      <td>0.432487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>0.418572</td>\n",
       "      <td>0.869523</td>\n",
       "      <td>0.444711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.476846</td>\n",
       "      <td>0.872775</td>\n",
       "      <td>0.434387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.444017</td>\n",
       "      <td>0.878546</td>\n",
       "      <td>0.456026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.879441</td>\n",
       "      <td>0.460192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.424262</td>\n",
       "      <td>0.881392</td>\n",
       "      <td>0.455520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.509130</td>\n",
       "      <td>0.881798</td>\n",
       "      <td>0.519086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.512990</td>\n",
       "      <td>0.878303</td>\n",
       "      <td>0.534844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.502769</td>\n",
       "      <td>0.883668</td>\n",
       "      <td>0.515370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.533488</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.528978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.610643</td>\n",
       "      <td>0.884725</td>\n",
       "      <td>0.509061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.638982</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.540545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.600144</td>\n",
       "      <td>0.876352</td>\n",
       "      <td>0.546848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.627354</td>\n",
       "      <td>0.883912</td>\n",
       "      <td>0.541456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.654991</td>\n",
       "      <td>0.885944</td>\n",
       "      <td>0.533603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.664105</td>\n",
       "      <td>0.886513</td>\n",
       "      <td>0.552660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.634009</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.553570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.689222</td>\n",
       "      <td>0.885863</td>\n",
       "      <td>0.569865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.787758</td>\n",
       "      <td>0.885944</td>\n",
       "      <td>0.534308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.730031</td>\n",
       "      <td>0.888952</td>\n",
       "      <td>0.536162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.889359</td>\n",
       "      <td>0.545951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.756550</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>0.568399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.771268</td>\n",
       "      <td>0.888302</td>\n",
       "      <td>0.553911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.791404</td>\n",
       "      <td>0.890009</td>\n",
       "      <td>0.555142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.787715</td>\n",
       "      <td>0.889277</td>\n",
       "      <td>0.554604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-ca, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-ca and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:00, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.621669</td>\n",
       "      <td>0.802780</td>\n",
       "      <td>0.254368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.839932</td>\n",
       "      <td>0.367785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.474653</td>\n",
       "      <td>0.848955</td>\n",
       "      <td>0.415827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.458082</td>\n",
       "      <td>0.861393</td>\n",
       "      <td>0.418012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.481237</td>\n",
       "      <td>0.863832</td>\n",
       "      <td>0.431737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.450582</td>\n",
       "      <td>0.859849</td>\n",
       "      <td>0.432487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>0.418572</td>\n",
       "      <td>0.869523</td>\n",
       "      <td>0.444711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.476846</td>\n",
       "      <td>0.872775</td>\n",
       "      <td>0.434387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.444017</td>\n",
       "      <td>0.878546</td>\n",
       "      <td>0.456026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.879441</td>\n",
       "      <td>0.460192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.424262</td>\n",
       "      <td>0.881392</td>\n",
       "      <td>0.455520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.509130</td>\n",
       "      <td>0.881798</td>\n",
       "      <td>0.519086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.512990</td>\n",
       "      <td>0.878303</td>\n",
       "      <td>0.534844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.502769</td>\n",
       "      <td>0.883668</td>\n",
       "      <td>0.515370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.533488</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.528978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.610643</td>\n",
       "      <td>0.884725</td>\n",
       "      <td>0.509061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.638982</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.540545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.600144</td>\n",
       "      <td>0.876352</td>\n",
       "      <td>0.546848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.627354</td>\n",
       "      <td>0.883912</td>\n",
       "      <td>0.541456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.654991</td>\n",
       "      <td>0.885944</td>\n",
       "      <td>0.533603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.664105</td>\n",
       "      <td>0.886513</td>\n",
       "      <td>0.552660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.634009</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.553570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.689222</td>\n",
       "      <td>0.885863</td>\n",
       "      <td>0.569865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.787758</td>\n",
       "      <td>0.885944</td>\n",
       "      <td>0.534308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.730031</td>\n",
       "      <td>0.888952</td>\n",
       "      <td>0.536162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.889359</td>\n",
       "      <td>0.545951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.756550</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>0.568399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.771268</td>\n",
       "      <td>0.888302</td>\n",
       "      <td>0.553911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.791404</td>\n",
       "      <td>0.890009</td>\n",
       "      <td>0.555142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.787715</td>\n",
       "      <td>0.889277</td>\n",
       "      <td>0.554604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:20, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.653137</td>\n",
       "      <td>0.799935</td>\n",
       "      <td>0.235476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.594800</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.832859</td>\n",
       "      <td>0.313581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>0.489777</td>\n",
       "      <td>0.845460</td>\n",
       "      <td>0.391686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.499668</td>\n",
       "      <td>0.851475</td>\n",
       "      <td>0.414289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.516842</td>\n",
       "      <td>0.856028</td>\n",
       "      <td>0.406061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.437092</td>\n",
       "      <td>0.871962</td>\n",
       "      <td>0.432109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.437545</td>\n",
       "      <td>0.871555</td>\n",
       "      <td>0.426582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.493320</td>\n",
       "      <td>0.871230</td>\n",
       "      <td>0.430522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.534737</td>\n",
       "      <td>0.869523</td>\n",
       "      <td>0.432569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.552616</td>\n",
       "      <td>0.873181</td>\n",
       "      <td>0.456166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.522373</td>\n",
       "      <td>0.874482</td>\n",
       "      <td>0.458016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.585797</td>\n",
       "      <td>0.868547</td>\n",
       "      <td>0.494988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.634568</td>\n",
       "      <td>0.879522</td>\n",
       "      <td>0.471393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.621519</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.487110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.600588</td>\n",
       "      <td>0.874888</td>\n",
       "      <td>0.474579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.710639</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.483883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.743944</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.486491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>0.873750</td>\n",
       "      <td>0.486362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.714173</td>\n",
       "      <td>0.881717</td>\n",
       "      <td>0.494435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.877571</td>\n",
       "      <td>0.505559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.801741</td>\n",
       "      <td>0.882042</td>\n",
       "      <td>0.534193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.844774</td>\n",
       "      <td>0.880660</td>\n",
       "      <td>0.497556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.795711</td>\n",
       "      <td>0.880579</td>\n",
       "      <td>0.532095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.841670</td>\n",
       "      <td>0.882042</td>\n",
       "      <td>0.536379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.855437</td>\n",
       "      <td>0.881961</td>\n",
       "      <td>0.535260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.882393</td>\n",
       "      <td>0.882367</td>\n",
       "      <td>0.526321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.863616</td>\n",
       "      <td>0.879685</td>\n",
       "      <td>0.586693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.853460</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.559053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.853670</td>\n",
       "      <td>0.884481</td>\n",
       "      <td>0.552380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.864206</td>\n",
       "      <td>0.883668</td>\n",
       "      <td>0.561000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b969f6464754ebebe4c203ac14127bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd408d94c304dafb0253eb26cc70749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.653137</td>\n",
       "      <td>0.799935</td>\n",
       "      <td>0.235476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.594800</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.832859</td>\n",
       "      <td>0.313581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>0.489777</td>\n",
       "      <td>0.845460</td>\n",
       "      <td>0.391686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.499668</td>\n",
       "      <td>0.851475</td>\n",
       "      <td>0.414289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.516842</td>\n",
       "      <td>0.856028</td>\n",
       "      <td>0.406061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.437092</td>\n",
       "      <td>0.871962</td>\n",
       "      <td>0.432109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.437545</td>\n",
       "      <td>0.871555</td>\n",
       "      <td>0.426582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.493320</td>\n",
       "      <td>0.871230</td>\n",
       "      <td>0.430522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.534737</td>\n",
       "      <td>0.869523</td>\n",
       "      <td>0.432569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.552616</td>\n",
       "      <td>0.873181</td>\n",
       "      <td>0.456166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.522373</td>\n",
       "      <td>0.874482</td>\n",
       "      <td>0.458016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.585797</td>\n",
       "      <td>0.868547</td>\n",
       "      <td>0.494988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.634568</td>\n",
       "      <td>0.879522</td>\n",
       "      <td>0.471393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.621519</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.487110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.600588</td>\n",
       "      <td>0.874888</td>\n",
       "      <td>0.474579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.710639</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.483883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.743944</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.486491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>0.873750</td>\n",
       "      <td>0.486362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.714173</td>\n",
       "      <td>0.881717</td>\n",
       "      <td>0.494435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.877571</td>\n",
       "      <td>0.505559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.801741</td>\n",
       "      <td>0.882042</td>\n",
       "      <td>0.534193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.844774</td>\n",
       "      <td>0.880660</td>\n",
       "      <td>0.497556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.795711</td>\n",
       "      <td>0.880579</td>\n",
       "      <td>0.532095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.841670</td>\n",
       "      <td>0.882042</td>\n",
       "      <td>0.536379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.855437</td>\n",
       "      <td>0.881961</td>\n",
       "      <td>0.535260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.882393</td>\n",
       "      <td>0.882367</td>\n",
       "      <td>0.526321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.863616</td>\n",
       "      <td>0.879685</td>\n",
       "      <td>0.586693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.853460</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.559053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.853670</td>\n",
       "      <td>0.884481</td>\n",
       "      <td>0.552380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.864206</td>\n",
       "      <td>0.883668</td>\n",
       "      <td>0.561000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f766d97e8eb04ccb84544a0c994c3714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c719fafa016640a9b31421af6ac01fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:17, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.653137</td>\n",
       "      <td>0.799935</td>\n",
       "      <td>0.235476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.594800</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.832859</td>\n",
       "      <td>0.313581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>0.489777</td>\n",
       "      <td>0.845460</td>\n",
       "      <td>0.391686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.499668</td>\n",
       "      <td>0.851475</td>\n",
       "      <td>0.414289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.516842</td>\n",
       "      <td>0.856028</td>\n",
       "      <td>0.406061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.437092</td>\n",
       "      <td>0.871962</td>\n",
       "      <td>0.432109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.437545</td>\n",
       "      <td>0.871555</td>\n",
       "      <td>0.426582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.493320</td>\n",
       "      <td>0.871230</td>\n",
       "      <td>0.430522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.534737</td>\n",
       "      <td>0.869523</td>\n",
       "      <td>0.432569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.552616</td>\n",
       "      <td>0.873181</td>\n",
       "      <td>0.456166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.522373</td>\n",
       "      <td>0.874482</td>\n",
       "      <td>0.458016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.585797</td>\n",
       "      <td>0.868547</td>\n",
       "      <td>0.494988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.634568</td>\n",
       "      <td>0.879522</td>\n",
       "      <td>0.471393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.621519</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.487110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.600588</td>\n",
       "      <td>0.874888</td>\n",
       "      <td>0.474579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.710639</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.483883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.743944</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.486491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.740181</td>\n",
       "      <td>0.873750</td>\n",
       "      <td>0.486362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.714173</td>\n",
       "      <td>0.881717</td>\n",
       "      <td>0.494435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.877571</td>\n",
       "      <td>0.505559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.801741</td>\n",
       "      <td>0.882042</td>\n",
       "      <td>0.534193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.844774</td>\n",
       "      <td>0.880660</td>\n",
       "      <td>0.497556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.795711</td>\n",
       "      <td>0.880579</td>\n",
       "      <td>0.532095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.841670</td>\n",
       "      <td>0.882042</td>\n",
       "      <td>0.536379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.855437</td>\n",
       "      <td>0.881961</td>\n",
       "      <td>0.535260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.882393</td>\n",
       "      <td>0.882367</td>\n",
       "      <td>0.526321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.863616</td>\n",
       "      <td>0.879685</td>\n",
       "      <td>0.586693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.853460</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.559053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.853670</td>\n",
       "      <td>0.884481</td>\n",
       "      <td>0.552380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.864206</td>\n",
       "      <td>0.883668</td>\n",
       "      <td>0.561000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/ARBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/ARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae45bd9d37b4e08bd90ae86bdd42646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe71205f694b496c8c99d45de875103f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:37, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.817700</td>\n",
       "      <td>0.692727</td>\n",
       "      <td>0.794326</td>\n",
       "      <td>0.225168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.614880</td>\n",
       "      <td>0.804975</td>\n",
       "      <td>0.249983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.589300</td>\n",
       "      <td>0.568386</td>\n",
       "      <td>0.813349</td>\n",
       "      <td>0.352189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.545789</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>0.360491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.571007</td>\n",
       "      <td>0.839363</td>\n",
       "      <td>0.357475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.543647</td>\n",
       "      <td>0.832940</td>\n",
       "      <td>0.365269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.473070</td>\n",
       "      <td>0.849931</td>\n",
       "      <td>0.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.580933</td>\n",
       "      <td>0.844078</td>\n",
       "      <td>0.378645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.636727</td>\n",
       "      <td>0.847411</td>\n",
       "      <td>0.397286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.659797</td>\n",
       "      <td>0.845785</td>\n",
       "      <td>0.373804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.597423</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>0.396634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.811915</td>\n",
       "      <td>0.806439</td>\n",
       "      <td>0.388570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.760981</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.382847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.745620</td>\n",
       "      <td>0.841801</td>\n",
       "      <td>0.387558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.743831</td>\n",
       "      <td>0.839281</td>\n",
       "      <td>0.389002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.848342</td>\n",
       "      <td>0.851475</td>\n",
       "      <td>0.415588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.870291</td>\n",
       "      <td>0.845541</td>\n",
       "      <td>0.413227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.903453</td>\n",
       "      <td>0.841964</td>\n",
       "      <td>0.401635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.850823</td>\n",
       "      <td>0.855215</td>\n",
       "      <td>0.418582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.964027</td>\n",
       "      <td>0.847167</td>\n",
       "      <td>0.409146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.986015</td>\n",
       "      <td>0.854646</td>\n",
       "      <td>0.417993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1.009703</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.412887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>1.009561</td>\n",
       "      <td>0.847736</td>\n",
       "      <td>0.447843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.038772</td>\n",
       "      <td>0.851232</td>\n",
       "      <td>0.438104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.092765</td>\n",
       "      <td>0.850825</td>\n",
       "      <td>0.440173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>1.088049</td>\n",
       "      <td>0.853508</td>\n",
       "      <td>0.447865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.076066</td>\n",
       "      <td>0.850906</td>\n",
       "      <td>0.446457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.103138</td>\n",
       "      <td>0.855134</td>\n",
       "      <td>0.437473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.119214</td>\n",
       "      <td>0.850419</td>\n",
       "      <td>0.441070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.115178</td>\n",
       "      <td>0.856191</td>\n",
       "      <td>0.427453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/ARBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/ARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c958b2537c154a55be4c2e8b6e7f3887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23378b585d314a88be7ed0b0c13cb19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:38, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.817700</td>\n",
       "      <td>0.692727</td>\n",
       "      <td>0.794326</td>\n",
       "      <td>0.225168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.614880</td>\n",
       "      <td>0.804975</td>\n",
       "      <td>0.249983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.589300</td>\n",
       "      <td>0.568386</td>\n",
       "      <td>0.813349</td>\n",
       "      <td>0.352189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.545789</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>0.360491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.571007</td>\n",
       "      <td>0.839363</td>\n",
       "      <td>0.357475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.543647</td>\n",
       "      <td>0.832940</td>\n",
       "      <td>0.365269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.473070</td>\n",
       "      <td>0.849931</td>\n",
       "      <td>0.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.580933</td>\n",
       "      <td>0.844078</td>\n",
       "      <td>0.378645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.636727</td>\n",
       "      <td>0.847411</td>\n",
       "      <td>0.397286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.659797</td>\n",
       "      <td>0.845785</td>\n",
       "      <td>0.373804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.597423</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>0.396634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.811915</td>\n",
       "      <td>0.806439</td>\n",
       "      <td>0.388570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.760981</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.382847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.745620</td>\n",
       "      <td>0.841801</td>\n",
       "      <td>0.387558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.743831</td>\n",
       "      <td>0.839281</td>\n",
       "      <td>0.389002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.848342</td>\n",
       "      <td>0.851475</td>\n",
       "      <td>0.415588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.870291</td>\n",
       "      <td>0.845541</td>\n",
       "      <td>0.413227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.903453</td>\n",
       "      <td>0.841964</td>\n",
       "      <td>0.401635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.850823</td>\n",
       "      <td>0.855215</td>\n",
       "      <td>0.418582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.964027</td>\n",
       "      <td>0.847167</td>\n",
       "      <td>0.409146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.986015</td>\n",
       "      <td>0.854646</td>\n",
       "      <td>0.417993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1.009703</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.412887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>1.009561</td>\n",
       "      <td>0.847736</td>\n",
       "      <td>0.447843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.038772</td>\n",
       "      <td>0.851232</td>\n",
       "      <td>0.438104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.092765</td>\n",
       "      <td>0.850825</td>\n",
       "      <td>0.440173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>1.088049</td>\n",
       "      <td>0.853508</td>\n",
       "      <td>0.447865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.076066</td>\n",
       "      <td>0.850906</td>\n",
       "      <td>0.446457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.103138</td>\n",
       "      <td>0.855134</td>\n",
       "      <td>0.437473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.119214</td>\n",
       "      <td>0.850419</td>\n",
       "      <td>0.441070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.115178</td>\n",
       "      <td>0.856191</td>\n",
       "      <td>0.427453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/ARBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/ARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae32b82c848347b5a2b3c930340b7cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b1793aaeae4906860d6eb66ef5d47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 04:37, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.817700</td>\n",
       "      <td>0.692727</td>\n",
       "      <td>0.794326</td>\n",
       "      <td>0.225168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.614880</td>\n",
       "      <td>0.804975</td>\n",
       "      <td>0.249983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.589300</td>\n",
       "      <td>0.568386</td>\n",
       "      <td>0.813349</td>\n",
       "      <td>0.352189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.545789</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>0.360491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.571007</td>\n",
       "      <td>0.839363</td>\n",
       "      <td>0.357475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.543647</td>\n",
       "      <td>0.832940</td>\n",
       "      <td>0.365269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.473070</td>\n",
       "      <td>0.849931</td>\n",
       "      <td>0.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.580933</td>\n",
       "      <td>0.844078</td>\n",
       "      <td>0.378645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.636727</td>\n",
       "      <td>0.847411</td>\n",
       "      <td>0.397286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.659797</td>\n",
       "      <td>0.845785</td>\n",
       "      <td>0.373804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.597423</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>0.396634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.811915</td>\n",
       "      <td>0.806439</td>\n",
       "      <td>0.388570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.760981</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.382847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.745620</td>\n",
       "      <td>0.841801</td>\n",
       "      <td>0.387558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.743831</td>\n",
       "      <td>0.839281</td>\n",
       "      <td>0.389002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.848342</td>\n",
       "      <td>0.851475</td>\n",
       "      <td>0.415588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.870291</td>\n",
       "      <td>0.845541</td>\n",
       "      <td>0.413227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.903453</td>\n",
       "      <td>0.841964</td>\n",
       "      <td>0.401635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.850823</td>\n",
       "      <td>0.855215</td>\n",
       "      <td>0.418582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.964027</td>\n",
       "      <td>0.847167</td>\n",
       "      <td>0.409146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.986015</td>\n",
       "      <td>0.854646</td>\n",
       "      <td>0.417993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1.009703</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.412887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>1.009561</td>\n",
       "      <td>0.847736</td>\n",
       "      <td>0.447843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.038772</td>\n",
       "      <td>0.851232</td>\n",
       "      <td>0.438104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.092765</td>\n",
       "      <td>0.850825</td>\n",
       "      <td>0.440173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>1.088049</td>\n",
       "      <td>0.853508</td>\n",
       "      <td>0.447865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.076066</td>\n",
       "      <td>0.850906</td>\n",
       "      <td>0.446457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.103138</td>\n",
       "      <td>0.855134</td>\n",
       "      <td>0.437473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.119214</td>\n",
       "      <td>0.850419</td>\n",
       "      <td>0.441070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.115178</td>\n",
       "      <td>0.856191</td>\n",
       "      <td>0.427453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arapoembert, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arapoembert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0839a54156484b4ab7b39100b3e298db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fe7ffeb20246928599684a38326fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 03:36, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.558100</td>\n",
       "      <td>0.404447</td>\n",
       "      <td>0.882367</td>\n",
       "      <td>0.447939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.374092</td>\n",
       "      <td>0.889521</td>\n",
       "      <td>0.461793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.336972</td>\n",
       "      <td>0.893992</td>\n",
       "      <td>0.473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.355340</td>\n",
       "      <td>0.900984</td>\n",
       "      <td>0.480249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.901065</td>\n",
       "      <td>0.482947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.195600</td>\n",
       "      <td>0.330107</td>\n",
       "      <td>0.907243</td>\n",
       "      <td>0.492358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>0.321083</td>\n",
       "      <td>0.906186</td>\n",
       "      <td>0.487712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.396964</td>\n",
       "      <td>0.906999</td>\n",
       "      <td>0.491375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.419521</td>\n",
       "      <td>0.908381</td>\n",
       "      <td>0.492268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.433245</td>\n",
       "      <td>0.909032</td>\n",
       "      <td>0.499760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.452808</td>\n",
       "      <td>0.909357</td>\n",
       "      <td>0.504127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.484412</td>\n",
       "      <td>0.908544</td>\n",
       "      <td>0.518937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.502832</td>\n",
       "      <td>0.911633</td>\n",
       "      <td>0.523132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.557979</td>\n",
       "      <td>0.909032</td>\n",
       "      <td>0.524913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.502470</td>\n",
       "      <td>0.909682</td>\n",
       "      <td>0.549908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.573999</td>\n",
       "      <td>0.910495</td>\n",
       "      <td>0.564188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.597597</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.548390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.628047</td>\n",
       "      <td>0.908544</td>\n",
       "      <td>0.556617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.910251</td>\n",
       "      <td>0.564173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.612803</td>\n",
       "      <td>0.911958</td>\n",
       "      <td>0.551769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.653636</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.580165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.659736</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.548212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.697715</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.540479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.656343</td>\n",
       "      <td>0.911877</td>\n",
       "      <td>0.548869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.692017</td>\n",
       "      <td>0.911064</td>\n",
       "      <td>0.549346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.660860</td>\n",
       "      <td>0.912121</td>\n",
       "      <td>0.552122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.675596</td>\n",
       "      <td>0.912284</td>\n",
       "      <td>0.555195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.693160</td>\n",
       "      <td>0.909438</td>\n",
       "      <td>0.544630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.701436</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>0.560647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.700733</td>\n",
       "      <td>0.911714</td>\n",
       "      <td>0.565629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arapoembert, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arapoembert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acf085e2c8f441ebd0093358b0247da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3593dfa452d2488595d1041627e86cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 03:36, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.558100</td>\n",
       "      <td>0.404447</td>\n",
       "      <td>0.882367</td>\n",
       "      <td>0.447939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.374092</td>\n",
       "      <td>0.889521</td>\n",
       "      <td>0.461793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.336972</td>\n",
       "      <td>0.893992</td>\n",
       "      <td>0.473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.355340</td>\n",
       "      <td>0.900984</td>\n",
       "      <td>0.480249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.901065</td>\n",
       "      <td>0.482947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.195600</td>\n",
       "      <td>0.330107</td>\n",
       "      <td>0.907243</td>\n",
       "      <td>0.492358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>0.321083</td>\n",
       "      <td>0.906186</td>\n",
       "      <td>0.487712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.396964</td>\n",
       "      <td>0.906999</td>\n",
       "      <td>0.491375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.419521</td>\n",
       "      <td>0.908381</td>\n",
       "      <td>0.492268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.433245</td>\n",
       "      <td>0.909032</td>\n",
       "      <td>0.499760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.452808</td>\n",
       "      <td>0.909357</td>\n",
       "      <td>0.504127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.484412</td>\n",
       "      <td>0.908544</td>\n",
       "      <td>0.518937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.502832</td>\n",
       "      <td>0.911633</td>\n",
       "      <td>0.523132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.557979</td>\n",
       "      <td>0.909032</td>\n",
       "      <td>0.524913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.502470</td>\n",
       "      <td>0.909682</td>\n",
       "      <td>0.549908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.573999</td>\n",
       "      <td>0.910495</td>\n",
       "      <td>0.564188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.597597</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.548390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.628047</td>\n",
       "      <td>0.908544</td>\n",
       "      <td>0.556617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.910251</td>\n",
       "      <td>0.564173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.612803</td>\n",
       "      <td>0.911958</td>\n",
       "      <td>0.551769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.653636</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.580165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.659736</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.548212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.697715</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.540479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.656343</td>\n",
       "      <td>0.911877</td>\n",
       "      <td>0.548869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.692017</td>\n",
       "      <td>0.911064</td>\n",
       "      <td>0.549346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.660860</td>\n",
       "      <td>0.912121</td>\n",
       "      <td>0.552122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.675596</td>\n",
       "      <td>0.912284</td>\n",
       "      <td>0.555195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.693160</td>\n",
       "      <td>0.909438</td>\n",
       "      <td>0.544630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.701436</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>0.560647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.700733</td>\n",
       "      <td>0.911714</td>\n",
       "      <td>0.565629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/bert-base-arapoembert, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/bert-base-arapoembert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c70721b9837466ca9014f19b0bb894c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406077df1cf242e7934a45d321bb8191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6152' max='6152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6152/6152 03:37, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.558100</td>\n",
       "      <td>0.404447</td>\n",
       "      <td>0.882367</td>\n",
       "      <td>0.447939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.374092</td>\n",
       "      <td>0.889521</td>\n",
       "      <td>0.461793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.336972</td>\n",
       "      <td>0.893992</td>\n",
       "      <td>0.473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.355340</td>\n",
       "      <td>0.900984</td>\n",
       "      <td>0.480249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.901065</td>\n",
       "      <td>0.482947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.195600</td>\n",
       "      <td>0.330107</td>\n",
       "      <td>0.907243</td>\n",
       "      <td>0.492358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>0.321083</td>\n",
       "      <td>0.906186</td>\n",
       "      <td>0.487712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.396964</td>\n",
       "      <td>0.906999</td>\n",
       "      <td>0.491375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.419521</td>\n",
       "      <td>0.908381</td>\n",
       "      <td>0.492268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.433245</td>\n",
       "      <td>0.909032</td>\n",
       "      <td>0.499760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.452808</td>\n",
       "      <td>0.909357</td>\n",
       "      <td>0.504127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.484412</td>\n",
       "      <td>0.908544</td>\n",
       "      <td>0.518937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.502832</td>\n",
       "      <td>0.911633</td>\n",
       "      <td>0.523132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.557979</td>\n",
       "      <td>0.909032</td>\n",
       "      <td>0.524913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.502470</td>\n",
       "      <td>0.909682</td>\n",
       "      <td>0.549908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.573999</td>\n",
       "      <td>0.910495</td>\n",
       "      <td>0.564188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.597597</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.548390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.628047</td>\n",
       "      <td>0.908544</td>\n",
       "      <td>0.556617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.910251</td>\n",
       "      <td>0.564173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.612803</td>\n",
       "      <td>0.911958</td>\n",
       "      <td>0.551769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.653636</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.580165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.659736</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.548212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.697715</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.540479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.656343</td>\n",
       "      <td>0.911877</td>\n",
       "      <td>0.548869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.692017</td>\n",
       "      <td>0.911064</td>\n",
       "      <td>0.549346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.660860</td>\n",
       "      <td>0.912121</td>\n",
       "      <td>0.552122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.675596</td>\n",
       "      <td>0.912284</td>\n",
       "      <td>0.555195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.693160</td>\n",
       "      <td>0.909438</td>\n",
       "      <td>0.544630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.701436</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>0.560647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.700733</td>\n",
       "      <td>0.911714</td>\n",
       "      <td>0.565629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'Accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5389/4050360847.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mlog_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'non_classical.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model,Accuracy,F1\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p1/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 144\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p1/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    729\u001b[0m         (\n\u001b[1;32m    730\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p1/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p1/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Accuracy'"
     ]
    }
   ],
   "source": [
    "log_file = 'non_classical.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "max_sequence_length = 32\n",
    "train_batch_size = 256\n",
    "\n",
    "models = [ \n",
    "        'aubmindlab/bert-base-arabertv01',\n",
    "    'aubmindlab/bert-base-arabert',\n",
    "        'CAMeL-Lab/bert-base-arabic-camelbert-ca',\n",
    "        'qarib/bert-base-qarib', \n",
    "        'UBC-NLP/ARBERT',\n",
    "        'faisalq/bert-base-arapoembert'\n",
    "]\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        # ds = Dataset.from_pandas(dfx)\n",
    "        # ds = ds.train_test_split(test_size=0.2, seed=i)\n",
    "        \n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=classes_num).to('cuda')                                                 \n",
    "        \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                    \n",
    "        \n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['text'], truncation=True, padding=\"max_length\",\n",
    "                             max_length=max_sequence_length)\n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "        \n",
    "        # Training setup\n",
    "        epochs = 8\n",
    "        save_steps = 10000\n",
    "        batch_size = 64\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs=epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            save_steps=save_steps,\n",
    "            save_total_limit=1,\n",
    "            fp16=True,\n",
    "            learning_rate=5e-5,\n",
    "            logging_steps=200,\n",
    "            evaluation_strategy='steps',\n",
    "            eval_steps=200\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'Accuracy'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('non_classical.csv')\n",
    "display(best_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "307a30c0-b0f1-452d-82d4-ed5c4db0eccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAMeL-Lab/bert-base-arabic-camelbert-ca</td>\n",
       "      <td>0.890009</td>\n",
       "      <td>0.555142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UBC-NLP/ARBERT</td>\n",
       "      <td>0.856191</td>\n",
       "      <td>0.427453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aubmindlab/bert-base-arabert</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.412987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aubmindlab/bert-base-arabertv01</td>\n",
       "      <td>0.860418</td>\n",
       "      <td>0.472605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>faisalq/bert-base-arapoembert</td>\n",
       "      <td>0.912284</td>\n",
       "      <td>0.555195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qarib/bert-base-qarib</td>\n",
       "      <td>0.884887</td>\n",
       "      <td>0.559053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Accuracy        F1\n",
       "0   CAMeL-Lab/bert-base-arabic-camelbert-ca  0.890009  0.555142\n",
       "3                            UBC-NLP/ARBERT  0.856191  0.427453\n",
       "6              aubmindlab/bert-base-arabert  0.849524  0.412987\n",
       "9           aubmindlab/bert-base-arabertv01  0.860418  0.472605\n",
       "10            faisalq/bert-base-arapoembert  0.912284  0.555195\n",
       "13                    qarib/bert-base-qarib  0.884887  0.559053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['Accuracy'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'Accuracy'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('non_classical.csv')\n",
    "display(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9fd3a-da11-415d-9f69-27e33f7dce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b334a-63ed-4bf2-a31c-7b78073be5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18bf7c-5717-4615-8531-eecafd478964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7cc85-d431-483b-9ceb-f0eb0c12f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1a3b1-299f-4d66-a7de-17109f7c37cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
