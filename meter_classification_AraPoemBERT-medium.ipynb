{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12e46f-23c8-4181-9e24-a0276dc12dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy==1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da4c2c-e801-4fa6-8676-c04e551ee88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.12\n",
    "!pip install pyarabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b7f2d-e4a6-4dc1-9a9f-eb0d99dc95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd9b83-c345-489a-ba9d-c27dc601972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c51d229-d74c-4ce9-9910-786a65f81dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd46459-397c-4680-aa71-61f421963385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# cell-1  \n",
    "#load and clean the data (removing diacritics and unwanted text)\n",
    "\n",
    "df = pd.read_csv('poemsDataset.csv')\n",
    "df.fillna('', inplace=True)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "def remove_diacritics(a):    \n",
    "    return araby.strip_diacritics(a)\n",
    "\n",
    "df['first_hemistich'] = df['first_hemistich'].apply(remove_diacritics)\n",
    "df['second_hemistich'] = df['second_hemistich'].apply(remove_diacritics)\n",
    "\n",
    "def normalizeBeforeTraining(df):\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('النابغـة: ', '')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('الـربيع: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('عبيــد: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('امـرؤ القيسـ: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('امرؤ القيس: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(جلال الــــدين الــــرومي):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(لـوك الفيلسـوف الإنكليزي):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(كانت الفيلسوف الألماني ):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(بركســــــــــــــــون):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الحـــــــــــــــور):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الشــــــــــــــاعر):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الإنســـــــــــــــان):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('العلم):', '', regex=False)\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(العشــــــــــــــــق):', '', regex=False)\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الزهــــــــــــــــــرة):', '', regex=False)\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('التوأم اليشكري: ', '', regex=False)  \n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('آ', 'أ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('آ', 'أ')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('[/\":?،؟]', '')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('[/\":?،؟]', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('  ', ' ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('  ', ' ')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('  ', ' ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('  ', ' ')\n",
    "\n",
    "\n",
    "normalizeBeforeTraining(df)\n",
    "df.drop(df[(df['first_hemistich'] == '') & (df['second_hemistich'] == '')].index, inplace=True)\n",
    "\n",
    "#if first_hemistich == '', then copy the text from second_hemistich. then delete the text in the second_hemistich\n",
    "df['first_hemistich'] = df.apply(lambda x: x['second_hemistich'] if x['first_hemistich'] == '' else x['first_hemistich'], axis=1)\n",
    "df['second_hemistich'] = df.apply(lambda x: '' if x['first_hemistich'] == x['second_hemistich'] else x['second_hemistich'], axis=1)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(len(df))\n",
    "# display(df[:10])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e68754b-15f2-4e08-b38a-ea0ccd974d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1480280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "370071"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-2 \n",
    "# preparing data for finetuning\n",
    "\n",
    "\n",
    "df['second_hemistich'].replace('', 'E', inplace=True)\n",
    "dfc = df[['first_hemistich', 'second_hemistich', 'meter', 'link']].copy()\n",
    "dfc['text'] = dfc['first_hemistich'] + ' S ' + dfc['second_hemistich']\n",
    "\n",
    "#removing verses without a meter\n",
    "dfc = dfc[dfc['meter'] != ''] \n",
    "dfc = dfc[dfc['meter'] != 'unspecified']\n",
    "dfc = dfc[dfc['meter'] != 'mixed']\n",
    "\n",
    "\n",
    "nonclassic100 = ['luaihani', 'sakhri', 'hajini', 'kankan', 'zajal'] #5 #meters with >100 verse\n",
    "nonclassic = ['masehube', 'selselah', 'mawalia', 'doubeet', 'colloquial', 'free_form', 'muashah'] #7\n",
    "\n",
    "classic = ['taweel', 'kamel', 'baseet', 'khafif', 'wafer', 'rajaz', 'ramel', 'mutaqarib',\n",
    "           'saree', 'munsarih', 'mujtath', 'hazaj', 'madeed', 'mutadarak', 'muqtadab', 'mudari'] #16\n",
    "\n",
    "\n",
    "#removing non-classical meters (comment to be included in the finetuning process)\n",
    "# dfc = dfc[~dfc['meter'].isin(nonclassic100)]\n",
    "# dfc = dfc[~dfc['meter'].isin(nonclassic)]\n",
    "\n",
    "#including only verses with classical meters\n",
    "dfc = dfc[dfc['meter'].isin(classic)]\n",
    "\n",
    "dfc.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfc['meter'] = dfc['meter'].astype('category')\n",
    "# display(dfc['meter'].unique())\n",
    "\n",
    "dfc['label'] = dfc['meter'].cat.codes #assign cat_value for each meter type\n",
    "dftrain, dftest = train_test_split(dfc, test_size=0.20, random_state=42, stratify=dfc['label'])\n",
    "ytrain = to_categorical(dftrain['label']).astype('int32')\n",
    "ytest = to_categorical(dftest['label']).astype('int32')\n",
    "\n",
    "max_sequence_length = 32\n",
    "train_batch_size = 256\n",
    "classes_num = len(dfc['meter'].unique())\n",
    "\n",
    "display(len(dfc))\n",
    "display(len(dftrain))\n",
    "display(len(dftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae2e7c-370e-407c-a87a-2e61f782f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-3\n",
    "#loading the tokenizer and the model\n",
    "\n",
    "from transformers import AutoTokenizer,TFBertModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('faisalq/bert-medium-arapoembert')\n",
    "bert = TFBertModel.from_pretrained('faisalq/bert-medium-arapoembert', from_pt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd261fd0-0b55-46b6-8f5a-67f213baeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-4\n",
    "#tokenizing the data\n",
    "\n",
    "xtrain = tokenizer(\n",
    "    text=dftrain['text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_sequence_length,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "xtest = tokenizer(\n",
    "    text=dftest['text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_sequence_length,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8e3243-381f-4745-8b60-4f96974f7336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       "array([    2,  2914,   277,   151,  2890,  1110,    83, 31553,  8365,\n",
       "           9, 25033,   122,    85,  4147,  5444,   678,   321, 40125,\n",
       "           3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0], dtype=int32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(xtest)\n",
    "display(xtest['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac648a8-7bf9-40b6-bc13-9f2aeaddf783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  95721216    ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 32,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 16)           12304       ['tf_bert_model[0][1]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 95,733,520\n",
      "Trainable params: 95,733,520\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#cell-5\n",
    "# building classifier model\n",
    "\n",
    "input_ids = Input(shape=(max_sequence_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_sequence_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "output = bert([input_ids, input_mask])[1] #pooled_output\n",
    "output = tf.keras.layers.Dense(classes_num, activation='softmax', name='output')(output)\n",
    "   \n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=output)\n",
    "\n",
    "optimizer = Adam(learning_rate=5e-05)\n",
    "\n",
    "\n",
    "loss =CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy('balanced_accuracy'),\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c8469d-06ca-4f95-8dfc-8d72bc656a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_11387/403206910.py:1: experimental_run_functions_eagerly (from tensorflow.python.eager.polymorphic_function.quarantine) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a65491c-3faf-48ce-9e1a-750781892ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5783/5783 [==============================] - 1277s 221ms/step - loss: 0.0671 - balanced_accuracy: 0.9848 - val_loss: 0.0499 - val_balanced_accuracy: 0.9896\n",
      "Epoch 2/3\n",
      "5783/5783 [==============================] - 1263s 218ms/step - loss: 0.0391 - balanced_accuracy: 0.9922 - val_loss: 0.0608 - val_balanced_accuracy: 0.9880\n",
      "Epoch 3/3\n",
      "5783/5783 [==============================] - 1270s 220ms/step - loss: 0.0303 - balanced_accuracy: 0.9940 - val_loss: 0.0586 - val_balanced_accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "#train the model (classic meters)\n",
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':xtrain['input_ids'],'attention_mask':xtrain['attention_mask']}, y = ytrain,\n",
    "    validation_data = ({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']}, \n",
    "    ytest), epochs=3, batch_size=train_batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c3f32b-4936-4324-b48b-a7f4eb0f03f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11565/11565 [==============================] - 426s 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9961    0.9942    0.9952     53009\n",
      "           1     0.9000    0.8445    0.8714      1833\n",
      "           2     0.9903    0.9914    0.9909     81382\n",
      "           3     0.9922    0.9944    0.9933     34821\n",
      "           4     0.9589    0.9048    0.9311      1755\n",
      "           5     0.5714    0.3333    0.4211        72\n",
      "           6     0.9698    0.9713    0.9706      3871\n",
      "           7     0.9690    0.9784    0.9737      5973\n",
      "           8     0.8908    0.8158    0.8516       190\n",
      "           9     0.9076    0.9480    0.9273      1326\n",
      "          10     0.9897    0.9902    0.9900     13905\n",
      "          11     0.9718    0.9527    0.9622     22267\n",
      "          12     0.9807    0.9876    0.9841     17971\n",
      "          13     0.9634    0.9835    0.9733     12252\n",
      "          14     0.9967    0.9974    0.9970     88553\n",
      "          15     0.9897    0.9915    0.9906     30891\n",
      "\n",
      "   micro avg     0.9888    0.9888    0.9888    370071\n",
      "   macro avg     0.9399    0.9174    0.9265    370071\n",
      "weighted avg     0.9887    0.9888    0.9887    370071\n",
      " samples avg     0.9888    0.9888    0.9888    370071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation (classic meters)\n",
    "\n",
    "pred = model.predict({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']})\n",
    "\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "y_pred = to_categorical(y_pred, num_classes=classes_num).astype('int32')\n",
    "\n",
    "print(classification_report(ytest, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9fd3a-da11-415d-9f69-27e33f7dce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75fa1f45-ca47-499a-be0c-80a552c0539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5975/5975 [==============================] - 1301s 218ms/step - loss: 0.1168 - balanced_accuracy: 0.9712 - val_loss: 0.0948 - val_balanced_accuracy: 0.9770\n",
      "Epoch 2/3\n",
      "5975/5975 [==============================] - 1296s 217ms/step - loss: 0.0737 - balanced_accuracy: 0.9820 - val_loss: 0.0965 - val_balanced_accuracy: 0.9772\n",
      "Epoch 3/3\n",
      "5975/5975 [==============================] - 1297s 217ms/step - loss: 0.0544 - balanced_accuracy: 0.9867 - val_loss: 0.1058 - val_balanced_accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "#train the model (all meters)\n",
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':xtrain['input_ids'],'attention_mask':xtrain['attention_mask']}, y = ytrain,\n",
    "    validation_data = ({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']}, \n",
    "    ytest), epochs=3, batch_size=train_batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "150ba65a-e966-4b63-b3ec-e8f04bb33de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11950/11950 [==============================] - 422s 35ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9932    0.9901    0.9916     53009\n",
      "           1     0.8682    0.6230    0.7254      1480\n",
      "           2     0.9307    0.9148    0.9227       587\n",
      "           3     0.8223    0.8671    0.8441      1686\n",
      "           4     0.0000    0.0000    0.0000        10\n",
      "           5     0.8385    0.8723    0.8551      1833\n",
      "           6     0.9864    0.9914    0.9889     81382\n",
      "           7     0.0000    0.0000    0.0000        12\n",
      "           8     0.9877    0.9927    0.9902     34821\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "          10     0.9499    0.8860    0.9169      1755\n",
      "          11     0.6621    0.5642    0.6092       257\n",
      "          12     0.5766    0.6286    0.6015       377\n",
      "          13     0.7475    0.7018    0.7239      7682\n",
      "          14     0.5652    0.3611    0.4407        72\n",
      "          15     0.9227    0.9646    0.9432      3871\n",
      "          16     0.9749    0.9689    0.9719      5973\n",
      "          17     0.8785    0.8368    0.8571       190\n",
      "          18     0.8918    0.9140    0.9028      1326\n",
      "          19     0.9847    0.9871    0.9859     13905\n",
      "          20     0.9620    0.9471    0.9545     22267\n",
      "          21     0.9452    0.9584    0.9518     17971\n",
      "          22     0.0000    0.0000    0.0000         3\n",
      "          23     0.9564    0.9827    0.9694     12252\n",
      "          24     0.6721    0.4339    0.5273       189\n",
      "          25     0.9961    0.9971    0.9966     88553\n",
      "          26     0.9887    0.9896    0.9891     30891\n",
      "          27     0.0000    0.0000    0.0000        16\n",
      "\n",
      "   micro avg     0.9769    0.9769    0.9769    382371\n",
      "   macro avg     0.7179    0.6919    0.7021    382371\n",
      "weighted avg     0.9764    0.9769    0.9765    382371\n",
      " samples avg     0.9769    0.9769    0.9769    382371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation (all meters)\n",
    "\n",
    "pred = model.predict({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']})\n",
    "\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "y_pred = to_categorical(y_pred, num_classes=classes_num).astype('int32')\n",
    "\n",
    "print(classification_report(ytest, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4547a78-e197-4212-8211-700f28a017c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b334a-63ed-4bf2-a31c-7b78073be5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7339e2-eb16-4e53-b7e8-d61654aa18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# classifier_path = 'finetuned/classic_meters_classifierTF_8L12H.h5'\n",
    "classifier_path = 'finetuned/all_meters_classifierTF_8L12H.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5185399-536e-4687-aa72-093cdcc76c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving finetuned model locally\n",
    "\n",
    "model.save_weights(classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b486d78-e842-4dc6-a06e-11a1414452ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the finetuned model locally\n",
    "# it's necessary to create new model similar to the saved one, then load it\n",
    "\n",
    "from transformers import TFBertModel\n",
    "\n",
    "def create_model():\n",
    "    input_ids = Input(shape=(max_sequence_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "    input_mask = Input(shape=(max_sequence_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    bert = TFBertModel.from_pretrained('faisalq/bert-medium-arapoembert', from_pt=True)\n",
    "    \n",
    "    output = bert([input_ids, input_mask])[1] #pooled_output\n",
    "    output = tf.keras.layers.Dense(classes_num, activation='softmax', name='output')(output)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=output)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=5e-05)\n",
    "     \n",
    "    loss =CategoricalCrossentropy(from_logits = True)\n",
    "    metric = CategoricalAccuracy('balanced_accuracy'),\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d068da-ad12-4531-b7fa-7a0d3029c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "\n",
    "pred = model.predict({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']})\n",
    "\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "y_pred = to_categorical(y_pred, num_classes=classes_num).astype('int32')\n",
    "\n",
    "print(classification_report(ytest, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c865f-e42d-4977-a783-58ebdebb7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# further finetuning the model\n",
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':xtrain['input_ids'],'attention_mask':xtrain['attention_mask']}, y = ytrain,\n",
    "    validation_data = ({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']}, \n",
    "    ytest), epochs=3, batch_size=train_batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7cc85-d431-483b-9ceb-f0eb0c12f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1de169-cbd8-4f8e-b172-61a5eb8aa60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
