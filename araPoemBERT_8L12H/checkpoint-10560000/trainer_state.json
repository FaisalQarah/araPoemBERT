{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1292.8501469147893,
  "global_step": 10560000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06,
      "learning_rate": 4.6957639569049954e-05,
      "loss": 7.6268,
      "step": 500
    },
    {
      "epoch": 0.12,
      "learning_rate": 4.389691478942214e-05,
      "loss": 7.4511,
      "step": 1000
    },
    {
      "epoch": 0.18,
      "learning_rate": 4.083619000979432e-05,
      "loss": 7.3364,
      "step": 1500
    },
    {
      "epoch": 0.24,
      "learning_rate": 3.777546523016651e-05,
      "loss": 7.2369,
      "step": 2000
    },
    {
      "epoch": 0.31,
      "learning_rate": 3.471474045053869e-05,
      "loss": 7.1406,
      "step": 2500
    },
    {
      "epoch": 0.61,
      "learning_rate": 4.9938822233104806e-05,
      "loss": 6.9325,
      "step": 5000
    },
    {
      "epoch": 1.22,
      "learning_rate": 4.987760773751224e-05,
      "loss": 6.5944,
      "step": 10000
    },
    {
      "epoch": 1.84,
      "learning_rate": 4.9816429970617045e-05,
      "loss": 6.2665,
      "step": 15000
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.9755239960822724e-05,
      "loss": 5.9899,
      "step": 20000
    },
    {
      "epoch": 3.06,
      "learning_rate": 4.96940499510284e-05,
      "loss": 5.754,
      "step": 25000
    },
    {
      "epoch": 3.67,
      "learning_rate": 4.9632872184133206e-05,
      "loss": 5.5283,
      "step": 30000
    },
    {
      "epoch": 4.29,
      "learning_rate": 4.9571682174338885e-05,
      "loss": 5.3393,
      "step": 35000
    },
    {
      "epoch": 4.9,
      "learning_rate": 4.951050440744369e-05,
      "loss": 5.173,
      "step": 40000
    },
    {
      "epoch": 5.51,
      "learning_rate": 4.944931439764937e-05,
      "loss": 5.0114,
      "step": 45000
    },
    {
      "epoch": 6.12,
      "learning_rate": 4.9388124387855046e-05,
      "loss": 4.8914,
      "step": 50000
    },
    {
      "epoch": 6.73,
      "learning_rate": 4.932692213516161e-05,
      "loss": 4.7799,
      "step": 55000
    },
    {
      "epoch": 7.35,
      "learning_rate": 4.926574436826641e-05,
      "loss": 4.6842,
      "step": 60000
    },
    {
      "epoch": 7.96,
      "learning_rate": 4.920454211557297e-05,
      "loss": 4.6061,
      "step": 65000
    },
    {
      "epoch": 8.57,
      "learning_rate": 4.914335210577865e-05,
      "loss": 4.5167,
      "step": 70000
    },
    {
      "epoch": 9.18,
      "learning_rate": 4.908216209598433e-05,
      "loss": 4.4615,
      "step": 75000
    },
    {
      "epoch": 9.79,
      "learning_rate": 4.9020972086190014e-05,
      "loss": 4.3973,
      "step": 80000
    },
    {
      "epoch": 10.41,
      "learning_rate": 4.895978207639569e-05,
      "loss": 4.3381,
      "step": 85000
    },
    {
      "epoch": 11.02,
      "learning_rate": 4.889859206660137e-05,
      "loss": 4.3053,
      "step": 90000
    },
    {
      "epoch": 11.63,
      "learning_rate": 4.883740205680705e-05,
      "loss": 4.247,
      "step": 95000
    },
    {
      "epoch": 12.24,
      "learning_rate": 4.877619980411362e-05,
      "loss": 4.2122,
      "step": 100000
    },
    {
      "epoch": 12.86,
      "learning_rate": 4.8715022037218415e-05,
      "loss": 4.1751,
      "step": 105000
    },
    {
      "epoch": 13.47,
      "learning_rate": 4.8653832027424093e-05,
      "loss": 4.1289,
      "step": 110000
    },
    {
      "epoch": 14.08,
      "learning_rate": 4.859264201762977e-05,
      "loss": 4.1101,
      "step": 115000
    },
    {
      "epoch": 14.69,
      "learning_rate": 4.853143976493634e-05,
      "loss": 4.073,
      "step": 120000
    },
    {
      "epoch": 15.3,
      "learning_rate": 4.8470261998041136e-05,
      "loss": 4.0398,
      "step": 125000
    },
    {
      "epoch": 15.92,
      "learning_rate": 4.840908423114594e-05,
      "loss": 4.0249,
      "step": 130000
    },
    {
      "epoch": 16.53,
      "learning_rate": 4.8347881978452494e-05,
      "loss": 3.9896,
      "step": 135000
    },
    {
      "epoch": 17.14,
      "learning_rate": 4.828669196865818e-05,
      "loss": 3.9719,
      "step": 140000
    },
    {
      "epoch": 17.75,
      "learning_rate": 4.8225514201762976e-05,
      "loss": 3.9436,
      "step": 145000
    },
    {
      "epoch": 18.36,
      "learning_rate": 4.8164311949069544e-05,
      "loss": 3.9192,
      "step": 150000
    },
    {
      "epoch": 18.98,
      "learning_rate": 4.810313418217434e-05,
      "loss": 3.9118,
      "step": 155000
    },
    {
      "epoch": 19.59,
      "learning_rate": 4.804194417238002e-05,
      "loss": 3.8691,
      "step": 160000
    },
    {
      "epoch": 20.2,
      "learning_rate": 4.79807541625857e-05,
      "loss": 3.8624,
      "step": 165000
    },
    {
      "epoch": 20.81,
      "learning_rate": 4.79195763956905e-05,
      "loss": 3.8433,
      "step": 170000
    },
    {
      "epoch": 21.43,
      "learning_rate": 4.785838638589618e-05,
      "loss": 3.823,
      "step": 175000
    },
    {
      "epoch": 22.04,
      "learning_rate": 4.7797196376101866e-05,
      "loss": 3.8167,
      "step": 180000
    },
    {
      "epoch": 22.65,
      "learning_rate": 4.773601860920666e-05,
      "loss": 3.7873,
      "step": 185000
    },
    {
      "epoch": 23.26,
      "learning_rate": 4.767482859941234e-05,
      "loss": 3.7677,
      "step": 190000
    },
    {
      "epoch": 23.87,
      "learning_rate": 4.761363858961803e-05,
      "loss": 3.7629,
      "step": 195000
    },
    {
      "epoch": 24.49,
      "learning_rate": 4.7552448579823706e-05,
      "loss": 3.7381,
      "step": 200000
    },
    {
      "epoch": 25.1,
      "learning_rate": 4.7491258570029384e-05,
      "loss": 3.736,
      "step": 205000
    },
    {
      "epoch": 25.71,
      "learning_rate": 4.743006856023506e-05,
      "loss": 3.7109,
      "step": 210000
    },
    {
      "epoch": 26.32,
      "learning_rate": 4.736887855044075e-05,
      "loss": 3.6978,
      "step": 215000
    },
    {
      "epoch": 26.93,
      "learning_rate": 4.730767629774731e-05,
      "loss": 3.6983,
      "step": 220000
    },
    {
      "epoch": 27.55,
      "learning_rate": 4.724648628795299e-05,
      "loss": 3.6678,
      "step": 225000
    },
    {
      "epoch": 28.16,
      "learning_rate": 4.718529627815867e-05,
      "loss": 3.6666,
      "step": 230000
    },
    {
      "epoch": 28.77,
      "learning_rate": 4.712413075416259e-05,
      "loss": 3.6487,
      "step": 235000
    },
    {
      "epoch": 29.38,
      "learning_rate": 4.706291625857003e-05,
      "loss": 3.6368,
      "step": 240000
    },
    {
      "epoch": 30.0,
      "learning_rate": 4.700172624877571e-05,
      "loss": 3.6388,
      "step": 245000
    },
    {
      "epoch": 30.61,
      "learning_rate": 4.694056072477963e-05,
      "loss": 3.6068,
      "step": 250000
    },
    {
      "epoch": 31.22,
      "learning_rate": 4.6879346229187074e-05,
      "loss": 3.604,
      "step": 255000
    },
    {
      "epoch": 31.83,
      "learning_rate": 4.681816846229187e-05,
      "loss": 3.5989,
      "step": 260000
    },
    {
      "epoch": 32.44,
      "learning_rate": 4.675696620959844e-05,
      "loss": 3.5767,
      "step": 265000
    },
    {
      "epoch": 33.06,
      "learning_rate": 4.669577619980412e-05,
      "loss": 3.584,
      "step": 270000
    },
    {
      "epoch": 33.67,
      "learning_rate": 4.6634586190009796e-05,
      "loss": 3.5553,
      "step": 275000
    },
    {
      "epoch": 34.28,
      "learning_rate": 4.657339618021548e-05,
      "loss": 3.5502,
      "step": 280000
    },
    {
      "epoch": 34.89,
      "learning_rate": 4.651221841332027e-05,
      "loss": 3.5498,
      "step": 285000
    },
    {
      "epoch": 35.5,
      "learning_rate": 4.645101616062684e-05,
      "loss": 3.5242,
      "step": 290000
    },
    {
      "epoch": 36.12,
      "learning_rate": 4.63898139079334e-05,
      "loss": 3.5266,
      "step": 295000
    },
    {
      "epoch": 36.73,
      "learning_rate": 4.6328623898139085e-05,
      "loss": 3.5095,
      "step": 300000
    },
    {
      "epoch": 37.34,
      "learning_rate": 4.6267433888344764e-05,
      "loss": 3.5008,
      "step": 305000
    },
    {
      "epoch": 37.95,
      "learning_rate": 4.6206231635651325e-05,
      "loss": 3.503,
      "step": 310000
    },
    {
      "epoch": 38.57,
      "learning_rate": 4.6145041625857003e-05,
      "loss": 3.4797,
      "step": 315000
    },
    {
      "epoch": 39.18,
      "learning_rate": 4.608385161606268e-05,
      "loss": 3.48,
      "step": 320000
    },
    {
      "epoch": 39.79,
      "learning_rate": 4.6022673849167486e-05,
      "loss": 3.4679,
      "step": 325000
    },
    {
      "epoch": 40.4,
      "learning_rate": 4.5961483839373164e-05,
      "loss": 3.4604,
      "step": 330000
    },
    {
      "epoch": 41.01,
      "learning_rate": 4.590029382957884e-05,
      "loss": 3.4657,
      "step": 335000
    },
    {
      "epoch": 41.63,
      "learning_rate": 4.583911606268365e-05,
      "loss": 3.4412,
      "step": 340000
    },
    {
      "epoch": 42.24,
      "learning_rate": 4.577790156709109e-05,
      "loss": 3.443,
      "step": 345000
    },
    {
      "epoch": 42.85,
      "learning_rate": 4.571671155729677e-05,
      "loss": 3.4364,
      "step": 350000
    },
    {
      "epoch": 43.46,
      "learning_rate": 4.5655509304603336e-05,
      "loss": 3.4224,
      "step": 355000
    },
    {
      "epoch": 44.07,
      "learning_rate": 4.559434378060725e-05,
      "loss": 3.4201,
      "step": 360000
    },
    {
      "epoch": 44.69,
      "learning_rate": 4.553314152791381e-05,
      "loss": 3.4015,
      "step": 365000
    },
    {
      "epoch": 45.3,
      "learning_rate": 4.547193927522038e-05,
      "loss": 3.4001,
      "step": 370000
    },
    {
      "epoch": 45.91,
      "learning_rate": 4.541073702252694e-05,
      "loss": 3.4021,
      "step": 375000
    },
    {
      "epoch": 46.52,
      "learning_rate": 4.5349571498530854e-05,
      "loss": 3.3773,
      "step": 380000
    },
    {
      "epoch": 47.14,
      "learning_rate": 4.52883570029383e-05,
      "loss": 3.386,
      "step": 385000
    },
    {
      "epoch": 47.75,
      "learning_rate": 4.522719147894222e-05,
      "loss": 3.3686,
      "step": 390000
    },
    {
      "epoch": 48.36,
      "learning_rate": 4.516597698334966e-05,
      "loss": 3.3645,
      "step": 395000
    },
    {
      "epoch": 48.97,
      "learning_rate": 4.510481145935358e-05,
      "loss": 3.3698,
      "step": 400000
    },
    {
      "epoch": 49.58,
      "learning_rate": 4.504360920666014e-05,
      "loss": 3.3418,
      "step": 405000
    },
    {
      "epoch": 50.2,
      "learning_rate": 4.498239471106758e-05,
      "loss": 3.349,
      "step": 410000
    },
    {
      "epoch": 50.81,
      "learning_rate": 4.492121694417238e-05,
      "loss": 3.3355,
      "step": 415000
    },
    {
      "epoch": 51.42,
      "learning_rate": 4.486002693437806e-05,
      "loss": 3.3304,
      "step": 420000
    },
    {
      "epoch": 52.03,
      "learning_rate": 4.479883692458374e-05,
      "loss": 3.3388,
      "step": 425000
    },
    {
      "epoch": 52.64,
      "learning_rate": 4.473764691478942e-05,
      "loss": 3.3136,
      "step": 430000
    },
    {
      "epoch": 53.26,
      "learning_rate": 4.4676456904995105e-05,
      "loss": 3.3122,
      "step": 435000
    },
    {
      "epoch": 53.87,
      "learning_rate": 4.461525465230167e-05,
      "loss": 3.3156,
      "step": 440000
    },
    {
      "epoch": 54.48,
      "learning_rate": 4.455408912830559e-05,
      "loss": 3.3006,
      "step": 445000
    },
    {
      "epoch": 55.09,
      "learning_rate": 4.449288687561215e-05,
      "loss": 3.3069,
      "step": 450000
    },
    {
      "epoch": 55.71,
      "learning_rate": 4.4431696865817827e-05,
      "loss": 3.2866,
      "step": 455000
    },
    {
      "epoch": 56.32,
      "learning_rate": 4.437051909892262e-05,
      "loss": 3.2873,
      "step": 460000
    },
    {
      "epoch": 56.93,
      "learning_rate": 4.430932908912831e-05,
      "loss": 3.2858,
      "step": 465000
    },
    {
      "epoch": 57.54,
      "learning_rate": 4.424812683643487e-05,
      "loss": 3.2651,
      "step": 470000
    },
    {
      "epoch": 58.15,
      "learning_rate": 4.4186949069539666e-05,
      "loss": 3.2757,
      "step": 475000
    },
    {
      "epoch": 58.77,
      "learning_rate": 4.4125746816846234e-05,
      "loss": 3.2636,
      "step": 480000
    },
    {
      "epoch": 59.38,
      "learning_rate": 4.406455680705191e-05,
      "loss": 3.2584,
      "step": 485000
    },
    {
      "epoch": 59.99,
      "learning_rate": 4.400337904015671e-05,
      "loss": 3.2634,
      "step": 490000
    },
    {
      "epoch": 60.6,
      "learning_rate": 4.394218903036239e-05,
      "loss": 3.234,
      "step": 495000
    },
    {
      "epoch": 61.21,
      "learning_rate": 4.388099902056807e-05,
      "loss": 3.2458,
      "step": 500000
    },
    {
      "epoch": 61.83,
      "learning_rate": 4.3819784524975516e-05,
      "loss": 3.2423,
      "step": 505000
    },
    {
      "epoch": 62.44,
      "learning_rate": 4.3758594515181195e-05,
      "loss": 3.2275,
      "step": 510000
    },
    {
      "epoch": 63.05,
      "learning_rate": 4.369740450538688e-05,
      "loss": 3.2355,
      "step": 515000
    },
    {
      "epoch": 63.66,
      "learning_rate": 4.363620225269344e-05,
      "loss": 3.2193,
      "step": 520000
    },
    {
      "epoch": 64.28,
      "learning_rate": 4.357502448579824e-05,
      "loss": 3.2168,
      "step": 525000
    },
    {
      "epoch": 64.89,
      "learning_rate": 4.351383447600392e-05,
      "loss": 3.2204,
      "step": 530000
    },
    {
      "epoch": 65.5,
      "learning_rate": 4.345263222331048e-05,
      "loss": 3.202,
      "step": 535000
    },
    {
      "epoch": 66.11,
      "learning_rate": 4.339144221351616e-05,
      "loss": 3.2131,
      "step": 540000
    },
    {
      "epoch": 66.72,
      "learning_rate": 4.333025220372184e-05,
      "loss": 3.1924,
      "step": 545000
    },
    {
      "epoch": 67.34,
      "learning_rate": 4.326906219392752e-05,
      "loss": 3.1951,
      "step": 550000
    },
    {
      "epoch": 67.95,
      "learning_rate": 4.320784769833497e-05,
      "loss": 3.1989,
      "step": 555000
    },
    {
      "epoch": 68.56,
      "learning_rate": 4.314666993143977e-05,
      "loss": 3.1788,
      "step": 560000
    },
    {
      "epoch": 69.17,
      "learning_rate": 4.308547992164545e-05,
      "loss": 3.188,
      "step": 565000
    },
    {
      "epoch": 69.78,
      "learning_rate": 4.302427766895201e-05,
      "loss": 3.1751,
      "step": 570000
    },
    {
      "epoch": 70.4,
      "learning_rate": 4.2963075416258574e-05,
      "loss": 3.1675,
      "step": 575000
    },
    {
      "epoch": 71.01,
      "learning_rate": 4.290188540646425e-05,
      "loss": 3.1789,
      "step": 580000
    },
    {
      "epoch": 71.62,
      "learning_rate": 4.284069539666993e-05,
      "loss": 3.1507,
      "step": 585000
    },
    {
      "epoch": 72.23,
      "learning_rate": 4.277950538687561e-05,
      "loss": 3.1662,
      "step": 590000
    },
    {
      "epoch": 72.85,
      "learning_rate": 4.2718315377081296e-05,
      "loss": 3.1574,
      "step": 595000
    },
    {
      "epoch": 73.46,
      "learning_rate": 4.2657125367286974e-05,
      "loss": 3.1465,
      "step": 600000
    },
    {
      "epoch": 74.07,
      "learning_rate": 4.259593535749265e-05,
      "loss": 3.161,
      "step": 605000
    },
    {
      "epoch": 74.68,
      "learning_rate": 4.253473310479922e-05,
      "loss": 3.1368,
      "step": 610000
    },
    {
      "epoch": 75.29,
      "learning_rate": 4.24735430950049e-05,
      "loss": 3.1377,
      "step": 615000
    },
    {
      "epoch": 75.91,
      "learning_rate": 4.241234084231146e-05,
      "loss": 3.144,
      "step": 620000
    },
    {
      "epoch": 76.52,
      "learning_rate": 4.2351150832517146e-05,
      "loss": 3.1246,
      "step": 625000
    },
    {
      "epoch": 77.13,
      "learning_rate": 4.228998530852106e-05,
      "loss": 3.1299,
      "step": 630000
    },
    {
      "epoch": 77.74,
      "learning_rate": 4.22287708129285e-05,
      "loss": 3.1199,
      "step": 635000
    },
    {
      "epoch": 78.35,
      "learning_rate": 4.216758080313418e-05,
      "loss": 3.1165,
      "step": 640000
    },
    {
      "epoch": 78.97,
      "learning_rate": 4.210639079333987e-05,
      "loss": 3.1267,
      "step": 645000
    },
    {
      "epoch": 79.58,
      "learning_rate": 4.204518854064643e-05,
      "loss": 3.1023,
      "step": 650000
    },
    {
      "epoch": 80.19,
      "learning_rate": 4.1984010773751225e-05,
      "loss": 3.1096,
      "step": 655000
    },
    {
      "epoch": 80.8,
      "learning_rate": 4.1922808521057786e-05,
      "loss": 3.1092,
      "step": 660000
    },
    {
      "epoch": 81.42,
      "learning_rate": 4.1861618511263464e-05,
      "loss": 3.0979,
      "step": 665000
    },
    {
      "epoch": 82.03,
      "learning_rate": 4.1800404015670914e-05,
      "loss": 3.1092,
      "step": 670000
    },
    {
      "epoch": 82.64,
      "learning_rate": 4.173923849167483e-05,
      "loss": 3.0854,
      "step": 675000
    },
    {
      "epoch": 83.25,
      "learning_rate": 4.167804848188051e-05,
      "loss": 3.0928,
      "step": 680000
    },
    {
      "epoch": 83.86,
      "learning_rate": 4.1616846229187075e-05,
      "loss": 3.0871,
      "step": 685000
    },
    {
      "epoch": 84.48,
      "learning_rate": 4.1555656219392754e-05,
      "loss": 3.0747,
      "step": 690000
    },
    {
      "epoch": 85.09,
      "learning_rate": 4.1494453966699314e-05,
      "loss": 3.0877,
      "step": 695000
    },
    {
      "epoch": 85.7,
      "learning_rate": 4.1433251714005875e-05,
      "loss": 3.0709,
      "step": 700000
    },
    {
      "epoch": 86.31,
      "learning_rate": 4.1372061704211554e-05,
      "loss": 3.0678,
      "step": 705000
    },
    {
      "epoch": 86.92,
      "learning_rate": 4.131087169441724e-05,
      "loss": 3.0727,
      "step": 710000
    },
    {
      "epoch": 87.54,
      "learning_rate": 4.124966944172381e-05,
      "loss": 3.0567,
      "step": 715000
    },
    {
      "epoch": 88.15,
      "learning_rate": 4.1188479431929486e-05,
      "loss": 3.067,
      "step": 720000
    },
    {
      "epoch": 88.76,
      "learning_rate": 4.1127289422135164e-05,
      "loss": 3.0568,
      "step": 725000
    },
    {
      "epoch": 89.37,
      "learning_rate": 4.106607492654261e-05,
      "loss": 3.0514,
      "step": 730000
    },
    {
      "epoch": 89.99,
      "learning_rate": 4.1004897159647404e-05,
      "loss": 3.061,
      "step": 735000
    },
    {
      "epoch": 90.6,
      "learning_rate": 4.094370714985309e-05,
      "loss": 3.04,
      "step": 740000
    },
    {
      "epoch": 91.21,
      "learning_rate": 4.088251714005877e-05,
      "loss": 3.0481,
      "step": 745000
    },
    {
      "epoch": 91.82,
      "learning_rate": 4.082131488736533e-05,
      "loss": 3.0449,
      "step": 750000
    },
    {
      "epoch": 92.43,
      "learning_rate": 4.076011263467189e-05,
      "loss": 3.0338,
      "step": 755000
    },
    {
      "epoch": 93.05,
      "learning_rate": 4.069891038197846e-05,
      "loss": 3.0452,
      "step": 760000
    },
    {
      "epoch": 93.66,
      "learning_rate": 4.0637720372184136e-05,
      "loss": 3.0227,
      "step": 765000
    },
    {
      "epoch": 94.27,
      "learning_rate": 4.0576530362389815e-05,
      "loss": 3.0303,
      "step": 770000
    },
    {
      "epoch": 94.88,
      "learning_rate": 4.051535259549462e-05,
      "loss": 3.0262,
      "step": 775000
    },
    {
      "epoch": 95.49,
      "learning_rate": 4.045415034280118e-05,
      "loss": 3.0139,
      "step": 780000
    },
    {
      "epoch": 96.11,
      "learning_rate": 4.039296033300686e-05,
      "loss": 3.0203,
      "step": 785000
    },
    {
      "epoch": 96.72,
      "learning_rate": 4.033175808031342e-05,
      "loss": 3.0105,
      "step": 790000
    },
    {
      "epoch": 97.33,
      "learning_rate": 4.027058031341822e-05,
      "loss": 3.0114,
      "step": 795000
    },
    {
      "epoch": 97.94,
      "learning_rate": 4.02093903036239e-05,
      "loss": 3.0155,
      "step": 800000
    },
    {
      "epoch": 98.56,
      "learning_rate": 4.014818805093046e-05,
      "loss": 2.9997,
      "step": 805000
    },
    {
      "epoch": 99.17,
      "learning_rate": 4.008702252693438e-05,
      "loss": 3.0063,
      "step": 810000
    },
    {
      "epoch": 99.78,
      "learning_rate": 4.0025820274240944e-05,
      "loss": 2.9999,
      "step": 815000
    },
    {
      "epoch": 100.39,
      "learning_rate": 3.9964618021547505e-05,
      "loss": 2.991,
      "step": 820000
    },
    {
      "epoch": 101.0,
      "learning_rate": 3.990341576885407e-05,
      "loss": 3.0022,
      "step": 825000
    },
    {
      "epoch": 101.62,
      "learning_rate": 3.984223800195886e-05,
      "loss": 2.9835,
      "step": 830000
    },
    {
      "epoch": 102.23,
      "learning_rate": 3.978102350636631e-05,
      "loss": 2.9929,
      "step": 835000
    },
    {
      "epoch": 102.84,
      "learning_rate": 3.971983349657199e-05,
      "loss": 2.9909,
      "step": 840000
    },
    {
      "epoch": 103.45,
      "learning_rate": 3.965864348677767e-05,
      "loss": 2.9775,
      "step": 845000
    },
    {
      "epoch": 104.06,
      "learning_rate": 3.9597453476983355e-05,
      "loss": 2.9848,
      "step": 850000
    },
    {
      "epoch": 104.68,
      "learning_rate": 3.95362389813908e-05,
      "loss": 2.9731,
      "step": 855000
    },
    {
      "epoch": 105.29,
      "learning_rate": 3.9475061214495594e-05,
      "loss": 2.9721,
      "step": 860000
    },
    {
      "epoch": 105.9,
      "learning_rate": 3.941388344760039e-05,
      "loss": 2.9775,
      "step": 865000
    },
    {
      "epoch": 106.51,
      "learning_rate": 3.935268119490695e-05,
      "loss": 2.9597,
      "step": 870000
    },
    {
      "epoch": 107.13,
      "learning_rate": 3.929149118511264e-05,
      "loss": 2.9668,
      "step": 875000
    },
    {
      "epoch": 107.74,
      "learning_rate": 3.9230288932419205e-05,
      "loss": 2.9574,
      "step": 880000
    },
    {
      "epoch": 108.35,
      "learning_rate": 3.916909892262488e-05,
      "loss": 2.9586,
      "step": 885000
    },
    {
      "epoch": 108.96,
      "learning_rate": 3.910790891283056e-05,
      "loss": 2.9667,
      "step": 890000
    },
    {
      "epoch": 109.57,
      "learning_rate": 3.904673114593536e-05,
      "loss": 2.9461,
      "step": 895000
    },
    {
      "epoch": 110.19,
      "learning_rate": 3.898554113614104e-05,
      "loss": 2.955,
      "step": 900000
    },
    {
      "epoch": 110.8,
      "learning_rate": 3.892435112634672e-05,
      "loss": 2.9486,
      "step": 905000
    },
    {
      "epoch": 111.41,
      "learning_rate": 3.886317335945152e-05,
      "loss": 2.9354,
      "step": 910000
    },
    {
      "epoch": 112.02,
      "learning_rate": 3.880197110675808e-05,
      "loss": 2.9536,
      "step": 915000
    },
    {
      "epoch": 112.63,
      "learning_rate": 3.874076885406465e-05,
      "loss": 2.9344,
      "step": 920000
    },
    {
      "epoch": 113.25,
      "learning_rate": 3.867956660137121e-05,
      "loss": 2.939,
      "step": 925000
    },
    {
      "epoch": 113.86,
      "learning_rate": 3.861836434867777e-05,
      "loss": 2.9407,
      "step": 930000
    },
    {
      "epoch": 114.47,
      "learning_rate": 3.855717433888345e-05,
      "loss": 2.9274,
      "step": 935000
    },
    {
      "epoch": 115.08,
      "learning_rate": 3.849598432908913e-05,
      "loss": 2.9361,
      "step": 940000
    },
    {
      "epoch": 115.7,
      "learning_rate": 3.843481880509305e-05,
      "loss": 2.9284,
      "step": 945000
    },
    {
      "epoch": 116.31,
      "learning_rate": 3.837361655239961e-05,
      "loss": 2.9242,
      "step": 950000
    },
    {
      "epoch": 116.92,
      "learning_rate": 3.831241429970617e-05,
      "loss": 2.9274,
      "step": 955000
    },
    {
      "epoch": 117.53,
      "learning_rate": 3.825121204701274e-05,
      "loss": 2.908,
      "step": 960000
    },
    {
      "epoch": 118.14,
      "learning_rate": 3.8190022037218416e-05,
      "loss": 2.9202,
      "step": 965000
    },
    {
      "epoch": 118.76,
      "learning_rate": 3.8128832027424095e-05,
      "loss": 2.9128,
      "step": 970000
    },
    {
      "epoch": 119.37,
      "learning_rate": 3.80676542605289e-05,
      "loss": 2.9079,
      "step": 975000
    },
    {
      "epoch": 119.98,
      "learning_rate": 3.800646425073458e-05,
      "loss": 2.9188,
      "step": 980000
    },
    {
      "epoch": 120.59,
      "learning_rate": 3.794524975514202e-05,
      "loss": 2.8946,
      "step": 985000
    },
    {
      "epoch": 121.2,
      "learning_rate": 3.788407198824682e-05,
      "loss": 2.9075,
      "step": 990000
    },
    {
      "epoch": 121.82,
      "learning_rate": 3.782289422135162e-05,
      "loss": 2.9022,
      "step": 995000
    },
    {
      "epoch": 122.43,
      "learning_rate": 3.77617042115573e-05,
      "loss": 2.8931,
      "step": 1000000
    },
    {
      "epoch": 123.04,
      "learning_rate": 3.7700514201762985e-05,
      "loss": 2.9076,
      "step": 1005000
    },
    {
      "epoch": 123.65,
      "learning_rate": 3.763931194906954e-05,
      "loss": 2.8868,
      "step": 1010000
    },
    {
      "epoch": 124.27,
      "learning_rate": 3.757809745347698e-05,
      "loss": 2.8907,
      "step": 1015000
    },
    {
      "epoch": 124.88,
      "learning_rate": 3.751690744368267e-05,
      "loss": 2.8912,
      "step": 1020000
    },
    {
      "epoch": 125.49,
      "learning_rate": 3.745570519098923e-05,
      "loss": 2.8773,
      "step": 1025000
    },
    {
      "epoch": 126.1,
      "learning_rate": 3.739452742409403e-05,
      "loss": 2.8909,
      "step": 1030000
    },
    {
      "epoch": 126.71,
      "learning_rate": 3.733333741429971e-05,
      "loss": 2.881,
      "step": 1035000
    },
    {
      "epoch": 127.33,
      "learning_rate": 3.727213516160627e-05,
      "loss": 2.8784,
      "step": 1040000
    },
    {
      "epoch": 127.94,
      "learning_rate": 3.721094515181195e-05,
      "loss": 2.8878,
      "step": 1045000
    },
    {
      "epoch": 128.55,
      "learning_rate": 3.714974289911851e-05,
      "loss": 2.8688,
      "step": 1050000
    },
    {
      "epoch": 129.16,
      "learning_rate": 3.708857737512243e-05,
      "loss": 2.8789,
      "step": 1055000
    },
    {
      "epoch": 129.77,
      "learning_rate": 3.702737512242899e-05,
      "loss": 2.8712,
      "step": 1060000
    },
    {
      "epoch": 130.39,
      "learning_rate": 3.696617286973555e-05,
      "loss": 2.861,
      "step": 1065000
    },
    {
      "epoch": 131.0,
      "learning_rate": 3.6905007345739475e-05,
      "loss": 2.8771,
      "step": 1070000
    },
    {
      "epoch": 131.61,
      "learning_rate": 3.684379285014692e-05,
      "loss": 2.8503,
      "step": 1075000
    },
    {
      "epoch": 132.22,
      "learning_rate": 3.6782602840352596e-05,
      "loss": 2.865,
      "step": 1080000
    },
    {
      "epoch": 132.84,
      "learning_rate": 3.6721400587659164e-05,
      "loss": 2.8587,
      "step": 1085000
    },
    {
      "epoch": 133.45,
      "learning_rate": 3.6660198334965724e-05,
      "loss": 2.8523,
      "step": 1090000
    },
    {
      "epoch": 134.06,
      "learning_rate": 3.659904505386876e-05,
      "loss": 2.8649,
      "step": 1095000
    },
    {
      "epoch": 134.67,
      "learning_rate": 3.653784280117532e-05,
      "loss": 2.8457,
      "step": 1100000
    },
    {
      "epoch": 135.28,
      "learning_rate": 3.6476640548481886e-05,
      "loss": 2.8505,
      "step": 1105000
    },
    {
      "epoch": 135.9,
      "learning_rate": 3.641542605288932e-05,
      "loss": 2.8521,
      "step": 1110000
    },
    {
      "epoch": 136.51,
      "learning_rate": 3.6354248285994125e-05,
      "loss": 2.8346,
      "step": 1115000
    },
    {
      "epoch": 137.12,
      "learning_rate": 3.6293058276199804e-05,
      "loss": 2.848,
      "step": 1120000
    },
    {
      "epoch": 137.73,
      "learning_rate": 3.623188050930461e-05,
      "loss": 2.8383,
      "step": 1125000
    },
    {
      "epoch": 138.34,
      "learning_rate": 3.617067825661117e-05,
      "loss": 2.8385,
      "step": 1130000
    },
    {
      "epoch": 138.96,
      "learning_rate": 3.610946376101861e-05,
      "loss": 2.8442,
      "step": 1135000
    },
    {
      "epoch": 139.57,
      "learning_rate": 3.604828599412341e-05,
      "loss": 2.8241,
      "step": 1140000
    },
    {
      "epoch": 140.18,
      "learning_rate": 3.5987095984329086e-05,
      "loss": 2.8362,
      "step": 1145000
    },
    {
      "epoch": 140.79,
      "learning_rate": 3.5925893731635654e-05,
      "loss": 2.8299,
      "step": 1150000
    },
    {
      "epoch": 141.41,
      "learning_rate": 3.586471596474045e-05,
      "loss": 2.826,
      "step": 1155000
    },
    {
      "epoch": 142.02,
      "learning_rate": 3.580351371204702e-05,
      "loss": 2.8323,
      "step": 1160000
    },
    {
      "epoch": 142.63,
      "learning_rate": 3.57423237022527e-05,
      "loss": 2.8126,
      "step": 1165000
    },
    {
      "epoch": 143.24,
      "learning_rate": 3.568112144955926e-05,
      "loss": 2.8242,
      "step": 1170000
    },
    {
      "epoch": 143.85,
      "learning_rate": 3.561994368266406e-05,
      "loss": 2.8248,
      "step": 1175000
    },
    {
      "epoch": 144.47,
      "learning_rate": 3.555875367286974e-05,
      "loss": 2.8129,
      "step": 1180000
    },
    {
      "epoch": 145.08,
      "learning_rate": 3.54975514201763e-05,
      "loss": 2.8238,
      "step": 1185000
    },
    {
      "epoch": 145.69,
      "learning_rate": 3.54363736532811e-05,
      "loss": 2.8042,
      "step": 1190000
    },
    {
      "epoch": 146.3,
      "learning_rate": 3.537517140058766e-05,
      "loss": 2.8116,
      "step": 1195000
    },
    {
      "epoch": 146.91,
      "learning_rate": 3.5313981390793344e-05,
      "loss": 2.8171,
      "step": 1200000
    },
    {
      "epoch": 147.53,
      "learning_rate": 3.525285259549461e-05,
      "loss": 2.8204,
      "step": 1205000
    },
    {
      "epoch": 148.14,
      "learning_rate": 3.51916625857003e-05,
      "loss": 2.8181,
      "step": 1210000
    },
    {
      "epoch": 148.75,
      "learning_rate": 3.5130472575905977e-05,
      "loss": 2.8174,
      "step": 1215000
    },
    {
      "epoch": 149.36,
      "learning_rate": 3.506925808031342e-05,
      "loss": 2.8056,
      "step": 1220000
    },
    {
      "epoch": 149.98,
      "learning_rate": 3.500805582761999e-05,
      "loss": 2.8114,
      "step": 1225000
    },
    {
      "epoch": 150.59,
      "learning_rate": 3.4946865817825666e-05,
      "loss": 2.7935,
      "step": 1230000
    },
    {
      "epoch": 151.2,
      "learning_rate": 3.4885663565132226e-05,
      "loss": 2.7946,
      "step": 1235000
    },
    {
      "epoch": 151.81,
      "learning_rate": 3.482446131243879e-05,
      "loss": 2.8033,
      "step": 1240000
    },
    {
      "epoch": 152.42,
      "learning_rate": 3.476333251714006e-05,
      "loss": 2.8701,
      "step": 1245000
    },
    {
      "epoch": 153.04,
      "learning_rate": 3.470213026444662e-05,
      "loss": 3.3656,
      "step": 1250000
    },
    {
      "epoch": 153.65,
      "learning_rate": 3.4640915768854066e-05,
      "loss": 2.8841,
      "step": 1255000
    },
    {
      "epoch": 154.26,
      "learning_rate": 3.4579725759059745e-05,
      "loss": 2.8458,
      "step": 1260000
    },
    {
      "epoch": 154.87,
      "learning_rate": 3.451856023506366e-05,
      "loss": 2.8331,
      "step": 1265000
    },
    {
      "epoch": 155.48,
      "learning_rate": 3.445734573947111e-05,
      "loss": 2.8009,
      "step": 1270000
    },
    {
      "epoch": 156.1,
      "learning_rate": 3.439614348677767e-05,
      "loss": 2.8067,
      "step": 1275000
    },
    {
      "epoch": 156.71,
      "learning_rate": 3.433495347698335e-05,
      "loss": 2.7919,
      "step": 1280000
    },
    {
      "epoch": 157.32,
      "learning_rate": 3.427377571008815e-05,
      "loss": 2.791,
      "step": 1285000
    },
    {
      "epoch": 157.93,
      "learning_rate": 3.421257345739471e-05,
      "loss": 2.7936,
      "step": 1290000
    },
    {
      "epoch": 158.55,
      "learning_rate": 3.4151371204701274e-05,
      "loss": 2.7738,
      "step": 1295000
    },
    {
      "epoch": 159.16,
      "learning_rate": 3.409019343780607e-05,
      "loss": 2.7837,
      "step": 1300000
    },
    {
      "epoch": 159.77,
      "learning_rate": 3.402899118511264e-05,
      "loss": 2.7746,
      "step": 1305000
    },
    {
      "epoch": 160.38,
      "learning_rate": 3.3967813418217435e-05,
      "loss": 2.7763,
      "step": 1310000
    },
    {
      "epoch": 160.99,
      "learning_rate": 3.390659892262488e-05,
      "loss": 2.7856,
      "step": 1315000
    },
    {
      "epoch": 161.61,
      "learning_rate": 3.384539666993144e-05,
      "loss": 2.7616,
      "step": 1320000
    },
    {
      "epoch": 162.22,
      "learning_rate": 3.3784194417238e-05,
      "loss": 2.763,
      "step": 1325000
    },
    {
      "epoch": 162.83,
      "learning_rate": 3.3723065621939274e-05,
      "loss": 2.7762,
      "step": 1330000
    },
    {
      "epoch": 163.44,
      "learning_rate": 3.3661863369245835e-05,
      "loss": 2.7614,
      "step": 1335000
    },
    {
      "epoch": 164.05,
      "learning_rate": 3.360067335945152e-05,
      "loss": 2.7703,
      "step": 1340000
    },
    {
      "epoch": 164.67,
      "learning_rate": 3.353947110675808e-05,
      "loss": 2.7684,
      "step": 1345000
    },
    {
      "epoch": 165.28,
      "learning_rate": 3.347828109696377e-05,
      "loss": 2.7581,
      "step": 1350000
    },
    {
      "epoch": 165.89,
      "learning_rate": 3.3417091087169446e-05,
      "loss": 2.7665,
      "step": 1355000
    },
    {
      "epoch": 166.5,
      "learning_rate": 3.3355901077375124e-05,
      "loss": 2.747,
      "step": 1360000
    },
    {
      "epoch": 167.12,
      "learning_rate": 3.329468658178257e-05,
      "loss": 2.7546,
      "step": 1365000
    },
    {
      "epoch": 167.73,
      "learning_rate": 3.323347208619001e-05,
      "loss": 2.7436,
      "step": 1370000
    },
    {
      "epoch": 168.34,
      "learning_rate": 3.3172282076395695e-05,
      "loss": 2.7466,
      "step": 1375000
    },
    {
      "epoch": 168.95,
      "learning_rate": 3.311112879529873e-05,
      "loss": 2.7542,
      "step": 1380000
    },
    {
      "epoch": 169.56,
      "learning_rate": 3.304993878550441e-05,
      "loss": 2.7362,
      "step": 1385000
    },
    {
      "epoch": 170.18,
      "learning_rate": 3.298873653281097e-05,
      "loss": 2.7422,
      "step": 1390000
    },
    {
      "epoch": 170.79,
      "learning_rate": 3.292757100881489e-05,
      "loss": 2.7447,
      "step": 1395000
    },
    {
      "epoch": 171.4,
      "learning_rate": 3.286635651322233e-05,
      "loss": 2.729,
      "step": 1400000
    },
    {
      "epoch": 172.01,
      "learning_rate": 3.280516650342802e-05,
      "loss": 2.7486,
      "step": 1405000
    },
    {
      "epoch": 172.62,
      "learning_rate": 3.2743952007835453e-05,
      "loss": 2.7222,
      "step": 1410000
    },
    {
      "epoch": 173.24,
      "learning_rate": 3.26827375122429e-05,
      "loss": 2.7341,
      "step": 1415000
    },
    {
      "epoch": 173.85,
      "learning_rate": 3.262157198824682e-05,
      "loss": 2.7325,
      "step": 1420000
    },
    {
      "epoch": 174.46,
      "learning_rate": 3.256040646425074e-05,
      "loss": 2.7245,
      "step": 1425000
    },
    {
      "epoch": 175.07,
      "learning_rate": 3.24992042115573e-05,
      "loss": 2.7354,
      "step": 1430000
    },
    {
      "epoch": 175.69,
      "learning_rate": 3.243798971596474e-05,
      "loss": 2.7145,
      "step": 1435000
    },
    {
      "epoch": 176.3,
      "learning_rate": 3.237679970617042e-05,
      "loss": 2.7181,
      "step": 1440000
    },
    {
      "epoch": 176.91,
      "learning_rate": 3.231559745347699e-05,
      "loss": 2.7222,
      "step": 1445000
    },
    {
      "epoch": 177.52,
      "learning_rate": 3.225440744368267e-05,
      "loss": 2.7152,
      "step": 1450000
    },
    {
      "epoch": 178.13,
      "learning_rate": 3.2193217433888347e-05,
      "loss": 2.719,
      "step": 1455000
    },
    {
      "epoch": 178.75,
      "learning_rate": 3.213201518119491e-05,
      "loss": 2.7148,
      "step": 1460000
    },
    {
      "epoch": 179.36,
      "learning_rate": 3.207081292850147e-05,
      "loss": 2.7098,
      "step": 1465000
    },
    {
      "epoch": 179.97,
      "learning_rate": 3.2009610675808036e-05,
      "loss": 2.722,
      "step": 1470000
    },
    {
      "epoch": 180.58,
      "learning_rate": 3.1948420666013714e-05,
      "loss": 2.6985,
      "step": 1475000
    },
    {
      "epoch": 181.19,
      "learning_rate": 3.188724289911851e-05,
      "loss": 2.7128,
      "step": 1480000
    },
    {
      "epoch": 181.81,
      "learning_rate": 3.182604064642508e-05,
      "loss": 2.7061,
      "step": 1485000
    },
    {
      "epoch": 182.42,
      "learning_rate": 3.176487512242899e-05,
      "loss": 2.6984,
      "step": 1490000
    },
    {
      "epoch": 183.03,
      "learning_rate": 3.1703721841332026e-05,
      "loss": 2.7181,
      "step": 1495000
    },
    {
      "epoch": 183.64,
      "learning_rate": 3.1642519588638594e-05,
      "loss": 2.6927,
      "step": 1500000
    },
    {
      "epoch": 184.26,
      "learning_rate": 3.158132957884427e-05,
      "loss": 2.7005,
      "step": 1505000
    },
    {
      "epoch": 184.87,
      "learning_rate": 3.1520115083251715e-05,
      "loss": 2.7001,
      "step": 1510000
    },
    {
      "epoch": 185.48,
      "learning_rate": 3.1458961802154755e-05,
      "loss": 2.6905,
      "step": 1515000
    },
    {
      "epoch": 186.09,
      "learning_rate": 3.139777179236043e-05,
      "loss": 2.7003,
      "step": 1520000
    },
    {
      "epoch": 186.7,
      "learning_rate": 3.1336557296767876e-05,
      "loss": 2.6912,
      "step": 1525000
    },
    {
      "epoch": 187.32,
      "learning_rate": 3.127537952987267e-05,
      "loss": 2.6887,
      "step": 1530000
    },
    {
      "epoch": 187.93,
      "learning_rate": 3.1214201762977476e-05,
      "loss": 2.6963,
      "step": 1535000
    },
    {
      "epoch": 188.54,
      "learning_rate": 3.115299951028404e-05,
      "loss": 2.6825,
      "step": 1540000
    },
    {
      "epoch": 189.15,
      "learning_rate": 3.10917972575906e-05,
      "loss": 2.6928,
      "step": 1545000
    },
    {
      "epoch": 189.76,
      "learning_rate": 3.103058276199805e-05,
      "loss": 2.6823,
      "step": 1550000
    },
    {
      "epoch": 190.38,
      "learning_rate": 3.0969392752203726e-05,
      "loss": 2.677,
      "step": 1555000
    },
    {
      "epoch": 190.99,
      "learning_rate": 3.090821498530852e-05,
      "loss": 2.6905,
      "step": 1560000
    },
    {
      "epoch": 191.6,
      "learning_rate": 3.0847000489715966e-05,
      "loss": 2.6653,
      "step": 1565000
    },
    {
      "epoch": 192.21,
      "learning_rate": 3.078585945151812e-05,
      "loss": 2.6817,
      "step": 1570000
    },
    {
      "epoch": 192.83,
      "learning_rate": 3.0724644955925566e-05,
      "loss": 2.6752,
      "step": 1575000
    },
    {
      "epoch": 193.44,
      "learning_rate": 3.066344270323213e-05,
      "loss": 2.6699,
      "step": 1580000
    },
    {
      "epoch": 194.05,
      "learning_rate": 3.0602252693437805e-05,
      "loss": 2.6801,
      "step": 1585000
    },
    {
      "epoch": 194.66,
      "learning_rate": 3.054108716944172e-05,
      "loss": 2.6652,
      "step": 1590000
    },
    {
      "epoch": 195.27,
      "learning_rate": 3.047987267384917e-05,
      "loss": 2.6727,
      "step": 1595000
    },
    {
      "epoch": 195.89,
      "learning_rate": 3.041867042115573e-05,
      "loss": 2.6693,
      "step": 1600000
    },
    {
      "epoch": 196.5,
      "learning_rate": 3.0357468168462295e-05,
      "loss": 2.6598,
      "step": 1605000
    },
    {
      "epoch": 197.11,
      "learning_rate": 3.0296302644466213e-05,
      "loss": 2.67,
      "step": 1610000
    },
    {
      "epoch": 197.72,
      "learning_rate": 3.023511263467189e-05,
      "loss": 2.6597,
      "step": 1615000
    },
    {
      "epoch": 198.33,
      "learning_rate": 3.017392262487757e-05,
      "loss": 2.6591,
      "step": 1620000
    },
    {
      "epoch": 198.95,
      "learning_rate": 3.0112732615083256e-05,
      "loss": 2.6675,
      "step": 1625000
    },
    {
      "epoch": 199.56,
      "learning_rate": 3.0051518119490695e-05,
      "loss": 2.6524,
      "step": 1630000
    },
    {
      "epoch": 200.17,
      "learning_rate": 2.999031586679726e-05,
      "loss": 2.6595,
      "step": 1635000
    },
    {
      "epoch": 200.78,
      "learning_rate": 2.9929162585700292e-05,
      "loss": 2.6568,
      "step": 1640000
    },
    {
      "epoch": 201.4,
      "learning_rate": 2.9867972575905977e-05,
      "loss": 2.6533,
      "step": 1645000
    },
    {
      "epoch": 202.01,
      "learning_rate": 2.980677032321254e-05,
      "loss": 2.6601,
      "step": 1650000
    },
    {
      "epoch": 202.62,
      "learning_rate": 2.9745568070519102e-05,
      "loss": 2.6413,
      "step": 1655000
    },
    {
      "epoch": 203.23,
      "learning_rate": 2.968436581782566e-05,
      "loss": 2.65,
      "step": 1660000
    },
    {
      "epoch": 203.84,
      "learning_rate": 2.9623151322233106e-05,
      "loss": 2.6487,
      "step": 1665000
    },
    {
      "epoch": 204.46,
      "learning_rate": 2.9561973555337906e-05,
      "loss": 2.6414,
      "step": 1670000
    },
    {
      "epoch": 205.07,
      "learning_rate": 2.9500795788442703e-05,
      "loss": 2.6481,
      "step": 1675000
    },
    {
      "epoch": 205.68,
      "learning_rate": 2.9439593535749267e-05,
      "loss": 2.6367,
      "step": 1680000
    },
    {
      "epoch": 206.29,
      "learning_rate": 2.9378391283055828e-05,
      "loss": 2.6372,
      "step": 1685000
    },
    {
      "epoch": 206.9,
      "learning_rate": 2.9317238001958864e-05,
      "loss": 2.6494,
      "step": 1690000
    },
    {
      "epoch": 207.52,
      "learning_rate": 2.9256035749265424e-05,
      "loss": 2.6289,
      "step": 1695000
    },
    {
      "epoch": 208.13,
      "learning_rate": 2.919483349657199e-05,
      "loss": 2.6367,
      "step": 1700000
    },
    {
      "epoch": 208.74,
      "learning_rate": 2.9133643486777674e-05,
      "loss": 2.6368,
      "step": 1705000
    },
    {
      "epoch": 209.35,
      "learning_rate": 2.907244123408423e-05,
      "loss": 2.6303,
      "step": 1710000
    },
    {
      "epoch": 209.97,
      "learning_rate": 2.901126346718903e-05,
      "loss": 2.6383,
      "step": 1715000
    },
    {
      "epoch": 210.58,
      "learning_rate": 2.8950110186092068e-05,
      "loss": 2.6243,
      "step": 1720000
    },
    {
      "epoch": 211.19,
      "learning_rate": 2.888890793339863e-05,
      "loss": 2.6286,
      "step": 1725000
    },
    {
      "epoch": 211.8,
      "learning_rate": 2.8827705680705193e-05,
      "loss": 2.6308,
      "step": 1730000
    },
    {
      "epoch": 212.41,
      "learning_rate": 2.876651567091087e-05,
      "loss": 2.6217,
      "step": 1735000
    },
    {
      "epoch": 213.03,
      "learning_rate": 2.8705313418217432e-05,
      "loss": 2.6304,
      "step": 1740000
    },
    {
      "epoch": 213.64,
      "learning_rate": 2.8644098922624878e-05,
      "loss": 2.6171,
      "step": 1745000
    },
    {
      "epoch": 214.25,
      "learning_rate": 2.8582896669931442e-05,
      "loss": 2.6214,
      "step": 1750000
    },
    {
      "epoch": 214.86,
      "learning_rate": 2.8521694417238003e-05,
      "loss": 2.6216,
      "step": 1755000
    },
    {
      "epoch": 215.48,
      "learning_rate": 2.84605166503428e-05,
      "loss": 2.6112,
      "step": 1760000
    },
    {
      "epoch": 216.09,
      "learning_rate": 2.8399326640548485e-05,
      "loss": 2.6214,
      "step": 1765000
    },
    {
      "epoch": 216.7,
      "learning_rate": 2.8338136630754164e-05,
      "loss": 2.6092,
      "step": 1770000
    },
    {
      "epoch": 217.31,
      "learning_rate": 2.8277032321253676e-05,
      "loss": 2.6192,
      "step": 1775000
    },
    {
      "epoch": 217.92,
      "learning_rate": 2.821581782566112e-05,
      "loss": 2.6223,
      "step": 1780000
    },
    {
      "epoch": 218.54,
      "learning_rate": 2.8154603330068565e-05,
      "loss": 2.6046,
      "step": 1785000
    },
    {
      "epoch": 219.15,
      "learning_rate": 2.8093437806072483e-05,
      "loss": 2.6183,
      "step": 1790000
    },
    {
      "epoch": 219.76,
      "learning_rate": 2.803224779627816e-05,
      "loss": 2.6025,
      "step": 1795000
    },
    {
      "epoch": 220.37,
      "learning_rate": 2.797107002938296e-05,
      "loss": 2.6043,
      "step": 1800000
    },
    {
      "epoch": 220.98,
      "learning_rate": 2.790986777668952e-05,
      "loss": 2.6146,
      "step": 1805000
    },
    {
      "epoch": 221.6,
      "learning_rate": 2.7848653281096965e-05,
      "loss": 2.5949,
      "step": 1810000
    },
    {
      "epoch": 222.21,
      "learning_rate": 2.778743878550441e-05,
      "loss": 2.6036,
      "step": 1815000
    },
    {
      "epoch": 222.82,
      "learning_rate": 2.7726261018609208e-05,
      "loss": 2.6024,
      "step": 1820000
    },
    {
      "epoch": 223.43,
      "learning_rate": 2.766505876591577e-05,
      "loss": 2.5922,
      "step": 1825000
    },
    {
      "epoch": 224.05,
      "learning_rate": 2.7603856513222333e-05,
      "loss": 2.6079,
      "step": 1830000
    },
    {
      "epoch": 224.66,
      "learning_rate": 2.7542654260528894e-05,
      "loss": 2.5926,
      "step": 1835000
    },
    {
      "epoch": 225.27,
      "learning_rate": 2.7481488736532812e-05,
      "loss": 2.5927,
      "step": 1840000
    },
    {
      "epoch": 225.88,
      "learning_rate": 2.742029872673849e-05,
      "loss": 2.5926,
      "step": 1845000
    },
    {
      "epoch": 226.49,
      "learning_rate": 2.7359108716944176e-05,
      "loss": 2.5815,
      "step": 1850000
    },
    {
      "epoch": 227.11,
      "learning_rate": 2.7297955435847212e-05,
      "loss": 2.5987,
      "step": 1855000
    },
    {
      "epoch": 227.72,
      "learning_rate": 2.723674094025465e-05,
      "loss": 2.5872,
      "step": 1860000
    },
    {
      "epoch": 228.33,
      "learning_rate": 2.7175538687561216e-05,
      "loss": 2.5825,
      "step": 1865000
    },
    {
      "epoch": 228.94,
      "learning_rate": 2.7114336434867776e-05,
      "loss": 2.5951,
      "step": 1870000
    },
    {
      "epoch": 229.55,
      "learning_rate": 2.7053158667972576e-05,
      "loss": 2.5785,
      "step": 1875000
    },
    {
      "epoch": 230.17,
      "learning_rate": 2.699196865817826e-05,
      "loss": 2.5899,
      "step": 1880000
    },
    {
      "epoch": 230.78,
      "learning_rate": 2.693076640548482e-05,
      "loss": 2.5784,
      "step": 1885000
    },
    {
      "epoch": 231.39,
      "learning_rate": 2.6869613124387855e-05,
      "loss": 2.5779,
      "step": 1890000
    },
    {
      "epoch": 232.0,
      "learning_rate": 2.680842311459354e-05,
      "loss": 2.5868,
      "step": 1895000
    },
    {
      "epoch": 232.62,
      "learning_rate": 2.674720861900098e-05,
      "loss": 2.5709,
      "step": 1900000
    },
    {
      "epoch": 233.23,
      "learning_rate": 2.668600636630754e-05,
      "loss": 2.5789,
      "step": 1905000
    },
    {
      "epoch": 233.84,
      "learning_rate": 2.662484084231146e-05,
      "loss": 2.5823,
      "step": 1910000
    },
    {
      "epoch": 234.45,
      "learning_rate": 2.6563650832517138e-05,
      "loss": 2.5687,
      "step": 1915000
    },
    {
      "epoch": 235.06,
      "learning_rate": 2.6502448579823702e-05,
      "loss": 2.5768,
      "step": 1920000
    },
    {
      "epoch": 235.68,
      "learning_rate": 2.6441246327130266e-05,
      "loss": 2.5651,
      "step": 1925000
    },
    {
      "epoch": 236.29,
      "learning_rate": 2.6380044074436827e-05,
      "loss": 2.5706,
      "step": 1930000
    },
    {
      "epoch": 236.9,
      "learning_rate": 2.6318854064642506e-05,
      "loss": 2.5726,
      "step": 1935000
    },
    {
      "epoch": 237.51,
      "learning_rate": 2.625765181194907e-05,
      "loss": 2.5619,
      "step": 1940000
    },
    {
      "epoch": 238.12,
      "learning_rate": 2.619649853085211e-05,
      "loss": 2.5743,
      "step": 1945000
    },
    {
      "epoch": 238.74,
      "learning_rate": 2.6135296278158674e-05,
      "loss": 2.5658,
      "step": 1950000
    },
    {
      "epoch": 239.35,
      "learning_rate": 2.6074118511263467e-05,
      "loss": 2.5626,
      "step": 1955000
    },
    {
      "epoch": 239.96,
      "learning_rate": 2.6012904015670913e-05,
      "loss": 2.5654,
      "step": 1960000
    },
    {
      "epoch": 240.57,
      "learning_rate": 2.5951714005876592e-05,
      "loss": 2.5486,
      "step": 1965000
    },
    {
      "epoch": 241.19,
      "learning_rate": 2.5890511753183156e-05,
      "loss": 2.5586,
      "step": 1970000
    },
    {
      "epoch": 241.8,
      "learning_rate": 2.5829346229187074e-05,
      "loss": 2.5545,
      "step": 1975000
    },
    {
      "epoch": 242.41,
      "learning_rate": 2.5768131733594513e-05,
      "loss": 2.5544,
      "step": 1980000
    },
    {
      "epoch": 243.02,
      "learning_rate": 2.570696620959843e-05,
      "loss": 2.5635,
      "step": 1985000
    },
    {
      "epoch": 243.63,
      "learning_rate": 2.5645763956904996e-05,
      "loss": 2.5471,
      "step": 1990000
    },
    {
      "epoch": 244.25,
      "learning_rate": 2.5584549461312442e-05,
      "loss": 2.5531,
      "step": 1995000
    },
    {
      "epoch": 244.86,
      "learning_rate": 2.552335945151812e-05,
      "loss": 2.5481,
      "step": 2000000
    },
    {
      "epoch": 245.47,
      "learning_rate": 2.546219392752204e-05,
      "loss": 2.5432,
      "step": 2005000
    },
    {
      "epoch": 246.08,
      "learning_rate": 2.540101616062684e-05,
      "loss": 2.5532,
      "step": 2010000
    },
    {
      "epoch": 246.69,
      "learning_rate": 2.5339850636630757e-05,
      "loss": 2.5446,
      "step": 2015000
    },
    {
      "epoch": 247.31,
      "learning_rate": 2.5278636141038196e-05,
      "loss": 2.5426,
      "step": 2020000
    },
    {
      "epoch": 247.92,
      "learning_rate": 2.5217421645445642e-05,
      "loss": 2.5435,
      "step": 2025000
    },
    {
      "epoch": 248.53,
      "learning_rate": 2.515625612144956e-05,
      "loss": 2.5345,
      "step": 2030000
    },
    {
      "epoch": 249.14,
      "learning_rate": 2.5095078354554357e-05,
      "loss": 2.5451,
      "step": 2035000
    },
    {
      "epoch": 249.76,
      "learning_rate": 2.503387610186092e-05,
      "loss": 2.539,
      "step": 2040000
    },
    {
      "epoch": 250.37,
      "learning_rate": 2.4972661606268368e-05,
      "loss": 2.5353,
      "step": 2045000
    },
    {
      "epoch": 250.98,
      "learning_rate": 2.491145935357493e-05,
      "loss": 2.5451,
      "step": 2050000
    },
    {
      "epoch": 251.59,
      "learning_rate": 2.4850293829578847e-05,
      "loss": 2.5282,
      "step": 2055000
    },
    {
      "epoch": 252.2,
      "learning_rate": 2.4789103819784525e-05,
      "loss": 2.5304,
      "step": 2060000
    },
    {
      "epoch": 252.82,
      "learning_rate": 2.472790156709109e-05,
      "loss": 2.5337,
      "step": 2065000
    },
    {
      "epoch": 253.43,
      "learning_rate": 2.466669931439765e-05,
      "loss": 2.5296,
      "step": 2070000
    },
    {
      "epoch": 254.04,
      "learning_rate": 2.460550930460333e-05,
      "loss": 2.5339,
      "step": 2075000
    },
    {
      "epoch": 254.65,
      "learning_rate": 2.4544331537708132e-05,
      "loss": 2.5233,
      "step": 2080000
    },
    {
      "epoch": 255.26,
      "learning_rate": 2.4483129285014693e-05,
      "loss": 2.5274,
      "step": 2085000
    },
    {
      "epoch": 255.88,
      "learning_rate": 2.4421914789422136e-05,
      "loss": 2.5297,
      "step": 2090000
    },
    {
      "epoch": 256.49,
      "learning_rate": 2.4360749265426054e-05,
      "loss": 2.5175,
      "step": 2095000
    },
    {
      "epoch": 257.1,
      "learning_rate": 2.429959598432909e-05,
      "loss": 2.5325,
      "step": 2100000
    },
    {
      "epoch": 257.71,
      "learning_rate": 2.4238381488736533e-05,
      "loss": 2.5195,
      "step": 2105000
    },
    {
      "epoch": 258.33,
      "learning_rate": 2.4177179236043097e-05,
      "loss": 2.516,
      "step": 2110000
    },
    {
      "epoch": 258.94,
      "learning_rate": 2.4115976983349658e-05,
      "loss": 2.525,
      "step": 2115000
    },
    {
      "epoch": 259.55,
      "learning_rate": 2.40547624877571e-05,
      "loss": 2.5131,
      "step": 2120000
    },
    {
      "epoch": 260.16,
      "learning_rate": 2.39935847208619e-05,
      "loss": 2.5202,
      "step": 2125000
    },
    {
      "epoch": 260.77,
      "learning_rate": 2.393238246816846e-05,
      "loss": 2.5134,
      "step": 2130000
    },
    {
      "epoch": 261.39,
      "learning_rate": 2.3871192458374144e-05,
      "loss": 2.5105,
      "step": 2135000
    },
    {
      "epoch": 262.0,
      "learning_rate": 2.3810002448579822e-05,
      "loss": 2.5225,
      "step": 2140000
    },
    {
      "epoch": 262.61,
      "learning_rate": 2.3748812438785504e-05,
      "loss": 2.5043,
      "step": 2145000
    },
    {
      "epoch": 263.22,
      "learning_rate": 2.368761018609207e-05,
      "loss": 2.5133,
      "step": 2150000
    },
    {
      "epoch": 263.83,
      "learning_rate": 2.3626407933398633e-05,
      "loss": 2.5058,
      "step": 2155000
    },
    {
      "epoch": 264.45,
      "learning_rate": 2.356523016650343e-05,
      "loss": 2.5014,
      "step": 2160000
    },
    {
      "epoch": 265.06,
      "learning_rate": 2.3504027913809994e-05,
      "loss": 2.5135,
      "step": 2165000
    },
    {
      "epoch": 265.67,
      "learning_rate": 2.3442837904015672e-05,
      "loss": 2.5014,
      "step": 2170000
    },
    {
      "epoch": 266.28,
      "learning_rate": 2.3381635651322233e-05,
      "loss": 2.5022,
      "step": 2175000
    },
    {
      "epoch": 266.9,
      "learning_rate": 2.332047012732615e-05,
      "loss": 2.5087,
      "step": 2180000
    },
    {
      "epoch": 267.51,
      "learning_rate": 2.3259341332027427e-05,
      "loss": 2.4983,
      "step": 2185000
    },
    {
      "epoch": 268.12,
      "learning_rate": 2.319812683643487e-05,
      "loss": 2.5072,
      "step": 2190000
    },
    {
      "epoch": 268.73,
      "learning_rate": 2.3136912340842312e-05,
      "loss": 2.4956,
      "step": 2195000
    },
    {
      "epoch": 269.34,
      "learning_rate": 2.3075722331047994e-05,
      "loss": 2.4927,
      "step": 2200000
    },
    {
      "epoch": 269.96,
      "learning_rate": 2.3014507835455437e-05,
      "loss": 2.5042,
      "step": 2205000
    },
    {
      "epoch": 270.57,
      "learning_rate": 2.295329333986288e-05,
      "loss": 2.4855,
      "step": 2210000
    },
    {
      "epoch": 271.18,
      "learning_rate": 2.289211557296768e-05,
      "loss": 2.4987,
      "step": 2215000
    },
    {
      "epoch": 271.79,
      "learning_rate": 2.2830925563173362e-05,
      "loss": 2.4918,
      "step": 2220000
    },
    {
      "epoch": 272.4,
      "learning_rate": 2.276976003917728e-05,
      "loss": 2.4912,
      "step": 2225000
    },
    {
      "epoch": 273.02,
      "learning_rate": 2.2708545543584723e-05,
      "loss": 2.4933,
      "step": 2230000
    },
    {
      "epoch": 273.63,
      "learning_rate": 2.2647343290891284e-05,
      "loss": 2.4824,
      "step": 2235000
    },
    {
      "epoch": 274.24,
      "learning_rate": 2.2586165523996084e-05,
      "loss": 2.4854,
      "step": 2240000
    },
    {
      "epoch": 274.85,
      "learning_rate": 2.2524975514201766e-05,
      "loss": 2.4904,
      "step": 2245000
    },
    {
      "epoch": 275.47,
      "learning_rate": 2.2463785504407445e-05,
      "loss": 2.482,
      "step": 2250000
    },
    {
      "epoch": 276.08,
      "learning_rate": 2.2402619980411363e-05,
      "loss": 2.4919,
      "step": 2255000
    },
    {
      "epoch": 276.69,
      "learning_rate": 2.2341405484818806e-05,
      "loss": 2.4783,
      "step": 2260000
    },
    {
      "epoch": 277.3,
      "learning_rate": 2.228019098922625e-05,
      "loss": 2.4802,
      "step": 2265000
    },
    {
      "epoch": 277.91,
      "learning_rate": 2.2219025465230167e-05,
      "loss": 2.4876,
      "step": 2270000
    },
    {
      "epoch": 278.53,
      "learning_rate": 2.215782321253673e-05,
      "loss": 2.4726,
      "step": 2275000
    },
    {
      "epoch": 279.14,
      "learning_rate": 2.209662095984329e-05,
      "loss": 2.4839,
      "step": 2280000
    },
    {
      "epoch": 279.75,
      "learning_rate": 2.2035418707149856e-05,
      "loss": 2.4748,
      "step": 2285000
    },
    {
      "epoch": 280.36,
      "learning_rate": 2.1974240940254652e-05,
      "loss": 2.4726,
      "step": 2290000
    },
    {
      "epoch": 280.97,
      "learning_rate": 2.1913038687561216e-05,
      "loss": 2.4803,
      "step": 2295000
    },
    {
      "epoch": 281.59,
      "learning_rate": 2.1851836434867777e-05,
      "loss": 2.4646,
      "step": 2300000
    },
    {
      "epoch": 282.2,
      "learning_rate": 2.179064642507346e-05,
      "loss": 2.4725,
      "step": 2305000
    },
    {
      "epoch": 282.81,
      "learning_rate": 2.1729480901077377e-05,
      "loss": 2.4707,
      "step": 2310000
    },
    {
      "epoch": 283.42,
      "learning_rate": 2.166826640548482e-05,
      "loss": 2.4703,
      "step": 2315000
    },
    {
      "epoch": 284.04,
      "learning_rate": 2.1607113124387856e-05,
      "loss": 2.4802,
      "step": 2320000
    },
    {
      "epoch": 284.65,
      "learning_rate": 2.15458986287953e-05,
      "loss": 2.459,
      "step": 2325000
    },
    {
      "epoch": 285.26,
      "learning_rate": 2.14847208619001e-05,
      "loss": 2.4638,
      "step": 2330000
    },
    {
      "epoch": 285.87,
      "learning_rate": 2.142351860920666e-05,
      "loss": 2.4711,
      "step": 2335000
    },
    {
      "epoch": 286.48,
      "learning_rate": 2.1362328599412342e-05,
      "loss": 2.4569,
      "step": 2340000
    },
    {
      "epoch": 287.1,
      "learning_rate": 2.130113858961802e-05,
      "loss": 2.4631,
      "step": 2345000
    },
    {
      "epoch": 287.71,
      "learning_rate": 2.1239924094025464e-05,
      "loss": 2.46,
      "step": 2350000
    },
    {
      "epoch": 288.32,
      "learning_rate": 2.1178746327130267e-05,
      "loss": 2.4576,
      "step": 2355000
    },
    {
      "epoch": 288.93,
      "learning_rate": 2.1117568560235064e-05,
      "loss": 2.4631,
      "step": 2360000
    },
    {
      "epoch": 289.54,
      "learning_rate": 2.1056378550440746e-05,
      "loss": 2.4452,
      "step": 2365000
    },
    {
      "epoch": 290.16,
      "learning_rate": 2.0995176297747307e-05,
      "loss": 2.4616,
      "step": 2370000
    },
    {
      "epoch": 290.77,
      "learning_rate": 2.093398628795299e-05,
      "loss": 2.4533,
      "step": 2375000
    },
    {
      "epoch": 291.38,
      "learning_rate": 2.0872796278158668e-05,
      "loss": 2.4504,
      "step": 2380000
    },
    {
      "epoch": 291.99,
      "learning_rate": 2.0811630754162586e-05,
      "loss": 2.4577,
      "step": 2385000
    },
    {
      "epoch": 292.61,
      "learning_rate": 2.075041625857003e-05,
      "loss": 2.4415,
      "step": 2390000
    },
    {
      "epoch": 293.22,
      "learning_rate": 2.068922624877571e-05,
      "loss": 2.4522,
      "step": 2395000
    },
    {
      "epoch": 293.83,
      "learning_rate": 2.0628011753183153e-05,
      "loss": 2.4496,
      "step": 2400000
    },
    {
      "epoch": 294.44,
      "learning_rate": 2.0566809500489718e-05,
      "loss": 2.4404,
      "step": 2405000
    },
    {
      "epoch": 295.05,
      "learning_rate": 2.0505607247796278e-05,
      "loss": 2.451,
      "step": 2410000
    },
    {
      "epoch": 295.67,
      "learning_rate": 2.0444404995102842e-05,
      "loss": 2.4375,
      "step": 2415000
    },
    {
      "epoch": 296.28,
      "learning_rate": 2.0383227228207643e-05,
      "loss": 2.4406,
      "step": 2420000
    },
    {
      "epoch": 296.89,
      "learning_rate": 2.032203721841332e-05,
      "loss": 2.4451,
      "step": 2425000
    },
    {
      "epoch": 297.5,
      "learning_rate": 2.026089618021548e-05,
      "loss": 2.4371,
      "step": 2430000
    },
    {
      "epoch": 298.11,
      "learning_rate": 2.0199693927522036e-05,
      "loss": 2.4448,
      "step": 2435000
    },
    {
      "epoch": 298.73,
      "learning_rate": 2.01384916748286e-05,
      "loss": 2.4356,
      "step": 2440000
    },
    {
      "epoch": 299.34,
      "learning_rate": 2.007728942213516e-05,
      "loss": 2.4355,
      "step": 2445000
    },
    {
      "epoch": 299.95,
      "learning_rate": 2.0016087169441725e-05,
      "loss": 2.4379,
      "step": 2450000
    },
    {
      "epoch": 300.56,
      "learning_rate": 1.9954884916748286e-05,
      "loss": 2.4305,
      "step": 2455000
    },
    {
      "epoch": 301.18,
      "learning_rate": 1.9893707149853086e-05,
      "loss": 2.4334,
      "step": 2460000
    },
    {
      "epoch": 301.79,
      "learning_rate": 1.9832517140058768e-05,
      "loss": 2.4343,
      "step": 2465000
    },
    {
      "epoch": 302.4,
      "learning_rate": 1.9771327130264447e-05,
      "loss": 2.4278,
      "step": 2470000
    },
    {
      "epoch": 303.01,
      "learning_rate": 1.971013712047013e-05,
      "loss": 2.4412,
      "step": 2475000
    },
    {
      "epoch": 303.62,
      "learning_rate": 1.9648947110675808e-05,
      "loss": 2.4217,
      "step": 2480000
    },
    {
      "epoch": 304.24,
      "learning_rate": 1.958775710088149e-05,
      "loss": 2.4292,
      "step": 2485000
    },
    {
      "epoch": 304.85,
      "learning_rate": 1.952656709108717e-05,
      "loss": 2.4289,
      "step": 2490000
    },
    {
      "epoch": 305.46,
      "learning_rate": 1.9465413809990208e-05,
      "loss": 2.424,
      "step": 2495000
    },
    {
      "epoch": 306.07,
      "learning_rate": 1.940419931439765e-05,
      "loss": 2.4298,
      "step": 2500000
    },
    {
      "epoch": 306.68,
      "learning_rate": 1.9342997061704212e-05,
      "loss": 2.4223,
      "step": 2505000
    },
    {
      "epoch": 307.3,
      "learning_rate": 1.9281794809010776e-05,
      "loss": 2.4235,
      "step": 2510000
    },
    {
      "epoch": 307.91,
      "learning_rate": 1.922058031341822e-05,
      "loss": 2.424,
      "step": 2515000
    },
    {
      "epoch": 308.52,
      "learning_rate": 1.91593903036239e-05,
      "loss": 2.4111,
      "step": 2520000
    },
    {
      "epoch": 309.13,
      "learning_rate": 1.9098212536728697e-05,
      "loss": 2.423,
      "step": 2525000
    },
    {
      "epoch": 309.75,
      "learning_rate": 1.9036998041136144e-05,
      "loss": 2.4155,
      "step": 2530000
    },
    {
      "epoch": 310.36,
      "learning_rate": 1.8975795788442704e-05,
      "loss": 2.4123,
      "step": 2535000
    },
    {
      "epoch": 310.97,
      "learning_rate": 1.8914630264446622e-05,
      "loss": 2.4202,
      "step": 2540000
    },
    {
      "epoch": 311.58,
      "learning_rate": 1.8853428011753187e-05,
      "loss": 2.4051,
      "step": 2545000
    },
    {
      "epoch": 312.19,
      "learning_rate": 1.8792225759059744e-05,
      "loss": 2.4142,
      "step": 2550000
    },
    {
      "epoch": 312.81,
      "learning_rate": 1.8731035749265426e-05,
      "loss": 2.4107,
      "step": 2555000
    },
    {
      "epoch": 313.42,
      "learning_rate": 1.8669857982370226e-05,
      "loss": 2.4112,
      "step": 2560000
    },
    {
      "epoch": 314.03,
      "learning_rate": 1.860864348677767e-05,
      "loss": 2.4136,
      "step": 2565000
    },
    {
      "epoch": 314.64,
      "learning_rate": 1.854746571988247e-05,
      "loss": 2.4032,
      "step": 2570000
    },
    {
      "epoch": 315.25,
      "learning_rate": 1.8486275710088148e-05,
      "loss": 2.4104,
      "step": 2575000
    },
    {
      "epoch": 315.87,
      "learning_rate": 1.8425122428991187e-05,
      "loss": 2.414,
      "step": 2580000
    },
    {
      "epoch": 316.48,
      "learning_rate": 1.8363956904995102e-05,
      "loss": 2.4031,
      "step": 2585000
    },
    {
      "epoch": 317.09,
      "learning_rate": 1.8302742409402548e-05,
      "loss": 2.4114,
      "step": 2590000
    },
    {
      "epoch": 317.7,
      "learning_rate": 1.8241576885406463e-05,
      "loss": 2.402,
      "step": 2595000
    },
    {
      "epoch": 318.32,
      "learning_rate": 1.8180374632713027e-05,
      "loss": 2.3997,
      "step": 2600000
    },
    {
      "epoch": 318.93,
      "learning_rate": 1.8119172380019588e-05,
      "loss": 2.4049,
      "step": 2605000
    },
    {
      "epoch": 319.54,
      "learning_rate": 1.805795788442703e-05,
      "loss": 2.39,
      "step": 2610000
    },
    {
      "epoch": 320.15,
      "learning_rate": 1.7996767874632713e-05,
      "loss": 2.4067,
      "step": 2615000
    },
    {
      "epoch": 320.76,
      "learning_rate": 1.7935565621939277e-05,
      "loss": 2.394,
      "step": 2620000
    },
    {
      "epoch": 321.38,
      "learning_rate": 1.7874375612144956e-05,
      "loss": 2.3929,
      "step": 2625000
    },
    {
      "epoch": 321.99,
      "learning_rate": 1.7813161116552402e-05,
      "loss": 2.4052,
      "step": 2630000
    },
    {
      "epoch": 322.6,
      "learning_rate": 1.7751995592556317e-05,
      "loss": 2.3882,
      "step": 2635000
    },
    {
      "epoch": 323.21,
      "learning_rate": 1.769079333986288e-05,
      "loss": 2.3936,
      "step": 2640000
    },
    {
      "epoch": 323.82,
      "learning_rate": 1.76296278158668e-05,
      "loss": 2.3958,
      "step": 2645000
    },
    {
      "epoch": 324.44,
      "learning_rate": 1.756842556317336e-05,
      "loss": 2.3891,
      "step": 2650000
    },
    {
      "epoch": 325.05,
      "learning_rate": 1.7507211067580802e-05,
      "loss": 2.3939,
      "step": 2655000
    },
    {
      "epoch": 325.66,
      "learning_rate": 1.7446033300685602e-05,
      "loss": 2.3825,
      "step": 2660000
    },
    {
      "epoch": 326.27,
      "learning_rate": 1.738488001958864e-05,
      "loss": 2.3895,
      "step": 2665000
    },
    {
      "epoch": 326.89,
      "learning_rate": 1.7323677766895203e-05,
      "loss": 2.3935,
      "step": 2670000
    },
    {
      "epoch": 327.5,
      "learning_rate": 1.72625e-05,
      "loss": 2.3846,
      "step": 2675000
    },
    {
      "epoch": 328.11,
      "learning_rate": 1.7201285504407442e-05,
      "loss": 2.3913,
      "step": 2680000
    },
    {
      "epoch": 328.72,
      "learning_rate": 1.714007100881489e-05,
      "loss": 2.3824,
      "step": 2685000
    },
    {
      "epoch": 329.33,
      "learning_rate": 1.707889324191969e-05,
      "loss": 2.3816,
      "step": 2690000
    },
    {
      "epoch": 329.95,
      "learning_rate": 1.7017727717923603e-05,
      "loss": 2.385,
      "step": 2695000
    },
    {
      "epoch": 330.56,
      "learning_rate": 1.695651322233105e-05,
      "loss": 2.372,
      "step": 2700000
    },
    {
      "epoch": 331.17,
      "learning_rate": 1.6895310969637614e-05,
      "loss": 2.3735,
      "step": 2705000
    },
    {
      "epoch": 331.78,
      "learning_rate": 1.683410871694417e-05,
      "loss": 2.3766,
      "step": 2710000
    },
    {
      "epoch": 332.39,
      "learning_rate": 1.6772918707149853e-05,
      "loss": 2.3733,
      "step": 2715000
    },
    {
      "epoch": 333.01,
      "learning_rate": 1.6711716454456417e-05,
      "loss": 2.3792,
      "step": 2720000
    },
    {
      "epoch": 333.62,
      "learning_rate": 1.6650538687561214e-05,
      "loss": 2.3691,
      "step": 2725000
    },
    {
      "epoch": 334.23,
      "learning_rate": 1.6589348677766896e-05,
      "loss": 2.3737,
      "step": 2730000
    },
    {
      "epoch": 334.84,
      "learning_rate": 1.6528146425073457e-05,
      "loss": 2.3788,
      "step": 2735000
    },
    {
      "epoch": 335.46,
      "learning_rate": 1.646694417238002e-05,
      "loss": 2.3685,
      "step": 2740000
    },
    {
      "epoch": 336.07,
      "learning_rate": 1.640576640548482e-05,
      "loss": 2.3758,
      "step": 2745000
    },
    {
      "epoch": 336.68,
      "learning_rate": 1.634458863858962e-05,
      "loss": 2.3649,
      "step": 2750000
    },
    {
      "epoch": 337.29,
      "learning_rate": 1.6283386385896182e-05,
      "loss": 2.3737,
      "step": 2755000
    },
    {
      "epoch": 337.9,
      "learning_rate": 1.6222171890303625e-05,
      "loss": 2.3717,
      "step": 2760000
    },
    {
      "epoch": 338.52,
      "learning_rate": 1.6160981880509303e-05,
      "loss": 2.3609,
      "step": 2765000
    },
    {
      "epoch": 339.13,
      "learning_rate": 1.6099804113614107e-05,
      "loss": 2.3676,
      "step": 2770000
    },
    {
      "epoch": 339.74,
      "learning_rate": 1.603858961802155e-05,
      "loss": 2.3614,
      "step": 2775000
    },
    {
      "epoch": 340.35,
      "learning_rate": 1.597738736532811e-05,
      "loss": 2.36,
      "step": 2780000
    },
    {
      "epoch": 340.96,
      "learning_rate": 1.591620959843291e-05,
      "loss": 2.3638,
      "step": 2785000
    },
    {
      "epoch": 341.58,
      "learning_rate": 1.585504407443683e-05,
      "loss": 2.3536,
      "step": 2790000
    },
    {
      "epoch": 342.19,
      "learning_rate": 1.5793854064642507e-05,
      "loss": 2.3575,
      "step": 2795000
    },
    {
      "epoch": 342.8,
      "learning_rate": 1.573266405484819e-05,
      "loss": 2.3606,
      "step": 2800000
    },
    {
      "epoch": 343.41,
      "learning_rate": 1.567147404505387e-05,
      "loss": 2.357,
      "step": 2805000
    },
    {
      "epoch": 344.03,
      "learning_rate": 1.561025954946131e-05,
      "loss": 2.3606,
      "step": 2810000
    },
    {
      "epoch": 344.64,
      "learning_rate": 1.5549057296767875e-05,
      "loss": 2.3487,
      "step": 2815000
    },
    {
      "epoch": 345.25,
      "learning_rate": 1.5487855044074436e-05,
      "loss": 2.3511,
      "step": 2820000
    },
    {
      "epoch": 345.86,
      "learning_rate": 1.5426665034280118e-05,
      "loss": 2.3559,
      "step": 2825000
    },
    {
      "epoch": 346.47,
      "learning_rate": 1.5365487267384918e-05,
      "loss": 2.3488,
      "step": 2830000
    },
    {
      "epoch": 347.09,
      "learning_rate": 1.5304309500489715e-05,
      "loss": 2.3526,
      "step": 2835000
    },
    {
      "epoch": 347.7,
      "learning_rate": 1.524309500489716e-05,
      "loss": 2.3431,
      "step": 2840000
    },
    {
      "epoch": 348.31,
      "learning_rate": 1.5181929480901078e-05,
      "loss": 2.3458,
      "step": 2845000
    },
    {
      "epoch": 348.92,
      "learning_rate": 1.5120763956904996e-05,
      "loss": 2.3559,
      "step": 2850000
    },
    {
      "epoch": 349.53,
      "learning_rate": 1.5059561704211558e-05,
      "loss": 2.344,
      "step": 2855000
    },
    {
      "epoch": 350.15,
      "learning_rate": 1.4998347208619001e-05,
      "loss": 2.3469,
      "step": 2860000
    },
    {
      "epoch": 350.76,
      "learning_rate": 1.4937157198824683e-05,
      "loss": 2.3434,
      "step": 2865000
    },
    {
      "epoch": 351.37,
      "learning_rate": 1.4875954946131245e-05,
      "loss": 2.3433,
      "step": 2870000
    },
    {
      "epoch": 351.98,
      "learning_rate": 1.4814764936336926e-05,
      "loss": 2.3481,
      "step": 2875000
    },
    {
      "epoch": 352.6,
      "learning_rate": 1.4753599412340844e-05,
      "loss": 2.3374,
      "step": 2880000
    },
    {
      "epoch": 353.21,
      "learning_rate": 1.4692421645445642e-05,
      "loss": 2.3518,
      "step": 2885000
    },
    {
      "epoch": 353.82,
      "learning_rate": 1.4631219392752205e-05,
      "loss": 2.3432,
      "step": 2890000
    },
    {
      "epoch": 354.43,
      "learning_rate": 1.4570004897159648e-05,
      "loss": 2.334,
      "step": 2895000
    },
    {
      "epoch": 355.04,
      "learning_rate": 1.450881488736533e-05,
      "loss": 2.3426,
      "step": 2900000
    },
    {
      "epoch": 355.66,
      "learning_rate": 1.4447600391772773e-05,
      "loss": 2.325,
      "step": 2905000
    },
    {
      "epoch": 356.27,
      "learning_rate": 1.4386398139079335e-05,
      "loss": 2.3325,
      "step": 2910000
    },
    {
      "epoch": 356.88,
      "learning_rate": 1.4325220372184133e-05,
      "loss": 2.3352,
      "step": 2915000
    },
    {
      "epoch": 357.49,
      "learning_rate": 1.4264005876591576e-05,
      "loss": 2.3289,
      "step": 2920000
    },
    {
      "epoch": 358.1,
      "learning_rate": 1.4202815866797258e-05,
      "loss": 2.3317,
      "step": 2925000
    },
    {
      "epoch": 358.72,
      "learning_rate": 1.4141674828599414e-05,
      "loss": 2.3299,
      "step": 2930000
    },
    {
      "epoch": 359.33,
      "learning_rate": 1.4080472575905977e-05,
      "loss": 2.3283,
      "step": 2935000
    },
    {
      "epoch": 359.94,
      "learning_rate": 1.4019270323212539e-05,
      "loss": 2.3332,
      "step": 2940000
    },
    {
      "epoch": 360.55,
      "learning_rate": 1.3958080313418218e-05,
      "loss": 2.3192,
      "step": 2945000
    },
    {
      "epoch": 361.17,
      "learning_rate": 1.38968903036239e-05,
      "loss": 2.3336,
      "step": 2950000
    },
    {
      "epoch": 361.78,
      "learning_rate": 1.3835700293829579e-05,
      "loss": 2.3239,
      "step": 2955000
    },
    {
      "epoch": 362.39,
      "learning_rate": 1.3774498041136141e-05,
      "loss": 2.3222,
      "step": 2960000
    },
    {
      "epoch": 363.0,
      "learning_rate": 1.3713295788442703e-05,
      "loss": 2.3313,
      "step": 2965000
    },
    {
      "epoch": 363.61,
      "learning_rate": 1.3652105778648386e-05,
      "loss": 2.3172,
      "step": 2970000
    },
    {
      "epoch": 364.23,
      "learning_rate": 1.3590903525954946e-05,
      "loss": 2.3208,
      "step": 2975000
    },
    {
      "epoch": 364.84,
      "learning_rate": 1.3529713516160627e-05,
      "loss": 2.3235,
      "step": 2980000
    },
    {
      "epoch": 365.45,
      "learning_rate": 1.3468547992164545e-05,
      "loss": 2.3135,
      "step": 2985000
    },
    {
      "epoch": 366.06,
      "learning_rate": 1.340733349657199e-05,
      "loss": 2.3201,
      "step": 2990000
    },
    {
      "epoch": 366.67,
      "learning_rate": 1.3346155729676788e-05,
      "loss": 2.3153,
      "step": 2995000
    },
    {
      "epoch": 367.29,
      "learning_rate": 1.328494123408423e-05,
      "loss": 2.3179,
      "step": 3000000
    },
    {
      "epoch": 367.9,
      "learning_rate": 1.3223787952987268e-05,
      "loss": 2.3172,
      "step": 3005000
    },
    {
      "epoch": 368.51,
      "learning_rate": 1.3162585700293831e-05,
      "loss": 2.3099,
      "step": 3010000
    },
    {
      "epoch": 369.12,
      "learning_rate": 1.3101383447600393e-05,
      "loss": 2.3175,
      "step": 3015000
    },
    {
      "epoch": 369.74,
      "learning_rate": 1.3040205680705192e-05,
      "loss": 2.3093,
      "step": 3020000
    },
    {
      "epoch": 370.35,
      "learning_rate": 1.2979003428011754e-05,
      "loss": 2.3127,
      "step": 3025000
    },
    {
      "epoch": 370.96,
      "learning_rate": 1.2917788932419197e-05,
      "loss": 2.3128,
      "step": 3030000
    },
    {
      "epoch": 371.57,
      "learning_rate": 1.285658667972576e-05,
      "loss": 2.3048,
      "step": 3035000
    },
    {
      "epoch": 372.18,
      "learning_rate": 1.279540891283056e-05,
      "loss": 2.3087,
      "step": 3040000
    },
    {
      "epoch": 372.8,
      "learning_rate": 1.2734231145935358e-05,
      "loss": 2.309,
      "step": 3045000
    },
    {
      "epoch": 373.41,
      "learning_rate": 1.267304113614104e-05,
      "loss": 2.2992,
      "step": 3050000
    },
    {
      "epoch": 374.02,
      "learning_rate": 1.2611851126346719e-05,
      "loss": 2.3061,
      "step": 3055000
    },
    {
      "epoch": 374.63,
      "learning_rate": 1.2550648873653281e-05,
      "loss": 2.2998,
      "step": 3060000
    },
    {
      "epoch": 375.24,
      "learning_rate": 1.2489495592556317e-05,
      "loss": 2.3106,
      "step": 3065000
    },
    {
      "epoch": 375.86,
      "learning_rate": 1.2428281096963762e-05,
      "loss": 2.3031,
      "step": 3070000
    },
    {
      "epoch": 376.47,
      "learning_rate": 1.2367078844270324e-05,
      "loss": 2.2996,
      "step": 3075000
    },
    {
      "epoch": 377.08,
      "learning_rate": 1.230591332027424e-05,
      "loss": 2.302,
      "step": 3080000
    },
    {
      "epoch": 377.69,
      "learning_rate": 1.2244723310479921e-05,
      "loss": 2.2949,
      "step": 3085000
    },
    {
      "epoch": 378.31,
      "learning_rate": 1.2183521057786485e-05,
      "loss": 2.2983,
      "step": 3090000
    },
    {
      "epoch": 378.92,
      "learning_rate": 1.2122355533790403e-05,
      "loss": 2.3018,
      "step": 3095000
    },
    {
      "epoch": 379.53,
      "learning_rate": 1.2061165523996084e-05,
      "loss": 2.2914,
      "step": 3100000
    },
    {
      "epoch": 380.14,
      "learning_rate": 1.1999963271302645e-05,
      "loss": 2.297,
      "step": 3105000
    },
    {
      "epoch": 380.75,
      "learning_rate": 1.1938785504407445e-05,
      "loss": 2.2976,
      "step": 3110000
    },
    {
      "epoch": 381.37,
      "learning_rate": 1.1877571008814887e-05,
      "loss": 2.2918,
      "step": 3115000
    },
    {
      "epoch": 381.98,
      "learning_rate": 1.1816356513222332e-05,
      "loss": 2.298,
      "step": 3120000
    },
    {
      "epoch": 382.59,
      "learning_rate": 1.1755154260528894e-05,
      "loss": 2.2888,
      "step": 3125000
    },
    {
      "epoch": 383.2,
      "learning_rate": 1.1693952007835455e-05,
      "loss": 2.2946,
      "step": 3130000
    },
    {
      "epoch": 383.81,
      "learning_rate": 1.1632749755142018e-05,
      "loss": 2.2897,
      "step": 3135000
    },
    {
      "epoch": 384.43,
      "learning_rate": 1.1571584231145936e-05,
      "loss": 2.2848,
      "step": 3140000
    },
    {
      "epoch": 385.04,
      "learning_rate": 1.1510381978452498e-05,
      "loss": 2.2957,
      "step": 3145000
    },
    {
      "epoch": 385.65,
      "learning_rate": 1.1449167482859943e-05,
      "loss": 2.2829,
      "step": 3150000
    },
    {
      "epoch": 386.26,
      "learning_rate": 1.1387977473065623e-05,
      "loss": 2.2854,
      "step": 3155000
    },
    {
      "epoch": 386.88,
      "learning_rate": 1.1326787463271303e-05,
      "loss": 2.2805,
      "step": 3160000
    },
    {
      "epoch": 387.49,
      "learning_rate": 1.1265597453476984e-05,
      "loss": 2.2838,
      "step": 3165000
    },
    {
      "epoch": 388.1,
      "learning_rate": 1.1204419686581782e-05,
      "loss": 2.2844,
      "step": 3170000
    },
    {
      "epoch": 388.71,
      "learning_rate": 1.1143205190989227e-05,
      "loss": 2.2785,
      "step": 3175000
    },
    {
      "epoch": 389.32,
      "learning_rate": 1.1082027424094025e-05,
      "loss": 2.2816,
      "step": 3180000
    },
    {
      "epoch": 389.94,
      "learning_rate": 1.1020837414299706e-05,
      "loss": 2.2819,
      "step": 3185000
    },
    {
      "epoch": 390.55,
      "learning_rate": 1.0959647404505386e-05,
      "loss": 2.2766,
      "step": 3190000
    },
    {
      "epoch": 391.16,
      "learning_rate": 1.0898457394711068e-05,
      "loss": 2.2761,
      "step": 3195000
    },
    {
      "epoch": 391.77,
      "learning_rate": 1.0837267384916749e-05,
      "loss": 2.2767,
      "step": 3200000
    },
    {
      "epoch": 392.38,
      "learning_rate": 1.0776101860920667e-05,
      "loss": 2.2715,
      "step": 3205000
    },
    {
      "epoch": 393.0,
      "learning_rate": 1.071489960822723e-05,
      "loss": 2.2792,
      "step": 3210000
    },
    {
      "epoch": 393.61,
      "learning_rate": 1.0653697355533792e-05,
      "loss": 2.2691,
      "step": 3215000
    },
    {
      "epoch": 394.22,
      "learning_rate": 1.059251958863859e-05,
      "loss": 2.2706,
      "step": 3220000
    },
    {
      "epoch": 394.83,
      "learning_rate": 1.0531305093046035e-05,
      "loss": 2.2721,
      "step": 3225000
    },
    {
      "epoch": 395.45,
      "learning_rate": 1.0470090597453477e-05,
      "loss": 2.2634,
      "step": 3230000
    },
    {
      "epoch": 396.06,
      "learning_rate": 2.5255570519098925e-05,
      "loss": 7.1622,
      "step": 3235000
    },
    {
      "epoch": 396.67,
      "learning_rate": 2.5217319111165528e-05,
      "loss": 6.3919,
      "step": 3240000
    },
    {
      "epoch": 397.28,
      "learning_rate": 2.5179067703232127e-05,
      "loss": 5.769,
      "step": 3245000
    },
    {
      "epoch": 397.89,
      "learning_rate": 2.5140831598922628e-05,
      "loss": 5.4024,
      "step": 3250000
    },
    {
      "epoch": 398.51,
      "learning_rate": 2.5102580190989227e-05,
      "loss": 5.1455,
      "step": 3255000
    },
    {
      "epoch": 399.12,
      "learning_rate": 2.506433643486778e-05,
      "loss": 4.9601,
      "step": 3260000
    },
    {
      "epoch": 399.73,
      "learning_rate": 2.5026100330558278e-05,
      "loss": 4.8083,
      "step": 3265000
    },
    {
      "epoch": 400.34,
      "learning_rate": 2.4987856574436828e-05,
      "loss": 4.6752,
      "step": 3270000
    },
    {
      "epoch": 400.95,
      "learning_rate": 2.4949612818315378e-05,
      "loss": 4.5744,
      "step": 3275000
    },
    {
      "epoch": 401.57,
      "learning_rate": 2.491136141038198e-05,
      "loss": 4.4612,
      "step": 3280000
    },
    {
      "epoch": 402.18,
      "learning_rate": 2.4873125306072478e-05,
      "loss": 4.377,
      "step": 3285000
    },
    {
      "epoch": 402.79,
      "learning_rate": 2.483488920176298e-05,
      "loss": 4.2922,
      "step": 3290000
    },
    {
      "epoch": 403.4,
      "learning_rate": 2.479663779382958e-05,
      "loss": 4.2165,
      "step": 3295000
    },
    {
      "epoch": 404.02,
      "learning_rate": 2.475838638589618e-05,
      "loss": 4.149,
      "step": 3300000
    },
    {
      "epoch": 404.63,
      "learning_rate": 2.4720150281586682e-05,
      "loss": 4.0688,
      "step": 3305000
    },
    {
      "epoch": 405.24,
      "learning_rate": 2.4681898873653285e-05,
      "loss": 4.0133,
      "step": 3310000
    },
    {
      "epoch": 405.85,
      "learning_rate": 2.464365511753183e-05,
      "loss": 3.9597,
      "step": 3315000
    },
    {
      "epoch": 406.46,
      "learning_rate": 2.460541136141038e-05,
      "loss": 3.9008,
      "step": 3320000
    },
    {
      "epoch": 407.08,
      "learning_rate": 2.4567159953476984e-05,
      "loss": 3.863,
      "step": 3325000
    },
    {
      "epoch": 407.69,
      "learning_rate": 2.4528939152791383e-05,
      "loss": 3.806,
      "step": 3330000
    },
    {
      "epoch": 408.3,
      "learning_rate": 2.4490680093046035e-05,
      "loss": 3.7628,
      "step": 3335000
    },
    {
      "epoch": 408.91,
      "learning_rate": 2.4452436336924585e-05,
      "loss": 3.736,
      "step": 3340000
    },
    {
      "epoch": 409.52,
      "learning_rate": 2.4414192580803135e-05,
      "loss": 3.6901,
      "step": 3345000
    },
    {
      "epoch": 410.14,
      "learning_rate": 2.4375948824681685e-05,
      "loss": 3.6605,
      "step": 3350000
    },
    {
      "epoch": 410.75,
      "learning_rate": 2.433770506856024e-05,
      "loss": 3.6297,
      "step": 3355000
    },
    {
      "epoch": 411.36,
      "learning_rate": 2.429946131243879e-05,
      "loss": 3.5981,
      "step": 3360000
    },
    {
      "epoch": 411.97,
      "learning_rate": 2.4261217556317335e-05,
      "loss": 3.5771,
      "step": 3365000
    },
    {
      "epoch": 412.59,
      "learning_rate": 2.4223012059255634e-05,
      "loss": 3.537,
      "step": 3370000
    },
    {
      "epoch": 413.2,
      "learning_rate": 2.4184760651322234e-05,
      "loss": 3.5201,
      "step": 3375000
    },
    {
      "epoch": 413.81,
      "learning_rate": 2.4146501591576887e-05,
      "loss": 3.4968,
      "step": 3380000
    },
    {
      "epoch": 414.42,
      "learning_rate": 2.410825018364349e-05,
      "loss": 3.4682,
      "step": 3385000
    },
    {
      "epoch": 415.03,
      "learning_rate": 2.4070037034769835e-05,
      "loss": 3.4598,
      "step": 3390000
    },
    {
      "epoch": 415.65,
      "learning_rate": 2.4031777975024487e-05,
      "loss": 3.4267,
      "step": 3395000
    },
    {
      "epoch": 416.26,
      "learning_rate": 2.3993541870714988e-05,
      "loss": 3.407,
      "step": 3400000
    },
    {
      "epoch": 416.87,
      "learning_rate": 2.3955290462781587e-05,
      "loss": 3.3977,
      "step": 3405000
    },
    {
      "epoch": 417.48,
      "learning_rate": 2.391703905484819e-05,
      "loss": 3.3694,
      "step": 3410000
    },
    {
      "epoch": 418.1,
      "learning_rate": 2.3878810602350638e-05,
      "loss": 3.3633,
      "step": 3415000
    },
    {
      "epoch": 418.71,
      "learning_rate": 2.3840559194417237e-05,
      "loss": 3.3436,
      "step": 3420000
    },
    {
      "epoch": 419.32,
      "learning_rate": 2.3802323090107738e-05,
      "loss": 3.3246,
      "step": 3425000
    },
    {
      "epoch": 419.93,
      "learning_rate": 2.376409463761019e-05,
      "loss": 3.324,
      "step": 3430000
    },
    {
      "epoch": 420.54,
      "learning_rate": 2.372584322967679e-05,
      "loss": 3.2938,
      "step": 3435000
    },
    {
      "epoch": 421.16,
      "learning_rate": 2.368758416993144e-05,
      "loss": 3.288,
      "step": 3440000
    },
    {
      "epoch": 421.77,
      "learning_rate": 2.364934041380999e-05,
      "loss": 3.2692,
      "step": 3445000
    },
    {
      "epoch": 422.38,
      "learning_rate": 2.3611089005876594e-05,
      "loss": 3.2536,
      "step": 3450000
    },
    {
      "epoch": 422.99,
      "learning_rate": 2.357285290156709e-05,
      "loss": 3.2542,
      "step": 3455000
    },
    {
      "epoch": 423.6,
      "learning_rate": 2.3534601493633694e-05,
      "loss": 3.2254,
      "step": 3460000
    },
    {
      "epoch": 424.22,
      "learning_rate": 2.3496357737512244e-05,
      "loss": 3.2228,
      "step": 3465000
    },
    {
      "epoch": 424.83,
      "learning_rate": 2.3458106329578847e-05,
      "loss": 3.2116,
      "step": 3470000
    },
    {
      "epoch": 425.44,
      "learning_rate": 2.3419847269833497e-05,
      "loss": 3.197,
      "step": 3475000
    },
    {
      "epoch": 426.05,
      "learning_rate": 2.3381618817335944e-05,
      "loss": 3.1955,
      "step": 3480000
    },
    {
      "epoch": 426.67,
      "learning_rate": 2.3343367409402547e-05,
      "loss": 3.1707,
      "step": 3485000
    },
    {
      "epoch": 427.28,
      "learning_rate": 2.330511600146915e-05,
      "loss": 3.1646,
      "step": 3490000
    },
    {
      "epoch": 427.89,
      "learning_rate": 2.326687989715965e-05,
      "loss": 3.162,
      "step": 3495000
    },
    {
      "epoch": 428.5,
      "learning_rate": 2.3228651444662098e-05,
      "loss": 3.1424,
      "step": 3500000
    },
    {
      "epoch": 429.11,
      "learning_rate": 2.3190400036728698e-05,
      "loss": 3.139,
      "step": 3505000
    },
    {
      "epoch": 429.73,
      "learning_rate": 2.315214097698335e-05,
      "loss": 3.1229,
      "step": 3510000
    },
    {
      "epoch": 430.34,
      "learning_rate": 2.3113881917238003e-05,
      "loss": 3.1171,
      "step": 3515000
    },
    {
      "epoch": 430.95,
      "learning_rate": 2.307565346474045e-05,
      "loss": 3.1145,
      "step": 3520000
    },
    {
      "epoch": 431.56,
      "learning_rate": 2.3037409708619e-05,
      "loss": 3.0933,
      "step": 3525000
    },
    {
      "epoch": 432.17,
      "learning_rate": 2.29991736043095e-05,
      "loss": 3.0941,
      "step": 3530000
    },
    {
      "epoch": 432.79,
      "learning_rate": 2.2960922196376104e-05,
      "loss": 3.0862,
      "step": 3535000
    },
    {
      "epoch": 433.4,
      "learning_rate": 2.2922670788442704e-05,
      "loss": 3.0768,
      "step": 3540000
    },
    {
      "epoch": 434.01,
      "learning_rate": 2.2884434684133204e-05,
      "loss": 3.0756,
      "step": 3545000
    },
    {
      "epoch": 434.62,
      "learning_rate": 2.2846183276199807e-05,
      "loss": 3.0551,
      "step": 3550000
    },
    {
      "epoch": 435.24,
      "learning_rate": 2.2807947171890304e-05,
      "loss": 3.0544,
      "step": 3555000
    },
    {
      "epoch": 435.85,
      "learning_rate": 2.2769703415768854e-05,
      "loss": 3.0466,
      "step": 3560000
    },
    {
      "epoch": 436.46,
      "learning_rate": 2.2731452007835457e-05,
      "loss": 3.0357,
      "step": 3565000
    },
    {
      "epoch": 437.07,
      "learning_rate": 2.269319294809011e-05,
      "loss": 3.036,
      "step": 3570000
    },
    {
      "epoch": 437.68,
      "learning_rate": 2.2654949191968657e-05,
      "loss": 3.0219,
      "step": 3575000
    },
    {
      "epoch": 438.3,
      "learning_rate": 2.261669778403526e-05,
      "loss": 3.0187,
      "step": 3580000
    },
    {
      "epoch": 438.91,
      "learning_rate": 2.2578454027913813e-05,
      "loss": 3.0134,
      "step": 3585000
    },
    {
      "epoch": 439.52,
      "learning_rate": 2.254021792360431e-05,
      "loss": 2.9984,
      "step": 3590000
    },
    {
      "epoch": 440.13,
      "learning_rate": 2.250197416748286e-05,
      "loss": 3.0012,
      "step": 3595000
    },
    {
      "epoch": 440.74,
      "learning_rate": 2.246373041136141e-05,
      "loss": 2.9912,
      "step": 3600000
    },
    {
      "epoch": 441.36,
      "learning_rate": 2.242548665523996e-05,
      "loss": 2.9881,
      "step": 3605000
    },
    {
      "epoch": 441.97,
      "learning_rate": 2.2387242899118514e-05,
      "loss": 2.9858,
      "step": 3610000
    },
    {
      "epoch": 442.58,
      "learning_rate": 2.2348999142997064e-05,
      "loss": 2.9746,
      "step": 3615000
    },
    {
      "epoch": 443.19,
      "learning_rate": 2.231075538687561e-05,
      "loss": 2.9725,
      "step": 3620000
    },
    {
      "epoch": 443.81,
      "learning_rate": 2.2272511630754164e-05,
      "loss": 2.9621,
      "step": 3625000
    },
    {
      "epoch": 444.42,
      "learning_rate": 2.2234267874632714e-05,
      "loss": 2.9514,
      "step": 3630000
    },
    {
      "epoch": 445.03,
      "learning_rate": 2.2196016466699314e-05,
      "loss": 2.9618,
      "step": 3635000
    },
    {
      "epoch": 445.64,
      "learning_rate": 2.2157765058765917e-05,
      "loss": 2.9434,
      "step": 3640000
    },
    {
      "epoch": 446.25,
      "learning_rate": 2.211951365083252e-05,
      "loss": 2.9414,
      "step": 3645000
    },
    {
      "epoch": 446.87,
      "learning_rate": 2.208127754652302e-05,
      "loss": 2.9378,
      "step": 3650000
    },
    {
      "epoch": 447.48,
      "learning_rate": 2.2043033790401567e-05,
      "loss": 2.9278,
      "step": 3655000
    },
    {
      "epoch": 448.09,
      "learning_rate": 2.200477473065622e-05,
      "loss": 2.9296,
      "step": 3660000
    },
    {
      "epoch": 448.7,
      "learning_rate": 2.196654627815867e-05,
      "loss": 2.9172,
      "step": 3665000
    },
    {
      "epoch": 449.31,
      "learning_rate": 2.192830252203722e-05,
      "loss": 2.9133,
      "step": 3670000
    },
    {
      "epoch": 449.93,
      "learning_rate": 2.189006641772772e-05,
      "loss": 2.9141,
      "step": 3675000
    },
    {
      "epoch": 450.54,
      "learning_rate": 2.185181500979432e-05,
      "loss": 2.8977,
      "step": 3680000
    },
    {
      "epoch": 451.15,
      "learning_rate": 2.1813578905484818e-05,
      "loss": 2.9031,
      "step": 3685000
    },
    {
      "epoch": 451.76,
      "learning_rate": 2.1775342801175318e-05,
      "loss": 2.9009,
      "step": 3690000
    },
    {
      "epoch": 452.38,
      "learning_rate": 2.1737083741429974e-05,
      "loss": 2.8903,
      "step": 3695000
    },
    {
      "epoch": 452.99,
      "learning_rate": 2.169884763712047e-05,
      "loss": 2.8941,
      "step": 3700000
    },
    {
      "epoch": 453.6,
      "learning_rate": 2.166060388099902e-05,
      "loss": 2.8744,
      "step": 3705000
    },
    {
      "epoch": 454.21,
      "learning_rate": 2.1622344821253674e-05,
      "loss": 2.8769,
      "step": 3710000
    },
    {
      "epoch": 454.82,
      "learning_rate": 2.1584085761508327e-05,
      "loss": 2.8743,
      "step": 3715000
    },
    {
      "epoch": 455.44,
      "learning_rate": 2.1545849657198824e-05,
      "loss": 2.8636,
      "step": 3720000
    },
    {
      "epoch": 456.05,
      "learning_rate": 2.1507605901077377e-05,
      "loss": 2.8723,
      "step": 3725000
    },
    {
      "epoch": 456.66,
      "learning_rate": 2.1469354493143977e-05,
      "loss": 2.8557,
      "step": 3730000
    },
    {
      "epoch": 457.27,
      "learning_rate": 2.1431118388834477e-05,
      "loss": 2.8572,
      "step": 3735000
    },
    {
      "epoch": 457.88,
      "learning_rate": 2.1392874632713027e-05,
      "loss": 2.8549,
      "step": 3740000
    },
    {
      "epoch": 458.5,
      "learning_rate": 2.135461557296768e-05,
      "loss": 2.8428,
      "step": 3745000
    },
    {
      "epoch": 459.11,
      "learning_rate": 2.131637181684623e-05,
      "loss": 2.8486,
      "step": 3750000
    },
    {
      "epoch": 459.72,
      "learning_rate": 2.1278135712536727e-05,
      "loss": 2.8364,
      "step": 3755000
    },
    {
      "epoch": 460.33,
      "learning_rate": 2.123988430460333e-05,
      "loss": 2.8366,
      "step": 3760000
    },
    {
      "epoch": 460.95,
      "learning_rate": 2.1201655852105778e-05,
      "loss": 2.8357,
      "step": 3765000
    },
    {
      "epoch": 461.56,
      "learning_rate": 2.116341209598433e-05,
      "loss": 2.8185,
      "step": 3770000
    },
    {
      "epoch": 462.17,
      "learning_rate": 2.112517599167483e-05,
      "loss": 2.8283,
      "step": 3775000
    },
    {
      "epoch": 462.78,
      "learning_rate": 2.108691693192948e-05,
      "loss": 2.8188,
      "step": 3780000
    },
    {
      "epoch": 463.39,
      "learning_rate": 2.1048665523996084e-05,
      "loss": 2.8106,
      "step": 3785000
    },
    {
      "epoch": 464.01,
      "learning_rate": 2.1010414116062683e-05,
      "loss": 2.8159,
      "step": 3790000
    },
    {
      "epoch": 464.62,
      "learning_rate": 2.0972155056317336e-05,
      "loss": 2.8003,
      "step": 3795000
    },
    {
      "epoch": 465.23,
      "learning_rate": 2.0933918952007836e-05,
      "loss": 2.803,
      "step": 3800000
    },
    {
      "epoch": 465.84,
      "learning_rate": 2.0895675195886387e-05,
      "loss": 2.8087,
      "step": 3805000
    },
    {
      "epoch": 466.45,
      "learning_rate": 2.0857423787952986e-05,
      "loss": 2.791,
      "step": 3810000
    },
    {
      "epoch": 467.07,
      "learning_rate": 2.0819187683643487e-05,
      "loss": 2.7965,
      "step": 3815000
    },
    {
      "epoch": 467.68,
      "learning_rate": 2.0780966882957885e-05,
      "loss": 2.7855,
      "step": 3820000
    },
    {
      "epoch": 468.29,
      "learning_rate": 2.0742715475024488e-05,
      "loss": 2.7821,
      "step": 3825000
    },
    {
      "epoch": 468.9,
      "learning_rate": 2.0704479370714985e-05,
      "loss": 2.7839,
      "step": 3830000
    },
    {
      "epoch": 469.52,
      "learning_rate": 2.0666220310969637e-05,
      "loss": 2.7752,
      "step": 3835000
    },
    {
      "epoch": 470.13,
      "learning_rate": 2.062796890303624e-05,
      "loss": 2.779,
      "step": 3840000
    },
    {
      "epoch": 470.74,
      "learning_rate": 2.058973279872674e-05,
      "loss": 2.7722,
      "step": 3845000
    },
    {
      "epoch": 471.35,
      "learning_rate": 2.055148139079334e-05,
      "loss": 2.7663,
      "step": 3850000
    },
    {
      "epoch": 471.96,
      "learning_rate": 2.051322998285994e-05,
      "loss": 2.7724,
      "step": 3855000
    },
    {
      "epoch": 472.58,
      "learning_rate": 2.047500918217434e-05,
      "loss": 2.7535,
      "step": 3860000
    },
    {
      "epoch": 473.19,
      "learning_rate": 2.0436788381488736e-05,
      "loss": 2.7655,
      "step": 3865000
    },
    {
      "epoch": 473.8,
      "learning_rate": 2.039852932174339e-05,
      "loss": 2.7557,
      "step": 3870000
    },
    {
      "epoch": 474.41,
      "learning_rate": 2.0360277913809992e-05,
      "loss": 2.7481,
      "step": 3875000
    },
    {
      "epoch": 475.02,
      "learning_rate": 2.032202650587659e-05,
      "loss": 2.7572,
      "step": 3880000
    },
    {
      "epoch": 475.64,
      "learning_rate": 2.028380570519099e-05,
      "loss": 2.7391,
      "step": 3885000
    },
    {
      "epoch": 476.25,
      "learning_rate": 2.0245546645445642e-05,
      "loss": 2.7472,
      "step": 3890000
    },
    {
      "epoch": 476.86,
      "learning_rate": 2.0207295237512245e-05,
      "loss": 2.7389,
      "step": 3895000
    },
    {
      "epoch": 477.47,
      "learning_rate": 2.0169036177766894e-05,
      "loss": 2.731,
      "step": 3900000
    },
    {
      "epoch": 478.09,
      "learning_rate": 2.0130807725269345e-05,
      "loss": 2.7387,
      "step": 3905000
    },
    {
      "epoch": 478.7,
      "learning_rate": 2.0092563969147895e-05,
      "loss": 2.7302,
      "step": 3910000
    },
    {
      "epoch": 479.31,
      "learning_rate": 2.0054312561214498e-05,
      "loss": 2.7262,
      "step": 3915000
    },
    {
      "epoch": 479.92,
      "learning_rate": 2.0016061153281098e-05,
      "loss": 2.7349,
      "step": 3920000
    },
    {
      "epoch": 480.53,
      "learning_rate": 1.99778097453477e-05,
      "loss": 2.7171,
      "step": 3925000
    },
    {
      "epoch": 481.15,
      "learning_rate": 1.99395583374143e-05,
      "loss": 2.7257,
      "step": 3930000
    },
    {
      "epoch": 481.76,
      "learning_rate": 1.99013375367287e-05,
      "loss": 2.7156,
      "step": 3935000
    },
    {
      "epoch": 482.37,
      "learning_rate": 1.986309378060725e-05,
      "loss": 2.7151,
      "step": 3940000
    },
    {
      "epoch": 482.98,
      "learning_rate": 1.9824842372673848e-05,
      "loss": 2.7195,
      "step": 3945000
    },
    {
      "epoch": 483.59,
      "learning_rate": 1.97865986165524e-05,
      "loss": 2.7024,
      "step": 3950000
    },
    {
      "epoch": 484.21,
      "learning_rate": 1.9748347208619005e-05,
      "loss": 2.71,
      "step": 3955000
    },
    {
      "epoch": 484.82,
      "learning_rate": 1.9710095800685604e-05,
      "loss": 2.7057,
      "step": 3960000
    },
    {
      "epoch": 485.43,
      "learning_rate": 1.96718596963761e-05,
      "loss": 2.6948,
      "step": 3965000
    },
    {
      "epoch": 486.04,
      "learning_rate": 1.963363124387855e-05,
      "loss": 2.7018,
      "step": 3970000
    },
    {
      "epoch": 486.66,
      "learning_rate": 1.9595372184133205e-05,
      "loss": 2.6882,
      "step": 3975000
    },
    {
      "epoch": 487.27,
      "learning_rate": 1.9557120776199804e-05,
      "loss": 2.6945,
      "step": 3980000
    },
    {
      "epoch": 487.88,
      "learning_rate": 1.9518861716454457e-05,
      "loss": 2.6883,
      "step": 3985000
    },
    {
      "epoch": 488.49,
      "learning_rate": 1.9480625612144957e-05,
      "loss": 2.6839,
      "step": 3990000
    },
    {
      "epoch": 489.1,
      "learning_rate": 1.9442412463271303e-05,
      "loss": 2.7001,
      "step": 3995000
    },
    {
      "epoch": 489.72,
      "learning_rate": 1.940415340352596e-05,
      "loss": 2.6796,
      "step": 4000000
    },
    {
      "epoch": 490.33,
      "learning_rate": 1.9365917299216456e-05,
      "loss": 2.68,
      "step": 4005000
    },
    {
      "epoch": 490.94,
      "learning_rate": 1.9327665891283055e-05,
      "loss": 2.6828,
      "step": 4010000
    },
    {
      "epoch": 491.55,
      "learning_rate": 1.9289414483349658e-05,
      "loss": 2.6657,
      "step": 4015000
    },
    {
      "epoch": 492.16,
      "learning_rate": 1.9251163075416258e-05,
      "loss": 2.6755,
      "step": 4020000
    },
    {
      "epoch": 492.78,
      "learning_rate": 1.921291166748286e-05,
      "loss": 2.6661,
      "step": 4025000
    },
    {
      "epoch": 493.39,
      "learning_rate": 1.917466791136141e-05,
      "loss": 2.6671,
      "step": 4030000
    },
    {
      "epoch": 494.0,
      "learning_rate": 1.9136439458863862e-05,
      "loss": 2.6707,
      "step": 4035000
    },
    {
      "epoch": 494.61,
      "learning_rate": 1.909818039911851e-05,
      "loss": 2.6528,
      "step": 4040000
    },
    {
      "epoch": 495.23,
      "learning_rate": 1.9059928991185114e-05,
      "loss": 2.6658,
      "step": 4045000
    },
    {
      "epoch": 495.84,
      "learning_rate": 1.902171584231146e-05,
      "loss": 2.6618,
      "step": 4050000
    },
    {
      "epoch": 496.45,
      "learning_rate": 1.8983464434378062e-05,
      "loss": 2.6524,
      "step": 4055000
    },
    {
      "epoch": 497.06,
      "learning_rate": 1.8945213026444665e-05,
      "loss": 2.6581,
      "step": 4060000
    },
    {
      "epoch": 497.67,
      "learning_rate": 1.8906984573947113e-05,
      "loss": 2.6459,
      "step": 4065000
    },
    {
      "epoch": 498.29,
      "learning_rate": 1.8868725514201762e-05,
      "loss": 2.6461,
      "step": 4070000
    },
    {
      "epoch": 498.9,
      "learning_rate": 1.8830474106268365e-05,
      "loss": 2.6495,
      "step": 4075000
    },
    {
      "epoch": 499.51,
      "learning_rate": 1.8792222698334964e-05,
      "loss": 2.6416,
      "step": 4080000
    },
    {
      "epoch": 500.12,
      "learning_rate": 1.8753971290401567e-05,
      "loss": 2.6442,
      "step": 4085000
    },
    {
      "epoch": 500.73,
      "learning_rate": 1.871572753428012e-05,
      "loss": 2.6377,
      "step": 4090000
    },
    {
      "epoch": 501.35,
      "learning_rate": 1.8677491429970618e-05,
      "loss": 2.6319,
      "step": 4095000
    },
    {
      "epoch": 501.96,
      "learning_rate": 1.8639240022037218e-05,
      "loss": 2.6406,
      "step": 4100000
    },
    {
      "epoch": 502.57,
      "learning_rate": 1.860099626591577e-05,
      "loss": 2.627,
      "step": 4105000
    },
    {
      "epoch": 503.18,
      "learning_rate": 1.8562760161606268e-05,
      "loss": 2.6332,
      "step": 4110000
    },
    {
      "epoch": 503.8,
      "learning_rate": 1.8524516405484822e-05,
      "loss": 2.6271,
      "step": 4115000
    },
    {
      "epoch": 504.41,
      "learning_rate": 1.848625734573947e-05,
      "loss": 2.6214,
      "step": 4120000
    },
    {
      "epoch": 505.02,
      "learning_rate": 1.8448005937806074e-05,
      "loss": 2.6286,
      "step": 4125000
    },
    {
      "epoch": 505.63,
      "learning_rate": 1.8409769833496574e-05,
      "loss": 2.6141,
      "step": 4130000
    },
    {
      "epoch": 506.24,
      "learning_rate": 1.8371526077375124e-05,
      "loss": 2.6197,
      "step": 4135000
    },
    {
      "epoch": 506.86,
      "learning_rate": 1.833328997306562e-05,
      "loss": 2.6231,
      "step": 4140000
    },
    {
      "epoch": 507.47,
      "learning_rate": 1.8295038565132225e-05,
      "loss": 2.6128,
      "step": 4145000
    },
    {
      "epoch": 508.08,
      "learning_rate": 1.8256787157198828e-05,
      "loss": 2.6173,
      "step": 4150000
    },
    {
      "epoch": 508.69,
      "learning_rate": 1.8218543401077374e-05,
      "loss": 2.6054,
      "step": 4155000
    },
    {
      "epoch": 509.3,
      "learning_rate": 1.8180291993143977e-05,
      "loss": 2.614,
      "step": 4160000
    },
    {
      "epoch": 509.92,
      "learning_rate": 1.814204058521058e-05,
      "loss": 2.6105,
      "step": 4165000
    },
    {
      "epoch": 510.53,
      "learning_rate": 1.810380448090108e-05,
      "loss": 2.6016,
      "step": 4170000
    },
    {
      "epoch": 511.14,
      "learning_rate": 1.8065560724779627e-05,
      "loss": 2.6087,
      "step": 4175000
    },
    {
      "epoch": 511.75,
      "learning_rate": 1.802730166503428e-05,
      "loss": 2.6046,
      "step": 4180000
    },
    {
      "epoch": 512.37,
      "learning_rate": 1.7989057908912833e-05,
      "loss": 2.5954,
      "step": 4185000
    },
    {
      "epoch": 512.98,
      "learning_rate": 1.7950806500979433e-05,
      "loss": 2.5996,
      "step": 4190000
    },
    {
      "epoch": 513.59,
      "learning_rate": 1.7912555093046036e-05,
      "loss": 2.5859,
      "step": 4195000
    },
    {
      "epoch": 514.2,
      "learning_rate": 1.7874311336924586e-05,
      "loss": 2.5958,
      "step": 4200000
    },
    {
      "epoch": 514.81,
      "learning_rate": 1.7836067580803133e-05,
      "loss": 2.5888,
      "step": 4205000
    },
    {
      "epoch": 515.43,
      "learning_rate": 1.7797823824681686e-05,
      "loss": 2.5831,
      "step": 4210000
    },
    {
      "epoch": 516.04,
      "learning_rate": 1.775957241674829e-05,
      "loss": 2.591,
      "step": 4215000
    },
    {
      "epoch": 516.65,
      "learning_rate": 1.7721359267874634e-05,
      "loss": 2.582,
      "step": 4220000
    },
    {
      "epoch": 517.26,
      "learning_rate": 1.768312316356513e-05,
      "loss": 2.5855,
      "step": 4225000
    },
    {
      "epoch": 517.87,
      "learning_rate": 1.7644864103819787e-05,
      "loss": 2.5805,
      "step": 4230000
    },
    {
      "epoch": 518.49,
      "learning_rate": 1.7606620347698334e-05,
      "loss": 2.5735,
      "step": 4235000
    },
    {
      "epoch": 519.1,
      "learning_rate": 1.7568376591576884e-05,
      "loss": 2.581,
      "step": 4240000
    },
    {
      "epoch": 519.71,
      "learning_rate": 1.7530125183643487e-05,
      "loss": 2.5763,
      "step": 4245000
    },
    {
      "epoch": 520.32,
      "learning_rate": 1.7491873775710087e-05,
      "loss": 2.5733,
      "step": 4250000
    },
    {
      "epoch": 520.94,
      "learning_rate": 1.745363001958864e-05,
      "loss": 2.5732,
      "step": 4255000
    },
    {
      "epoch": 521.55,
      "learning_rate": 1.7415401567091088e-05,
      "loss": 2.5637,
      "step": 4260000
    },
    {
      "epoch": 522.16,
      "learning_rate": 1.737714250734574e-05,
      "loss": 2.569,
      "step": 4265000
    },
    {
      "epoch": 522.77,
      "learning_rate": 1.733889109941234e-05,
      "loss": 2.5676,
      "step": 4270000
    },
    {
      "epoch": 523.38,
      "learning_rate": 1.730065499510284e-05,
      "loss": 2.5586,
      "step": 4275000
    },
    {
      "epoch": 524.0,
      "learning_rate": 1.726243419441724e-05,
      "loss": 2.5683,
      "step": 4280000
    },
    {
      "epoch": 524.61,
      "learning_rate": 1.7224182786483838e-05,
      "loss": 2.5556,
      "step": 4285000
    },
    {
      "epoch": 525.22,
      "learning_rate": 1.7185923726738494e-05,
      "loss": 2.5591,
      "step": 4290000
    },
    {
      "epoch": 525.83,
      "learning_rate": 1.714767997061704e-05,
      "loss": 2.5614,
      "step": 4295000
    },
    {
      "epoch": 526.44,
      "learning_rate": 1.710944386630754e-05,
      "loss": 2.5529,
      "step": 4300000
    },
    {
      "epoch": 527.06,
      "learning_rate": 1.7071192458374144e-05,
      "loss": 2.5587,
      "step": 4305000
    },
    {
      "epoch": 527.67,
      "learning_rate": 1.7032956354064645e-05,
      "loss": 2.5488,
      "step": 4310000
    },
    {
      "epoch": 528.28,
      "learning_rate": 1.6994704946131244e-05,
      "loss": 2.5512,
      "step": 4315000
    },
    {
      "epoch": 528.89,
      "learning_rate": 1.6956453538197847e-05,
      "loss": 2.5567,
      "step": 4320000
    },
    {
      "epoch": 529.51,
      "learning_rate": 3.67672930950049e-05,
      "loss": 2.6372,
      "step": 4325000
    },
    {
      "epoch": 530.12,
      "learning_rate": 3.6751992531831545e-05,
      "loss": 2.6872,
      "step": 4330000
    },
    {
      "epoch": 530.73,
      "learning_rate": 3.67367042115573e-05,
      "loss": 2.6936,
      "step": 4335000
    },
    {
      "epoch": 531.34,
      "learning_rate": 3.6721400587659164e-05,
      "loss": 2.6996,
      "step": 4340000
    },
    {
      "epoch": 531.95,
      "learning_rate": 3.67061000244858e-05,
      "loss": 2.7146,
      "step": 4345000
    },
    {
      "epoch": 532.57,
      "learning_rate": 3.6690796400587665e-05,
      "loss": 2.6972,
      "step": 4350000
    },
    {
      "epoch": 533.18,
      "learning_rate": 3.667549889813908e-05,
      "loss": 2.7116,
      "step": 4355000
    },
    {
      "epoch": 533.79,
      "learning_rate": 3.666020751714006e-05,
      "loss": 2.7098,
      "step": 4360000
    },
    {
      "epoch": 534.4,
      "learning_rate": 3.66449222575906e-05,
      "loss": 2.7071,
      "step": 4365000
    },
    {
      "epoch": 535.01,
      "learning_rate": 3.662962169441724e-05,
      "loss": 2.7235,
      "step": 4370000
    },
    {
      "epoch": 535.63,
      "learning_rate": 3.66143180705191e-05,
      "loss": 2.7006,
      "step": 4375000
    },
    {
      "epoch": 536.24,
      "learning_rate": 3.659901444662096e-05,
      "loss": 2.7088,
      "step": 4380000
    },
    {
      "epoch": 536.85,
      "learning_rate": 3.65837138834476e-05,
      "loss": 2.7108,
      "step": 4385000
    },
    {
      "epoch": 537.46,
      "learning_rate": 3.656841638099902e-05,
      "loss": 2.7003,
      "step": 4390000
    },
    {
      "epoch": 538.08,
      "learning_rate": 3.655312193927522e-05,
      "loss": 2.7143,
      "step": 4395000
    },
    {
      "epoch": 538.69,
      "learning_rate": 3.653782443682664e-05,
      "loss": 2.6997,
      "step": 4400000
    },
    {
      "epoch": 539.3,
      "learning_rate": 3.652252387365328e-05,
      "loss": 2.7066,
      "step": 4405000
    },
    {
      "epoch": 539.91,
      "learning_rate": 3.650722331047992e-05,
      "loss": 2.7124,
      "step": 4410000
    },
    {
      "epoch": 540.52,
      "learning_rate": 3.649192580803134e-05,
      "loss": 2.696,
      "step": 4415000
    },
    {
      "epoch": 541.14,
      "learning_rate": 3.6476625244857985e-05,
      "loss": 2.7091,
      "step": 4420000
    },
    {
      "epoch": 541.75,
      "learning_rate": 3.6461327742409406e-05,
      "loss": 2.6983,
      "step": 4425000
    },
    {
      "epoch": 542.36,
      "learning_rate": 3.6446027179236044e-05,
      "loss": 2.6963,
      "step": 4430000
    },
    {
      "epoch": 542.97,
      "learning_rate": 3.6430735798237025e-05,
      "loss": 2.7014,
      "step": 4435000
    },
    {
      "epoch": 543.58,
      "learning_rate": 3.641543523506366e-05,
      "loss": 2.6828,
      "step": 4440000
    },
    {
      "epoch": 544.2,
      "learning_rate": 3.64001499755142e-05,
      "loss": 2.7037,
      "step": 4445000
    },
    {
      "epoch": 544.81,
      "learning_rate": 3.638484941234084e-05,
      "loss": 2.6925,
      "step": 4450000
    },
    {
      "epoch": 545.42,
      "learning_rate": 3.6369548849167487e-05,
      "loss": 2.687,
      "step": 4455000
    },
    {
      "epoch": 546.03,
      "learning_rate": 3.6354248285994125e-05,
      "loss": 2.7048,
      "step": 4460000
    },
    {
      "epoch": 546.65,
      "learning_rate": 3.6338947722820763e-05,
      "loss": 2.6779,
      "step": 4465000
    },
    {
      "epoch": 547.26,
      "learning_rate": 3.6323650220372185e-05,
      "loss": 2.6923,
      "step": 4470000
    },
    {
      "epoch": 547.87,
      "learning_rate": 3.630834965719882e-05,
      "loss": 2.6892,
      "step": 4475000
    },
    {
      "epoch": 548.48,
      "learning_rate": 3.6293046033300686e-05,
      "loss": 2.6714,
      "step": 4480000
    },
    {
      "epoch": 549.09,
      "learning_rate": 3.6277754652301666e-05,
      "loss": 2.6902,
      "step": 4485000
    },
    {
      "epoch": 549.71,
      "learning_rate": 3.6262463271302647e-05,
      "loss": 2.685,
      "step": 4490000
    },
    {
      "epoch": 550.32,
      "learning_rate": 3.62471596474045e-05,
      "loss": 2.6788,
      "step": 4495000
    },
    {
      "epoch": 550.93,
      "learning_rate": 3.6231865205680706e-05,
      "loss": 2.687,
      "step": 4500000
    },
    {
      "epoch": 551.54,
      "learning_rate": 3.621656770323213e-05,
      "loss": 2.6719,
      "step": 4505000
    },
    {
      "epoch": 552.15,
      "learning_rate": 3.6201279382957884e-05,
      "loss": 2.6797,
      "step": 4510000
    },
    {
      "epoch": 552.77,
      "learning_rate": 3.618597575905975e-05,
      "loss": 2.6739,
      "step": 4515000
    },
    {
      "epoch": 553.38,
      "learning_rate": 3.617067519588639e-05,
      "loss": 2.6685,
      "step": 4520000
    },
    {
      "epoch": 553.99,
      "learning_rate": 3.6155377693437807e-05,
      "loss": 2.6842,
      "step": 4525000
    },
    {
      "epoch": 554.6,
      "learning_rate": 3.614008019098923e-05,
      "loss": 2.657,
      "step": 4530000
    },
    {
      "epoch": 555.22,
      "learning_rate": 3.612477656709109e-05,
      "loss": 2.6707,
      "step": 4535000
    },
    {
      "epoch": 555.83,
      "learning_rate": 3.610947600391773e-05,
      "loss": 2.6671,
      "step": 4540000
    },
    {
      "epoch": 556.44,
      "learning_rate": 3.609417850146915e-05,
      "loss": 2.6594,
      "step": 4545000
    },
    {
      "epoch": 557.05,
      "learning_rate": 3.607888099902057e-05,
      "loss": 2.6737,
      "step": 4550000
    },
    {
      "epoch": 557.66,
      "learning_rate": 3.606358349657199e-05,
      "loss": 2.6576,
      "step": 4555000
    },
    {
      "epoch": 558.28,
      "learning_rate": 3.604828599412341e-05,
      "loss": 2.6587,
      "step": 4560000
    },
    {
      "epoch": 558.89,
      "learning_rate": 3.603298543095005e-05,
      "loss": 2.6602,
      "step": 4565000
    },
    {
      "epoch": 559.5,
      "learning_rate": 3.601768486777669e-05,
      "loss": 2.6499,
      "step": 4570000
    },
    {
      "epoch": 560.11,
      "learning_rate": 3.600238736532811e-05,
      "loss": 2.6631,
      "step": 4575000
    },
    {
      "epoch": 560.72,
      "learning_rate": 3.598709292360431e-05,
      "loss": 2.6506,
      "step": 4580000
    },
    {
      "epoch": 561.34,
      "learning_rate": 3.597178929970617e-05,
      "loss": 2.6513,
      "step": 4585000
    },
    {
      "epoch": 561.95,
      "learning_rate": 3.5956491797257594e-05,
      "loss": 2.6586,
      "step": 4590000
    },
    {
      "epoch": 562.56,
      "learning_rate": 3.594119429480901e-05,
      "loss": 2.6434,
      "step": 4595000
    },
    {
      "epoch": 563.17,
      "learning_rate": 3.5925893731635654e-05,
      "loss": 2.6504,
      "step": 4600000
    },
    {
      "epoch": 563.79,
      "learning_rate": 3.591059316846229e-05,
      "loss": 2.6467,
      "step": 4605000
    },
    {
      "epoch": 564.4,
      "learning_rate": 3.5895304848188056e-05,
      "loss": 2.6428,
      "step": 4610000
    },
    {
      "epoch": 565.01,
      "learning_rate": 3.588000122428991e-05,
      "loss": 2.653,
      "step": 4615000
    },
    {
      "epoch": 565.62,
      "learning_rate": 3.586470372184134e-05,
      "loss": 2.6328,
      "step": 4620000
    },
    {
      "epoch": 566.23,
      "learning_rate": 3.5849406219392754e-05,
      "loss": 2.642,
      "step": 4625000
    },
    {
      "epoch": 566.85,
      "learning_rate": 3.5834108716944175e-05,
      "loss": 2.6444,
      "step": 4630000
    },
    {
      "epoch": 567.46,
      "learning_rate": 3.58188112144956e-05,
      "loss": 2.6354,
      "step": 4635000
    },
    {
      "epoch": 568.07,
      "learning_rate": 3.580352289422135e-05,
      "loss": 2.644,
      "step": 4640000
    },
    {
      "epoch": 568.68,
      "learning_rate": 3.5788219270323216e-05,
      "loss": 2.629,
      "step": 4645000
    },
    {
      "epoch": 569.29,
      "learning_rate": 3.5772918707149854e-05,
      "loss": 2.6333,
      "step": 4650000
    },
    {
      "epoch": 569.91,
      "learning_rate": 3.575762426542605e-05,
      "loss": 2.6415,
      "step": 4655000
    },
    {
      "epoch": 570.52,
      "learning_rate": 3.5742329823702256e-05,
      "loss": 2.6242,
      "step": 4660000
    },
    {
      "epoch": 571.13,
      "learning_rate": 3.572702619980411e-05,
      "loss": 2.6348,
      "step": 4665000
    },
    {
      "epoch": 571.74,
      "learning_rate": 3.571172563663076e-05,
      "loss": 2.6237,
      "step": 4670000
    },
    {
      "epoch": 572.36,
      "learning_rate": 3.5696431194906954e-05,
      "loss": 2.6254,
      "step": 4675000
    },
    {
      "epoch": 572.97,
      "learning_rate": 3.5681133692458376e-05,
      "loss": 2.6361,
      "step": 4680000
    },
    {
      "epoch": 573.58,
      "learning_rate": 3.56658361900098e-05,
      "loss": 2.6121,
      "step": 4685000
    },
    {
      "epoch": 574.19,
      "learning_rate": 3.565053256611165e-05,
      "loss": 2.6231,
      "step": 4690000
    },
    {
      "epoch": 574.8,
      "learning_rate": 3.563523812438786e-05,
      "loss": 2.6217,
      "step": 4695000
    },
    {
      "epoch": 575.42,
      "learning_rate": 3.5619937561214495e-05,
      "loss": 2.613,
      "step": 4700000
    },
    {
      "epoch": 576.03,
      "learning_rate": 3.5604640058765923e-05,
      "loss": 2.6304,
      "step": 4705000
    },
    {
      "epoch": 576.64,
      "learning_rate": 3.558933949559256e-05,
      "loss": 2.6068,
      "step": 4710000
    },
    {
      "epoch": 577.25,
      "learning_rate": 3.557404199314398e-05,
      "loss": 2.6191,
      "step": 4715000
    },
    {
      "epoch": 577.86,
      "learning_rate": 3.555874755142018e-05,
      "loss": 2.6199,
      "step": 4720000
    },
    {
      "epoch": 578.48,
      "learning_rate": 3.55434500489716e-05,
      "loss": 2.6092,
      "step": 4725000
    },
    {
      "epoch": 579.09,
      "learning_rate": 3.552814948579824e-05,
      "loss": 2.6176,
      "step": 4730000
    },
    {
      "epoch": 579.7,
      "learning_rate": 3.551285504407444e-05,
      "loss": 2.6061,
      "step": 4735000
    },
    {
      "epoch": 580.31,
      "learning_rate": 3.549756366307542e-05,
      "loss": 2.6121,
      "step": 4740000
    },
    {
      "epoch": 580.93,
      "learning_rate": 3.548226616062684e-05,
      "loss": 2.6244,
      "step": 4745000
    },
    {
      "epoch": 581.54,
      "learning_rate": 3.5466962536728696e-05,
      "loss": 2.6017,
      "step": 4750000
    },
    {
      "epoch": 582.15,
      "learning_rate": 3.545166503428012e-05,
      "loss": 2.6143,
      "step": 4755000
    },
    {
      "epoch": 582.76,
      "learning_rate": 3.5436370592556314e-05,
      "loss": 2.6087,
      "step": 4760000
    },
    {
      "epoch": 583.37,
      "learning_rate": 3.542106696865818e-05,
      "loss": 2.6072,
      "step": 4765000
    },
    {
      "epoch": 583.99,
      "learning_rate": 3.54057694662096e-05,
      "loss": 2.6147,
      "step": 4770000
    },
    {
      "epoch": 584.6,
      "learning_rate": 3.539047196376102e-05,
      "loss": 2.5939,
      "step": 4775000
    },
    {
      "epoch": 585.21,
      "learning_rate": 3.537516833986288e-05,
      "loss": 2.605,
      "step": 4780000
    },
    {
      "epoch": 585.82,
      "learning_rate": 3.535988308031342e-05,
      "loss": 2.6026,
      "step": 4785000
    },
    {
      "epoch": 586.43,
      "learning_rate": 3.5344579456415284e-05,
      "loss": 2.5978,
      "step": 4790000
    },
    {
      "epoch": 587.05,
      "learning_rate": 3.532927583251714e-05,
      "loss": 2.6076,
      "step": 4795000
    },
    {
      "epoch": 587.66,
      "learning_rate": 3.531397526934378e-05,
      "loss": 2.5913,
      "step": 4800000
    },
    {
      "epoch": 588.27,
      "learning_rate": 3.529868082761998e-05,
      "loss": 2.5964,
      "step": 4805000
    },
    {
      "epoch": 588.88,
      "learning_rate": 3.5283383325171403e-05,
      "loss": 2.5993,
      "step": 4810000
    },
    {
      "epoch": 589.5,
      "learning_rate": 3.5268085822722825e-05,
      "loss": 2.5906,
      "step": 4815000
    },
    {
      "epoch": 590.11,
      "learning_rate": 3.525278219882469e-05,
      "loss": 2.6006,
      "step": 4820000
    },
    {
      "epoch": 590.72,
      "learning_rate": 3.5237487757100885e-05,
      "loss": 2.5877,
      "step": 4825000
    },
    {
      "epoch": 591.33,
      "learning_rate": 3.522218413320275e-05,
      "loss": 2.5916,
      "step": 4830000
    },
    {
      "epoch": 591.94,
      "learning_rate": 3.5206889691478945e-05,
      "loss": 2.6008,
      "step": 4835000
    },
    {
      "epoch": 592.56,
      "learning_rate": 3.5191592189030366e-05,
      "loss": 2.5769,
      "step": 4840000
    },
    {
      "epoch": 593.17,
      "learning_rate": 3.517629468658179e-05,
      "loss": 2.5914,
      "step": 4845000
    },
    {
      "epoch": 593.78,
      "learning_rate": 3.5160994123408426e-05,
      "loss": 2.5841,
      "step": 4850000
    },
    {
      "epoch": 594.39,
      "learning_rate": 3.514569968168462e-05,
      "loss": 2.5835,
      "step": 4855000
    },
    {
      "epoch": 595.0,
      "learning_rate": 3.513039911851126e-05,
      "loss": 2.5971,
      "step": 4860000
    },
    {
      "epoch": 595.62,
      "learning_rate": 3.511509855533791e-05,
      "loss": 2.5728,
      "step": 4865000
    },
    {
      "epoch": 596.23,
      "learning_rate": 3.5099804113614105e-05,
      "loss": 2.585,
      "step": 4870000
    },
    {
      "epoch": 596.84,
      "learning_rate": 3.508450048971597e-05,
      "loss": 2.5822,
      "step": 4875000
    },
    {
      "epoch": 597.45,
      "learning_rate": 3.506920298726739e-05,
      "loss": 2.5737,
      "step": 4880000
    },
    {
      "epoch": 598.07,
      "learning_rate": 3.5053908545543586e-05,
      "loss": 2.5871,
      "step": 4885000
    },
    {
      "epoch": 598.68,
      "learning_rate": 3.503861410381978e-05,
      "loss": 2.5736,
      "step": 4890000
    },
    {
      "epoch": 599.29,
      "learning_rate": 3.502331354064642e-05,
      "loss": 2.5751,
      "step": 4895000
    },
    {
      "epoch": 599.9,
      "learning_rate": 3.500801297747307e-05,
      "loss": 2.5799,
      "step": 4900000
    },
    {
      "epoch": 600.51,
      "learning_rate": 3.499271853574927e-05,
      "loss": 2.5703,
      "step": 4905000
    },
    {
      "epoch": 601.13,
      "learning_rate": 3.4977421033300686e-05,
      "loss": 2.5801,
      "step": 4910000
    },
    {
      "epoch": 601.74,
      "learning_rate": 3.496212353085211e-05,
      "loss": 2.571,
      "step": 4915000
    },
    {
      "epoch": 602.35,
      "learning_rate": 3.494682296767875e-05,
      "loss": 2.5684,
      "step": 4920000
    },
    {
      "epoch": 602.96,
      "learning_rate": 3.493151934378061e-05,
      "loss": 2.5793,
      "step": 4925000
    },
    {
      "epoch": 603.57,
      "learning_rate": 3.491622184133203e-05,
      "loss": 2.5592,
      "step": 4930000
    },
    {
      "epoch": 604.19,
      "learning_rate": 3.490092433888345e-05,
      "loss": 2.5731,
      "step": 4935000
    },
    {
      "epoch": 604.8,
      "learning_rate": 3.488562377571009e-05,
      "loss": 2.5656,
      "step": 4940000
    },
    {
      "epoch": 605.41,
      "learning_rate": 3.4870335455435846e-05,
      "loss": 2.5602,
      "step": 4945000
    },
    {
      "epoch": 606.02,
      "learning_rate": 3.485504713516161e-05,
      "loss": 2.5802,
      "step": 4950000
    },
    {
      "epoch": 606.64,
      "learning_rate": 3.4839749632713024e-05,
      "loss": 2.5676,
      "step": 4955000
    },
    {
      "epoch": 607.25,
      "learning_rate": 3.4824452130264445e-05,
      "loss": 2.5779,
      "step": 4960000
    },
    {
      "epoch": 607.86,
      "learning_rate": 3.480914850636631e-05,
      "loss": 2.5714,
      "step": 4965000
    },
    {
      "epoch": 608.47,
      "learning_rate": 3.479384488246817e-05,
      "loss": 2.5527,
      "step": 4970000
    },
    {
      "epoch": 609.08,
      "learning_rate": 3.477854431929481e-05,
      "loss": 2.5702,
      "step": 4975000
    },
    {
      "epoch": 609.7,
      "learning_rate": 3.4763252938295796e-05,
      "loss": 2.559,
      "step": 4980000
    },
    {
      "epoch": 610.31,
      "learning_rate": 3.474795543584721e-05,
      "loss": 2.5567,
      "step": 4985000
    },
    {
      "epoch": 610.92,
      "learning_rate": 3.4732651811949066e-05,
      "loss": 2.5665,
      "step": 4990000
    },
    {
      "epoch": 611.53,
      "learning_rate": 3.471735737022527e-05,
      "loss": 2.551,
      "step": 4995000
    },
    {
      "epoch": 612.14,
      "learning_rate": 3.470205374632713e-05,
      "loss": 2.5623,
      "step": 5000000
    },
    {
      "epoch": 612.76,
      "learning_rate": 3.4686756243878554e-05,
      "loss": 2.5519,
      "step": 5005000
    },
    {
      "epoch": 613.37,
      "learning_rate": 3.4671458741429975e-05,
      "loss": 2.5526,
      "step": 5010000
    },
    {
      "epoch": 613.98,
      "learning_rate": 3.46561612389814e-05,
      "loss": 2.5639,
      "step": 5015000
    },
    {
      "epoch": 614.59,
      "learning_rate": 3.464086373653281e-05,
      "loss": 2.5415,
      "step": 5020000
    },
    {
      "epoch": 615.21,
      "learning_rate": 3.462556623408423e-05,
      "loss": 2.5548,
      "step": 5025000
    },
    {
      "epoch": 615.82,
      "learning_rate": 3.461026567091087e-05,
      "loss": 2.5552,
      "step": 5030000
    },
    {
      "epoch": 616.43,
      "learning_rate": 3.459497428991185e-05,
      "loss": 2.5446,
      "step": 5035000
    },
    {
      "epoch": 617.04,
      "learning_rate": 3.4579670666013714e-05,
      "loss": 2.5597,
      "step": 5040000
    },
    {
      "epoch": 617.65,
      "learning_rate": 3.456438540646425e-05,
      "loss": 2.5464,
      "step": 5045000
    },
    {
      "epoch": 618.27,
      "learning_rate": 3.454909096474046e-05,
      "loss": 2.5533,
      "step": 5050000
    },
    {
      "epoch": 618.88,
      "learning_rate": 3.453378734084231e-05,
      "loss": 2.5543,
      "step": 5055000
    },
    {
      "epoch": 619.49,
      "learning_rate": 3.451848677766895e-05,
      "loss": 2.5466,
      "step": 5060000
    },
    {
      "epoch": 620.1,
      "learning_rate": 3.4503198457394715e-05,
      "loss": 2.5868,
      "step": 5065000
    },
    {
      "epoch": 620.71,
      "learning_rate": 3.448789789422135e-05,
      "loss": 2.5451,
      "step": 5070000
    },
    {
      "epoch": 621.33,
      "learning_rate": 3.4472594270323216e-05,
      "loss": 2.5456,
      "step": 5075000
    },
    {
      "epoch": 621.94,
      "learning_rate": 3.445729982859941e-05,
      "loss": 2.5546,
      "step": 5080000
    },
    {
      "epoch": 622.55,
      "learning_rate": 3.4442008447600394e-05,
      "loss": 2.5644,
      "step": 5085000
    },
    {
      "epoch": 623.16,
      "learning_rate": 3.4426704823702256e-05,
      "loss": 2.5469,
      "step": 5090000
    },
    {
      "epoch": 623.78,
      "learning_rate": 3.441140732125368e-05,
      "loss": 2.5425,
      "step": 5095000
    },
    {
      "epoch": 624.39,
      "learning_rate": 3.439610369735553e-05,
      "loss": 2.5358,
      "step": 5100000
    },
    {
      "epoch": 625.0,
      "learning_rate": 3.438080313418218e-05,
      "loss": 2.5534,
      "step": 5105000
    },
    {
      "epoch": 625.61,
      "learning_rate": 3.436550257100882e-05,
      "loss": 2.5277,
      "step": 5110000
    },
    {
      "epoch": 626.22,
      "learning_rate": 3.435020506856024e-05,
      "loss": 2.546,
      "step": 5115000
    },
    {
      "epoch": 626.84,
      "learning_rate": 3.433490756611166e-05,
      "loss": 2.5433,
      "step": 5120000
    },
    {
      "epoch": 627.45,
      "learning_rate": 3.4319603942213515e-05,
      "loss": 2.5307,
      "step": 5125000
    },
    {
      "epoch": 628.06,
      "learning_rate": 3.430430337904016e-05,
      "loss": 2.5429,
      "step": 5130000
    },
    {
      "epoch": 628.67,
      "learning_rate": 3.428900587659158e-05,
      "loss": 2.5245,
      "step": 5135000
    },
    {
      "epoch": 629.29,
      "learning_rate": 3.4273708374142996e-05,
      "loss": 2.5341,
      "step": 5140000
    },
    {
      "epoch": 629.9,
      "learning_rate": 3.425840781096964e-05,
      "loss": 2.5408,
      "step": 5145000
    },
    {
      "epoch": 630.51,
      "learning_rate": 3.424310724779628e-05,
      "loss": 2.5245,
      "step": 5150000
    },
    {
      "epoch": 631.12,
      "learning_rate": 3.42278097453477e-05,
      "loss": 2.5347,
      "step": 5155000
    },
    {
      "epoch": 631.73,
      "learning_rate": 3.42125153036239e-05,
      "loss": 2.5264,
      "step": 5160000
    },
    {
      "epoch": 632.35,
      "learning_rate": 3.4197220861900097e-05,
      "loss": 2.5258,
      "step": 5165000
    },
    {
      "epoch": 632.96,
      "learning_rate": 3.4181929480901084e-05,
      "loss": 2.5411,
      "step": 5170000
    },
    {
      "epoch": 633.57,
      "learning_rate": 3.416662891772772e-05,
      "loss": 2.5194,
      "step": 5175000
    },
    {
      "epoch": 634.18,
      "learning_rate": 3.415132835455436e-05,
      "loss": 2.5297,
      "step": 5180000
    },
    {
      "epoch": 634.79,
      "learning_rate": 3.4136033912830565e-05,
      "loss": 2.5256,
      "step": 5185000
    },
    {
      "epoch": 635.41,
      "learning_rate": 3.412073641038198e-05,
      "loss": 2.5219,
      "step": 5190000
    },
    {
      "epoch": 636.02,
      "learning_rate": 3.4105441968658184e-05,
      "loss": 2.5405,
      "step": 5195000
    },
    {
      "epoch": 636.63,
      "learning_rate": 3.409013834476004e-05,
      "loss": 2.5162,
      "step": 5200000
    },
    {
      "epoch": 637.24,
      "learning_rate": 3.40748347208619e-05,
      "loss": 2.5225,
      "step": 5205000
    },
    {
      "epoch": 637.86,
      "learning_rate": 3.405953415768855e-05,
      "loss": 2.5245,
      "step": 5210000
    },
    {
      "epoch": 638.47,
      "learning_rate": 3.404424277668952e-05,
      "loss": 2.5125,
      "step": 5215000
    },
    {
      "epoch": 639.08,
      "learning_rate": 3.4028942213516166e-05,
      "loss": 2.5305,
      "step": 5220000
    },
    {
      "epoch": 639.69,
      "learning_rate": 3.401365083251714e-05,
      "loss": 2.515,
      "step": 5225000
    },
    {
      "epoch": 640.3,
      "learning_rate": 3.3998347208619e-05,
      "loss": 2.517,
      "step": 5230000
    },
    {
      "epoch": 640.92,
      "learning_rate": 3.398304664544564e-05,
      "loss": 2.5247,
      "step": 5235000
    },
    {
      "epoch": 641.53,
      "learning_rate": 3.396775526444662e-05,
      "loss": 2.5081,
      "step": 5240000
    },
    {
      "epoch": 642.14,
      "learning_rate": 3.395246082272282e-05,
      "loss": 2.5255,
      "step": 5245000
    },
    {
      "epoch": 642.75,
      "learning_rate": 3.393716638099902e-05,
      "loss": 2.5233,
      "step": 5250000
    },
    {
      "epoch": 643.36,
      "learning_rate": 3.3921868878550444e-05,
      "loss": 2.5189,
      "step": 5255000
    },
    {
      "epoch": 643.98,
      "learning_rate": 3.3906565254652306e-05,
      "loss": 2.5261,
      "step": 5260000
    },
    {
      "epoch": 644.59,
      "learning_rate": 3.389126163075416e-05,
      "loss": 2.5104,
      "step": 5265000
    },
    {
      "epoch": 645.2,
      "learning_rate": 3.3875958006856024e-05,
      "loss": 2.5128,
      "step": 5270000
    },
    {
      "epoch": 645.81,
      "learning_rate": 3.386066356513222e-05,
      "loss": 2.5106,
      "step": 5275000
    },
    {
      "epoch": 646.43,
      "learning_rate": 3.384536300195886e-05,
      "loss": 2.5051,
      "step": 5280000
    },
    {
      "epoch": 647.04,
      "learning_rate": 3.3830062438785506e-05,
      "loss": 2.5176,
      "step": 5285000
    },
    {
      "epoch": 647.65,
      "learning_rate": 3.381476799706171e-05,
      "loss": 2.5017,
      "step": 5290000
    },
    {
      "epoch": 648.26,
      "learning_rate": 3.3799476616062683e-05,
      "loss": 2.5076,
      "step": 5295000
    },
    {
      "epoch": 648.87,
      "learning_rate": 3.3784172992164546e-05,
      "loss": 2.5106,
      "step": 5300000
    },
    {
      "epoch": 649.49,
      "learning_rate": 3.376887548971597e-05,
      "loss": 2.4992,
      "step": 5305000
    },
    {
      "epoch": 650.1,
      "learning_rate": 3.3753574926542606e-05,
      "loss": 2.5136,
      "step": 5310000
    },
    {
      "epoch": 650.71,
      "learning_rate": 3.3738283545543586e-05,
      "loss": 2.4979,
      "step": 5315000
    },
    {
      "epoch": 651.32,
      "learning_rate": 3.372298604309501e-05,
      "loss": 2.5044,
      "step": 5320000
    },
    {
      "epoch": 651.93,
      "learning_rate": 3.370768854064643e-05,
      "loss": 2.5142,
      "step": 5325000
    },
    {
      "epoch": 652.55,
      "learning_rate": 3.3692394098922626e-05,
      "loss": 2.4973,
      "step": 5330000
    },
    {
      "epoch": 653.16,
      "learning_rate": 3.367709659647405e-05,
      "loss": 2.5091,
      "step": 5335000
    },
    {
      "epoch": 653.77,
      "learning_rate": 3.3661796033300686e-05,
      "loss": 2.5,
      "step": 5340000
    },
    {
      "epoch": 654.38,
      "learning_rate": 3.3646501591576884e-05,
      "loss": 2.4994,
      "step": 5345000
    },
    {
      "epoch": 655.0,
      "learning_rate": 3.3631197967678746e-05,
      "loss": 2.5115,
      "step": 5350000
    },
    {
      "epoch": 655.61,
      "learning_rate": 3.361590046523017e-05,
      "loss": 2.4893,
      "step": 5355000
    },
    {
      "epoch": 656.22,
      "learning_rate": 3.3600599902056806e-05,
      "loss": 2.5019,
      "step": 5360000
    },
    {
      "epoch": 656.83,
      "learning_rate": 3.3585299338883444e-05,
      "loss": 2.4968,
      "step": 5365000
    },
    {
      "epoch": 657.44,
      "learning_rate": 3.357000489715965e-05,
      "loss": 2.4906,
      "step": 5370000
    },
    {
      "epoch": 658.06,
      "learning_rate": 3.3554704333986294e-05,
      "loss": 2.5057,
      "step": 5375000
    },
    {
      "epoch": 658.67,
      "learning_rate": 3.353940683153771e-05,
      "loss": 2.4892,
      "step": 5380000
    },
    {
      "epoch": 659.28,
      "learning_rate": 3.352411238981391e-05,
      "loss": 2.4972,
      "step": 5385000
    },
    {
      "epoch": 659.89,
      "learning_rate": 3.3508808765915775e-05,
      "loss": 2.5001,
      "step": 5390000
    },
    {
      "epoch": 660.5,
      "learning_rate": 3.349351126346719e-05,
      "loss": 2.4878,
      "step": 5395000
    },
    {
      "epoch": 661.12,
      "learning_rate": 3.3478210700293835e-05,
      "loss": 2.4998,
      "step": 5400000
    },
    {
      "epoch": 661.73,
      "learning_rate": 3.346291625857003e-05,
      "loss": 2.4907,
      "step": 5405000
    },
    {
      "epoch": 662.34,
      "learning_rate": 3.344761569539667e-05,
      "loss": 2.4916,
      "step": 5410000
    },
    {
      "epoch": 662.95,
      "learning_rate": 3.3432333496571987e-05,
      "loss": 2.5078,
      "step": 5415000
    },
    {
      "epoch": 663.57,
      "learning_rate": 3.341702987267385e-05,
      "loss": 2.4838,
      "step": 5420000
    },
    {
      "epoch": 664.18,
      "learning_rate": 3.340172624877571e-05,
      "loss": 2.4921,
      "step": 5425000
    },
    {
      "epoch": 664.79,
      "learning_rate": 3.338643180705191e-05,
      "loss": 2.4919,
      "step": 5430000
    },
    {
      "epoch": 665.4,
      "learning_rate": 3.337113124387855e-05,
      "loss": 2.4851,
      "step": 5435000
    },
    {
      "epoch": 666.01,
      "learning_rate": 3.335583068070519e-05,
      "loss": 2.4981,
      "step": 5440000
    },
    {
      "epoch": 666.63,
      "learning_rate": 3.3340527056807055e-05,
      "loss": 2.4796,
      "step": 5445000
    },
    {
      "epoch": 667.24,
      "learning_rate": 3.332523261508325e-05,
      "loss": 2.4907,
      "step": 5450000
    },
    {
      "epoch": 667.85,
      "learning_rate": 3.330993205190989e-05,
      "loss": 2.4916,
      "step": 5455000
    },
    {
      "epoch": 668.46,
      "learning_rate": 3.329463454946131e-05,
      "loss": 2.4774,
      "step": 5460000
    },
    {
      "epoch": 669.07,
      "learning_rate": 3.3279337047012734e-05,
      "loss": 2.4889,
      "step": 5465000
    },
    {
      "epoch": 669.69,
      "learning_rate": 3.3264039544564155e-05,
      "loss": 2.4769,
      "step": 5470000
    },
    {
      "epoch": 670.3,
      "learning_rate": 3.324875122428991e-05,
      "loss": 2.4835,
      "step": 5475000
    },
    {
      "epoch": 670.91,
      "learning_rate": 3.323345372184133e-05,
      "loss": 2.5014,
      "step": 5480000
    },
    {
      "epoch": 671.52,
      "learning_rate": 3.3218156219392754e-05,
      "loss": 2.4875,
      "step": 5485000
    },
    {
      "epoch": 672.14,
      "learning_rate": 3.320285565621939e-05,
      "loss": 2.4873,
      "step": 5490000
    },
    {
      "epoch": 672.75,
      "learning_rate": 3.3187552032321255e-05,
      "loss": 2.4794,
      "step": 5495000
    },
    {
      "epoch": 673.36,
      "learning_rate": 3.3172251469147894e-05,
      "loss": 2.4757,
      "step": 5500000
    },
    {
      "epoch": 673.97,
      "learning_rate": 3.3156960088148874e-05,
      "loss": 2.4962,
      "step": 5505000
    },
    {
      "epoch": 674.58,
      "learning_rate": 3.314165952497551e-05,
      "loss": 2.4713,
      "step": 5510000
    },
    {
      "epoch": 675.2,
      "learning_rate": 3.312635896180216e-05,
      "loss": 2.4869,
      "step": 5515000
    },
    {
      "epoch": 675.81,
      "learning_rate": 3.3111064520078355e-05,
      "loss": 2.486,
      "step": 5520000
    },
    {
      "epoch": 676.42,
      "learning_rate": 3.309577007835455e-05,
      "loss": 2.4783,
      "step": 5525000
    },
    {
      "epoch": 677.03,
      "learning_rate": 3.3080466454456415e-05,
      "loss": 2.4862,
      "step": 5530000
    },
    {
      "epoch": 677.64,
      "learning_rate": 3.3065165891283054e-05,
      "loss": 2.4672,
      "step": 5535000
    },
    {
      "epoch": 678.26,
      "learning_rate": 3.3049874510284034e-05,
      "loss": 2.4796,
      "step": 5540000
    },
    {
      "epoch": 678.87,
      "learning_rate": 3.3034577007835455e-05,
      "loss": 2.481,
      "step": 5545000
    },
    {
      "epoch": 679.48,
      "learning_rate": 3.301927338393732e-05,
      "loss": 2.4637,
      "step": 5550000
    },
    {
      "epoch": 680.09,
      "learning_rate": 3.300396976003918e-05,
      "loss": 2.4804,
      "step": 5555000
    },
    {
      "epoch": 680.71,
      "learning_rate": 3.2988672257590595e-05,
      "loss": 2.4693,
      "step": 5560000
    },
    {
      "epoch": 681.32,
      "learning_rate": 3.297338087659158e-05,
      "loss": 2.4669,
      "step": 5565000
    },
    {
      "epoch": 681.93,
      "learning_rate": 3.2958083374143e-05,
      "loss": 2.4908,
      "step": 5570000
    },
    {
      "epoch": 682.54,
      "learning_rate": 3.294278281096964e-05,
      "loss": 2.463,
      "step": 5575000
    },
    {
      "epoch": 683.15,
      "learning_rate": 3.2927479187071504e-05,
      "loss": 2.4731,
      "step": 5580000
    },
    {
      "epoch": 683.77,
      "learning_rate": 3.29121847453477e-05,
      "loss": 2.4674,
      "step": 5585000
    },
    {
      "epoch": 684.38,
      "learning_rate": 3.289689642507346e-05,
      "loss": 2.4826,
      "step": 5590000
    },
    {
      "epoch": 684.99,
      "learning_rate": 3.28815958619001e-05,
      "loss": 2.4819,
      "step": 5595000
    },
    {
      "epoch": 685.6,
      "learning_rate": 3.286629223800196e-05,
      "loss": 2.4567,
      "step": 5600000
    },
    {
      "epoch": 686.21,
      "learning_rate": 3.285098861410382e-05,
      "loss": 2.4691,
      "step": 5605000
    },
    {
      "epoch": 686.83,
      "learning_rate": 3.283569111165524e-05,
      "loss": 2.4651,
      "step": 5610000
    },
    {
      "epoch": 687.44,
      "learning_rate": 3.282039666993144e-05,
      "loss": 2.4681,
      "step": 5615000
    },
    {
      "epoch": 688.05,
      "learning_rate": 3.280509610675808e-05,
      "loss": 2.4755,
      "step": 5620000
    },
    {
      "epoch": 688.66,
      "learning_rate": 3.278979248285994e-05,
      "loss": 2.4566,
      "step": 5625000
    },
    {
      "epoch": 689.28,
      "learning_rate": 3.27745041625857e-05,
      "loss": 2.4653,
      "step": 5630000
    },
    {
      "epoch": 689.89,
      "learning_rate": 3.275920666013712e-05,
      "loss": 2.4706,
      "step": 5635000
    },
    {
      "epoch": 690.5,
      "learning_rate": 3.2743906096963764e-05,
      "loss": 2.4588,
      "step": 5640000
    },
    {
      "epoch": 691.11,
      "learning_rate": 3.27286055337904e-05,
      "loss": 2.4679,
      "step": 5645000
    },
    {
      "epoch": 691.72,
      "learning_rate": 3.271330497061704e-05,
      "loss": 2.4529,
      "step": 5650000
    },
    {
      "epoch": 692.34,
      "learning_rate": 3.269801052889324e-05,
      "loss": 2.4602,
      "step": 5655000
    },
    {
      "epoch": 692.95,
      "learning_rate": 3.26827069049951e-05,
      "loss": 2.4674,
      "step": 5660000
    },
    {
      "epoch": 693.56,
      "learning_rate": 3.266740940254652e-05,
      "loss": 2.4534,
      "step": 5665000
    },
    {
      "epoch": 694.17,
      "learning_rate": 3.265211496082272e-05,
      "loss": 2.4586,
      "step": 5670000
    },
    {
      "epoch": 694.78,
      "learning_rate": 3.263681745837415e-05,
      "loss": 2.4599,
      "step": 5675000
    },
    {
      "epoch": 695.4,
      "learning_rate": 3.2621513834476004e-05,
      "loss": 2.4532,
      "step": 5680000
    },
    {
      "epoch": 696.01,
      "learning_rate": 3.260621327130264e-05,
      "loss": 2.4638,
      "step": 5685000
    },
    {
      "epoch": 696.62,
      "learning_rate": 3.259091576885407e-05,
      "loss": 2.4448,
      "step": 5690000
    },
    {
      "epoch": 697.23,
      "learning_rate": 3.257561826640549e-05,
      "loss": 2.4599,
      "step": 5695000
    },
    {
      "epoch": 697.85,
      "learning_rate": 3.256032382468169e-05,
      "loss": 2.4587,
      "step": 5700000
    },
    {
      "epoch": 698.46,
      "learning_rate": 3.254502326150833e-05,
      "loss": 2.4487,
      "step": 5705000
    },
    {
      "epoch": 699.07,
      "learning_rate": 3.2529722698334966e-05,
      "loss": 2.4597,
      "step": 5710000
    },
    {
      "epoch": 699.68,
      "learning_rate": 3.251442519588639e-05,
      "loss": 2.4445,
      "step": 5715000
    },
    {
      "epoch": 700.29,
      "learning_rate": 3.249912769343781e-05,
      "loss": 2.4498,
      "step": 5720000
    },
    {
      "epoch": 700.91,
      "learning_rate": 3.248383325171401e-05,
      "loss": 2.4609,
      "step": 5725000
    },
    {
      "epoch": 701.52,
      "learning_rate": 3.2468538809990204e-05,
      "loss": 2.4436,
      "step": 5730000
    },
    {
      "epoch": 702.13,
      "learning_rate": 3.2453241307541625e-05,
      "loss": 2.4578,
      "step": 5735000
    },
    {
      "epoch": 702.74,
      "learning_rate": 3.2437940744368264e-05,
      "loss": 2.4493,
      "step": 5740000
    },
    {
      "epoch": 703.35,
      "learning_rate": 3.2422643241919685e-05,
      "loss": 2.4605,
      "step": 5745000
    },
    {
      "epoch": 703.97,
      "learning_rate": 3.240733961802155e-05,
      "loss": 2.4578,
      "step": 5750000
    },
    {
      "epoch": 704.58,
      "learning_rate": 3.239203599412341e-05,
      "loss": 2.4402,
      "step": 5755000
    },
    {
      "epoch": 705.19,
      "learning_rate": 3.237673849167483e-05,
      "loss": 2.4496,
      "step": 5760000
    },
    {
      "epoch": 705.8,
      "learning_rate": 3.2361440989226246e-05,
      "loss": 2.4469,
      "step": 5765000
    },
    {
      "epoch": 706.42,
      "learning_rate": 3.234614042605289e-05,
      "loss": 2.4383,
      "step": 5770000
    },
    {
      "epoch": 707.03,
      "learning_rate": 3.2330849045053865e-05,
      "loss": 2.4573,
      "step": 5775000
    },
    {
      "epoch": 707.64,
      "learning_rate": 3.2315551542605286e-05,
      "loss": 2.44,
      "step": 5780000
    },
    {
      "epoch": 708.25,
      "learning_rate": 3.230024791870715e-05,
      "loss": 2.4461,
      "step": 5785000
    },
    {
      "epoch": 708.86,
      "learning_rate": 3.2284956537708136e-05,
      "loss": 2.4547,
      "step": 5790000
    },
    {
      "epoch": 709.48,
      "learning_rate": 3.226965903525955e-05,
      "loss": 2.4425,
      "step": 5795000
    },
    {
      "epoch": 710.09,
      "learning_rate": 3.2254358472086196e-05,
      "loss": 2.4554,
      "step": 5800000
    },
    {
      "epoch": 710.7,
      "learning_rate": 3.223906096963761e-05,
      "loss": 2.4425,
      "step": 5805000
    },
    {
      "epoch": 711.31,
      "learning_rate": 3.222376346718903e-05,
      "loss": 2.4389,
      "step": 5810000
    },
    {
      "epoch": 711.92,
      "learning_rate": 3.220846290401568e-05,
      "loss": 2.451,
      "step": 5815000
    },
    {
      "epoch": 712.54,
      "learning_rate": 3.219316540156709e-05,
      "loss": 2.4349,
      "step": 5820000
    },
    {
      "epoch": 713.15,
      "learning_rate": 3.2177861777668954e-05,
      "loss": 2.4437,
      "step": 5825000
    },
    {
      "epoch": 713.76,
      "learning_rate": 3.216256733594515e-05,
      "loss": 2.4345,
      "step": 5830000
    },
    {
      "epoch": 714.37,
      "learning_rate": 3.21472667727718e-05,
      "loss": 2.4374,
      "step": 5835000
    },
    {
      "epoch": 714.99,
      "learning_rate": 3.213197845249755e-05,
      "loss": 2.4454,
      "step": 5840000
    },
    {
      "epoch": 715.6,
      "learning_rate": 3.2116674828599416e-05,
      "loss": 2.4277,
      "step": 5845000
    },
    {
      "epoch": 716.21,
      "learning_rate": 3.210138038687561e-05,
      "loss": 2.441,
      "step": 5850000
    },
    {
      "epoch": 716.82,
      "learning_rate": 3.2086082884427035e-05,
      "loss": 2.4371,
      "step": 5855000
    },
    {
      "epoch": 717.43,
      "learning_rate": 3.207078538197845e-05,
      "loss": 2.4333,
      "step": 5860000
    },
    {
      "epoch": 718.05,
      "learning_rate": 3.2055494000979436e-05,
      "loss": 2.4507,
      "step": 5865000
    },
    {
      "epoch": 718.66,
      "learning_rate": 3.2040193437806075e-05,
      "loss": 2.4283,
      "step": 5870000
    },
    {
      "epoch": 719.27,
      "learning_rate": 3.202489287463272e-05,
      "loss": 2.4347,
      "step": 5875000
    },
    {
      "epoch": 719.88,
      "learning_rate": 3.2009604554358477e-05,
      "loss": 2.4449,
      "step": 5880000
    },
    {
      "epoch": 720.49,
      "learning_rate": 3.199430705190989e-05,
      "loss": 2.4314,
      "step": 5885000
    },
    {
      "epoch": 721.11,
      "learning_rate": 3.1979003428011754e-05,
      "loss": 2.4419,
      "step": 5890000
    },
    {
      "epoch": 721.72,
      "learning_rate": 3.1963705925563175e-05,
      "loss": 2.4328,
      "step": 5895000
    },
    {
      "epoch": 722.33,
      "learning_rate": 3.194840230166504e-05,
      "loss": 2.43,
      "step": 5900000
    },
    {
      "epoch": 722.94,
      "learning_rate": 3.1933101738491676e-05,
      "loss": 2.44,
      "step": 5905000
    },
    {
      "epoch": 723.56,
      "learning_rate": 3.191780117531832e-05,
      "loss": 2.4249,
      "step": 5910000
    },
    {
      "epoch": 724.17,
      "learning_rate": 3.190250061214496e-05,
      "loss": 2.4295,
      "step": 5915000
    },
    {
      "epoch": 724.78,
      "learning_rate": 3.188719698824682e-05,
      "loss": 2.429,
      "step": 5920000
    },
    {
      "epoch": 725.39,
      "learning_rate": 3.1871905607247796e-05,
      "loss": 2.4253,
      "step": 5925000
    },
    {
      "epoch": 726.0,
      "learning_rate": 3.185661728697356e-05,
      "loss": 2.442,
      "step": 5930000
    },
    {
      "epoch": 726.62,
      "learning_rate": 3.1841313663075414e-05,
      "loss": 2.4141,
      "step": 5935000
    },
    {
      "epoch": 727.23,
      "learning_rate": 3.182601922135162e-05,
      "loss": 2.4296,
      "step": 5940000
    },
    {
      "epoch": 727.84,
      "learning_rate": 3.1810724779627816e-05,
      "loss": 2.4307,
      "step": 5945000
    },
    {
      "epoch": 728.45,
      "learning_rate": 3.1795424216454455e-05,
      "loss": 2.4229,
      "step": 5950000
    },
    {
      "epoch": 729.06,
      "learning_rate": 3.178013283545544e-05,
      "loss": 2.4336,
      "step": 5955000
    },
    {
      "epoch": 729.68,
      "learning_rate": 3.1764835333006856e-05,
      "loss": 2.4284,
      "step": 5960000
    },
    {
      "epoch": 730.29,
      "learning_rate": 3.174953170910872e-05,
      "loss": 2.4253,
      "step": 5965000
    },
    {
      "epoch": 730.9,
      "learning_rate": 3.1734228085210574e-05,
      "loss": 2.4334,
      "step": 5970000
    },
    {
      "epoch": 731.51,
      "learning_rate": 3.1718930582762e-05,
      "loss": 2.4131,
      "step": 5975000
    },
    {
      "epoch": 732.13,
      "learning_rate": 3.1703633080313424e-05,
      "loss": 2.4305,
      "step": 5980000
    },
    {
      "epoch": 732.74,
      "learning_rate": 3.168833557786484e-05,
      "loss": 2.4224,
      "step": 5985000
    },
    {
      "epoch": 733.35,
      "learning_rate": 3.167303807541626e-05,
      "loss": 2.4149,
      "step": 5990000
    },
    {
      "epoch": 733.96,
      "learning_rate": 3.165774363369246e-05,
      "loss": 2.4345,
      "step": 5995000
    },
    {
      "epoch": 734.57,
      "learning_rate": 3.164244919196866e-05,
      "loss": 2.4128,
      "step": 6000000
    },
    {
      "epoch": 735.19,
      "learning_rate": 3.16271486287953e-05,
      "loss": 2.4236,
      "step": 6005000
    },
    {
      "epoch": 735.8,
      "learning_rate": 3.161185112634672e-05,
      "loss": 2.4178,
      "step": 6010000
    },
    {
      "epoch": 736.41,
      "learning_rate": 3.159655362389814e-05,
      "loss": 2.4139,
      "step": 6015000
    },
    {
      "epoch": 737.02,
      "learning_rate": 3.158125e-05,
      "loss": 2.4284,
      "step": 6020000
    },
    {
      "epoch": 737.63,
      "learning_rate": 3.156595249755142e-05,
      "loss": 2.4127,
      "step": 6025000
    },
    {
      "epoch": 738.25,
      "learning_rate": 3.15506611165524e-05,
      "loss": 2.4239,
      "step": 6030000
    },
    {
      "epoch": 738.86,
      "learning_rate": 3.153536361410382e-05,
      "loss": 2.4228,
      "step": 6035000
    },
    {
      "epoch": 739.47,
      "learning_rate": 3.152006305093046e-05,
      "loss": 2.4134,
      "step": 6040000
    },
    {
      "epoch": 740.08,
      "learning_rate": 3.1504768609206664e-05,
      "loss": 2.427,
      "step": 6045000
    },
    {
      "epoch": 740.7,
      "learning_rate": 3.14894680460333e-05,
      "loss": 2.4125,
      "step": 6050000
    },
    {
      "epoch": 741.31,
      "learning_rate": 3.14741736043095e-05,
      "loss": 2.4176,
      "step": 6055000
    },
    {
      "epoch": 741.92,
      "learning_rate": 3.145886998041136e-05,
      "loss": 2.4234,
      "step": 6060000
    },
    {
      "epoch": 742.53,
      "learning_rate": 3.1443566356513225e-05,
      "loss": 2.4012,
      "step": 6065000
    },
    {
      "epoch": 743.14,
      "learning_rate": 3.142826273261508e-05,
      "loss": 2.4178,
      "step": 6070000
    },
    {
      "epoch": 743.76,
      "learning_rate": 3.1412968290891285e-05,
      "loss": 2.4118,
      "step": 6075000
    },
    {
      "epoch": 744.37,
      "learning_rate": 3.139766772771793e-05,
      "loss": 2.4065,
      "step": 6080000
    },
    {
      "epoch": 744.98,
      "learning_rate": 3.138236716454457e-05,
      "loss": 2.4215,
      "step": 6085000
    },
    {
      "epoch": 745.59,
      "learning_rate": 3.1367078844270325e-05,
      "loss": 2.4028,
      "step": 6090000
    },
    {
      "epoch": 746.2,
      "learning_rate": 3.135178134182175e-05,
      "loss": 2.4165,
      "step": 6095000
    },
    {
      "epoch": 746.82,
      "learning_rate": 3.1336480778648385e-05,
      "loss": 2.4156,
      "step": 6100000
    },
    {
      "epoch": 747.43,
      "learning_rate": 3.1321183276199807e-05,
      "loss": 2.4052,
      "step": 6105000
    },
    {
      "epoch": 748.04,
      "learning_rate": 3.130588577375123e-05,
      "loss": 2.4185,
      "step": 6110000
    },
    {
      "epoch": 748.65,
      "learning_rate": 3.1290585210577866e-05,
      "loss": 2.4,
      "step": 6115000
    },
    {
      "epoch": 749.27,
      "learning_rate": 3.127528770812929e-05,
      "loss": 2.4055,
      "step": 6120000
    },
    {
      "epoch": 749.88,
      "learning_rate": 3.1259987144955926e-05,
      "loss": 2.4137,
      "step": 6125000
    },
    {
      "epoch": 750.49,
      "learning_rate": 3.124469882468168e-05,
      "loss": 2.4011,
      "step": 6130000
    },
    {
      "epoch": 751.1,
      "learning_rate": 3.122940438295789e-05,
      "loss": 2.4204,
      "step": 6135000
    },
    {
      "epoch": 751.71,
      "learning_rate": 3.121410075905974e-05,
      "loss": 2.4023,
      "step": 6140000
    },
    {
      "epoch": 752.33,
      "learning_rate": 3.119880019588639e-05,
      "loss": 2.4052,
      "step": 6145000
    },
    {
      "epoch": 752.94,
      "learning_rate": 3.1183499632713026e-05,
      "loss": 2.4129,
      "step": 6150000
    },
    {
      "epoch": 753.55,
      "learning_rate": 3.116821131243879e-05,
      "loss": 2.4048,
      "step": 6155000
    },
    {
      "epoch": 754.16,
      "learning_rate": 3.115291074926543e-05,
      "loss": 2.4076,
      "step": 6160000
    },
    {
      "epoch": 754.77,
      "learning_rate": 3.113760712536729e-05,
      "loss": 2.4021,
      "step": 6165000
    },
    {
      "epoch": 755.39,
      "learning_rate": 3.112231574436827e-05,
      "loss": 2.4028,
      "step": 6170000
    },
    {
      "epoch": 756.0,
      "learning_rate": 3.1107024363369245e-05,
      "loss": 2.4214,
      "step": 6175000
    },
    {
      "epoch": 756.61,
      "learning_rate": 3.109172073947111e-05,
      "loss": 2.3981,
      "step": 6180000
    },
    {
      "epoch": 757.22,
      "learning_rate": 3.1076426297747304e-05,
      "loss": 2.4087,
      "step": 6185000
    },
    {
      "epoch": 757.84,
      "learning_rate": 3.106112267384917e-05,
      "loss": 2.4048,
      "step": 6190000
    },
    {
      "epoch": 758.45,
      "learning_rate": 3.104582517140059e-05,
      "loss": 2.3955,
      "step": 6195000
    },
    {
      "epoch": 759.06,
      "learning_rate": 3.103052766895201e-05,
      "loss": 2.4099,
      "step": 6200000
    },
    {
      "epoch": 759.67,
      "learning_rate": 3.101522404505387e-05,
      "loss": 2.3934,
      "step": 6205000
    },
    {
      "epoch": 760.28,
      "learning_rate": 3.0999926542605287e-05,
      "loss": 2.3993,
      "step": 6210000
    },
    {
      "epoch": 760.9,
      "learning_rate": 3.098462597943193e-05,
      "loss": 2.4064,
      "step": 6215000
    },
    {
      "epoch": 761.51,
      "learning_rate": 3.0969334598432905e-05,
      "loss": 2.3921,
      "step": 6220000
    },
    {
      "epoch": 762.12,
      "learning_rate": 3.095404015670911e-05,
      "loss": 2.4052,
      "step": 6225000
    },
    {
      "epoch": 762.73,
      "learning_rate": 3.093873959353575e-05,
      "loss": 2.3994,
      "step": 6230000
    },
    {
      "epoch": 763.34,
      "learning_rate": 3.092343903036239e-05,
      "loss": 2.3931,
      "step": 6235000
    },
    {
      "epoch": 763.96,
      "learning_rate": 3.0908141527913815e-05,
      "loss": 2.4044,
      "step": 6240000
    },
    {
      "epoch": 764.57,
      "learning_rate": 3.0892840964740447e-05,
      "loss": 2.3829,
      "step": 6245000
    },
    {
      "epoch": 765.18,
      "learning_rate": 3.087754652301665e-05,
      "loss": 2.4029,
      "step": 6250000
    },
    {
      "epoch": 765.79,
      "learning_rate": 3.086224289911851e-05,
      "loss": 2.3974,
      "step": 6255000
    },
    {
      "epoch": 766.41,
      "learning_rate": 3.0846945396669935e-05,
      "loss": 2.3886,
      "step": 6260000
    },
    {
      "epoch": 767.02,
      "learning_rate": 3.083164483349657e-05,
      "loss": 2.4024,
      "step": 6265000
    },
    {
      "epoch": 767.63,
      "learning_rate": 3.081635039177278e-05,
      "loss": 2.3844,
      "step": 6270000
    },
    {
      "epoch": 768.24,
      "learning_rate": 3.080105288932419e-05,
      "loss": 2.3959,
      "step": 6275000
    },
    {
      "epoch": 768.85,
      "learning_rate": 3.078575538687561e-05,
      "loss": 2.3979,
      "step": 6280000
    },
    {
      "epoch": 769.47,
      "learning_rate": 3.077046094515181e-05,
      "loss": 2.3905,
      "step": 6285000
    },
    {
      "epoch": 770.08,
      "learning_rate": 3.075516956415279e-05,
      "loss": 2.4088,
      "step": 6290000
    },
    {
      "epoch": 770.69,
      "learning_rate": 3.0739865940254654e-05,
      "loss": 2.3867,
      "step": 6295000
    },
    {
      "epoch": 771.3,
      "learning_rate": 3.072457149853085e-05,
      "loss": 2.3897,
      "step": 6300000
    },
    {
      "epoch": 771.91,
      "learning_rate": 3.070928011753184e-05,
      "loss": 2.41,
      "step": 6305000
    },
    {
      "epoch": 772.53,
      "learning_rate": 3.069397955435848e-05,
      "loss": 2.3945,
      "step": 6310000
    },
    {
      "epoch": 773.14,
      "learning_rate": 3.067867593046033e-05,
      "loss": 2.3969,
      "step": 6315000
    },
    {
      "epoch": 773.75,
      "learning_rate": 3.066338148873654e-05,
      "loss": 2.3917,
      "step": 6320000
    },
    {
      "epoch": 774.36,
      "learning_rate": 3.0648080925563175e-05,
      "loss": 2.3911,
      "step": 6325000
    },
    {
      "epoch": 774.98,
      "learning_rate": 3.063278036238982e-05,
      "loss": 2.3942,
      "step": 6330000
    },
    {
      "epoch": 775.59,
      "learning_rate": 3.061747979921646e-05,
      "loss": 2.3776,
      "step": 6335000
    },
    {
      "epoch": 776.2,
      "learning_rate": 3.060218229676788e-05,
      "loss": 2.3934,
      "step": 6340000
    },
    {
      "epoch": 776.81,
      "learning_rate": 3.0586884794319295e-05,
      "loss": 2.3916,
      "step": 6345000
    },
    {
      "epoch": 777.42,
      "learning_rate": 3.057158117042116e-05,
      "loss": 2.3833,
      "step": 6350000
    },
    {
      "epoch": 778.04,
      "learning_rate": 3.05562959108717e-05,
      "loss": 2.3971,
      "step": 6355000
    },
    {
      "epoch": 778.65,
      "learning_rate": 3.054099228697356e-05,
      "loss": 2.3778,
      "step": 6360000
    },
    {
      "epoch": 779.26,
      "learning_rate": 3.052568866307542e-05,
      "loss": 2.3896,
      "step": 6365000
    },
    {
      "epoch": 779.87,
      "learning_rate": 3.051038809990206e-05,
      "loss": 2.3914,
      "step": 6370000
    },
    {
      "epoch": 780.48,
      "learning_rate": 3.0495090597453478e-05,
      "loss": 2.3793,
      "step": 6375000
    },
    {
      "epoch": 781.1,
      "learning_rate": 3.0479802277179238e-05,
      "loss": 2.392,
      "step": 6380000
    },
    {
      "epoch": 781.71,
      "learning_rate": 3.0464507835455435e-05,
      "loss": 2.3869,
      "step": 6385000
    },
    {
      "epoch": 782.32,
      "learning_rate": 3.0449204211557298e-05,
      "loss": 2.3933,
      "step": 6390000
    },
    {
      "epoch": 782.93,
      "learning_rate": 3.043390364838394e-05,
      "loss": 2.3956,
      "step": 6395000
    },
    {
      "epoch": 783.55,
      "learning_rate": 3.0418606145935357e-05,
      "loss": 2.3791,
      "step": 6400000
    },
    {
      "epoch": 784.16,
      "learning_rate": 3.040331170421156e-05,
      "loss": 2.3911,
      "step": 6405000
    },
    {
      "epoch": 784.77,
      "learning_rate": 3.0388008080313417e-05,
      "loss": 2.3825,
      "step": 6410000
    },
    {
      "epoch": 785.38,
      "learning_rate": 3.037270751714006e-05,
      "loss": 2.3787,
      "step": 6415000
    },
    {
      "epoch": 785.99,
      "learning_rate": 3.0357406953966698e-05,
      "loss": 2.3893,
      "step": 6420000
    },
    {
      "epoch": 786.61,
      "learning_rate": 3.03421125122429e-05,
      "loss": 2.3691,
      "step": 6425000
    },
    {
      "epoch": 787.22,
      "learning_rate": 3.0326815009794317e-05,
      "loss": 2.3794,
      "step": 6430000
    },
    {
      "epoch": 787.83,
      "learning_rate": 3.031151444662096e-05,
      "loss": 2.3824,
      "step": 6435000
    },
    {
      "epoch": 788.44,
      "learning_rate": 3.02962138834476e-05,
      "loss": 2.3699,
      "step": 6440000
    },
    {
      "epoch": 789.05,
      "learning_rate": 3.028091638099902e-05,
      "loss": 2.3883,
      "step": 6445000
    },
    {
      "epoch": 789.67,
      "learning_rate": 3.0265618878550443e-05,
      "loss": 2.3725,
      "step": 6450000
    },
    {
      "epoch": 790.28,
      "learning_rate": 3.0250324436826644e-05,
      "loss": 2.3744,
      "step": 6455000
    },
    {
      "epoch": 790.89,
      "learning_rate": 3.0235023873653286e-05,
      "loss": 2.3854,
      "step": 6460000
    },
    {
      "epoch": 791.5,
      "learning_rate": 3.0219723310479924e-05,
      "loss": 2.368,
      "step": 6465000
    },
    {
      "epoch": 792.12,
      "learning_rate": 3.0204425808031346e-05,
      "loss": 2.381,
      "step": 6470000
    },
    {
      "epoch": 792.73,
      "learning_rate": 3.0189125244857984e-05,
      "loss": 2.3706,
      "step": 6475000
    },
    {
      "epoch": 793.34,
      "learning_rate": 3.0173824681684626e-05,
      "loss": 2.373,
      "step": 6480000
    },
    {
      "epoch": 793.95,
      "learning_rate": 3.0158527179236044e-05,
      "loss": 2.3822,
      "step": 6485000
    },
    {
      "epoch": 794.56,
      "learning_rate": 3.0143226616062686e-05,
      "loss": 2.3642,
      "step": 6490000
    },
    {
      "epoch": 795.18,
      "learning_rate": 3.0127929113614107e-05,
      "loss": 2.3804,
      "step": 6495000
    },
    {
      "epoch": 795.79,
      "learning_rate": 3.0112628550440746e-05,
      "loss": 2.3694,
      "step": 6500000
    },
    {
      "epoch": 796.4,
      "learning_rate": 3.0097327987267388e-05,
      "loss": 2.3681,
      "step": 6505000
    },
    {
      "epoch": 797.01,
      "learning_rate": 3.0082036606268365e-05,
      "loss": 2.3847,
      "step": 6510000
    },
    {
      "epoch": 797.62,
      "learning_rate": 3.0066745225269345e-05,
      "loss": 2.3641,
      "step": 6515000
    },
    {
      "epoch": 798.24,
      "learning_rate": 3.0051441601371204e-05,
      "loss": 2.3736,
      "step": 6520000
    },
    {
      "epoch": 798.85,
      "learning_rate": 3.0036141038197846e-05,
      "loss": 2.3805,
      "step": 6525000
    },
    {
      "epoch": 799.46,
      "learning_rate": 3.0020843535749264e-05,
      "loss": 2.3615,
      "step": 6530000
    },
    {
      "epoch": 800.07,
      "learning_rate": 3.0005549094025465e-05,
      "loss": 2.3784,
      "step": 6535000
    },
    {
      "epoch": 800.69,
      "learning_rate": 2.9990251591576883e-05,
      "loss": 2.3644,
      "step": 6540000
    },
    {
      "epoch": 801.3,
      "learning_rate": 2.9974947967678745e-05,
      "loss": 2.3687,
      "step": 6545000
    },
    {
      "epoch": 801.91,
      "learning_rate": 2.9959650465230167e-05,
      "loss": 2.3774,
      "step": 6550000
    },
    {
      "epoch": 802.52,
      "learning_rate": 2.9944349902056805e-05,
      "loss": 2.3589,
      "step": 6555000
    },
    {
      "epoch": 803.13,
      "learning_rate": 2.9929064642507348e-05,
      "loss": 2.3738,
      "step": 6560000
    },
    {
      "epoch": 803.75,
      "learning_rate": 2.991376101860921e-05,
      "loss": 2.364,
      "step": 6565000
    },
    {
      "epoch": 804.36,
      "learning_rate": 2.9898466576885408e-05,
      "loss": 2.3641,
      "step": 6570000
    },
    {
      "epoch": 804.97,
      "learning_rate": 2.988316295298727e-05,
      "loss": 2.3785,
      "step": 6575000
    },
    {
      "epoch": 805.58,
      "learning_rate": 2.9867871571988247e-05,
      "loss": 2.3567,
      "step": 6580000
    },
    {
      "epoch": 806.19,
      "learning_rate": 2.985257406953967e-05,
      "loss": 2.3702,
      "step": 6585000
    },
    {
      "epoch": 806.81,
      "learning_rate": 2.983727350636631e-05,
      "loss": 2.3679,
      "step": 6590000
    },
    {
      "epoch": 807.42,
      "learning_rate": 2.982197600391773e-05,
      "loss": 2.3635,
      "step": 6595000
    },
    {
      "epoch": 808.03,
      "learning_rate": 2.980667544074437e-05,
      "loss": 2.3758,
      "step": 6600000
    },
    {
      "epoch": 808.64,
      "learning_rate": 2.979137487757101e-05,
      "loss": 2.3572,
      "step": 6605000
    },
    {
      "epoch": 809.26,
      "learning_rate": 2.977608349657199e-05,
      "loss": 2.3703,
      "step": 6610000
    },
    {
      "epoch": 809.87,
      "learning_rate": 2.9760779872673848e-05,
      "loss": 2.3703,
      "step": 6615000
    },
    {
      "epoch": 810.48,
      "learning_rate": 2.974548543095005e-05,
      "loss": 2.3573,
      "step": 6620000
    },
    {
      "epoch": 811.09,
      "learning_rate": 2.9730184867776688e-05,
      "loss": 2.3752,
      "step": 6625000
    },
    {
      "epoch": 811.7,
      "learning_rate": 2.971489042605289e-05,
      "loss": 2.3598,
      "step": 6630000
    },
    {
      "epoch": 812.32,
      "learning_rate": 2.9699595984329093e-05,
      "loss": 2.3635,
      "step": 6635000
    },
    {
      "epoch": 812.93,
      "learning_rate": 2.9684292360430955e-05,
      "loss": 2.3693,
      "step": 6640000
    },
    {
      "epoch": 813.54,
      "learning_rate": 2.9668994857982373e-05,
      "loss": 2.3564,
      "step": 6645000
    },
    {
      "epoch": 814.15,
      "learning_rate": 2.9653694294809015e-05,
      "loss": 2.3645,
      "step": 6650000
    },
    {
      "epoch": 814.76,
      "learning_rate": 2.9638402913809992e-05,
      "loss": 2.3629,
      "step": 6655000
    },
    {
      "epoch": 815.38,
      "learning_rate": 2.9623105411361413e-05,
      "loss": 2.359,
      "step": 6660000
    },
    {
      "epoch": 815.99,
      "learning_rate": 2.9607801787463276e-05,
      "loss": 2.3689,
      "step": 6665000
    },
    {
      "epoch": 816.6,
      "learning_rate": 2.9592504285014694e-05,
      "loss": 2.3534,
      "step": 6670000
    },
    {
      "epoch": 817.21,
      "learning_rate": 2.9577203721841336e-05,
      "loss": 2.3607,
      "step": 6675000
    },
    {
      "epoch": 817.83,
      "learning_rate": 2.9561909280117533e-05,
      "loss": 2.359,
      "step": 6680000
    },
    {
      "epoch": 818.44,
      "learning_rate": 2.954661789911851e-05,
      "loss": 2.3536,
      "step": 6685000
    },
    {
      "epoch": 819.05,
      "learning_rate": 2.9531314275220372e-05,
      "loss": 2.3657,
      "step": 6690000
    },
    {
      "epoch": 819.66,
      "learning_rate": 2.9516019833496573e-05,
      "loss": 2.3485,
      "step": 6695000
    },
    {
      "epoch": 820.27,
      "learning_rate": 2.9500719270323212e-05,
      "loss": 2.3561,
      "step": 6700000
    },
    {
      "epoch": 820.89,
      "learning_rate": 2.9485418707149854e-05,
      "loss": 2.3625,
      "step": 6705000
    },
    {
      "epoch": 821.5,
      "learning_rate": 2.9470115083251716e-05,
      "loss": 2.3474,
      "step": 6710000
    },
    {
      "epoch": 822.11,
      "learning_rate": 2.9454817580803134e-05,
      "loss": 2.3569,
      "step": 6715000
    },
    {
      "epoch": 822.72,
      "learning_rate": 2.9439517017629776e-05,
      "loss": 2.3527,
      "step": 6720000
    },
    {
      "epoch": 823.33,
      "learning_rate": 2.9424219515181194e-05,
      "loss": 2.3536,
      "step": 6725000
    },
    {
      "epoch": 823.95,
      "learning_rate": 2.9408928134182174e-05,
      "loss": 2.3614,
      "step": 6730000
    },
    {
      "epoch": 824.56,
      "learning_rate": 2.93936306317336e-05,
      "loss": 2.3439,
      "step": 6735000
    },
    {
      "epoch": 825.17,
      "learning_rate": 2.9378330068560238e-05,
      "loss": 2.3584,
      "step": 6740000
    },
    {
      "epoch": 825.78,
      "learning_rate": 2.9363029505386873e-05,
      "loss": 2.3496,
      "step": 6745000
    },
    {
      "epoch": 826.4,
      "learning_rate": 2.9347728942213515e-05,
      "loss": 2.3499,
      "step": 6750000
    },
    {
      "epoch": 827.01,
      "learning_rate": 2.9332428379040156e-05,
      "loss": 2.3583,
      "step": 6755000
    },
    {
      "epoch": 827.62,
      "learning_rate": 2.931713393731636e-05,
      "loss": 2.3408,
      "step": 6760000
    },
    {
      "epoch": 828.23,
      "learning_rate": 2.930183643486778e-05,
      "loss": 2.3538,
      "step": 6765000
    },
    {
      "epoch": 828.84,
      "learning_rate": 2.928654505386876e-05,
      "loss": 2.3621,
      "step": 6770000
    },
    {
      "epoch": 829.46,
      "learning_rate": 2.9271241429970618e-05,
      "loss": 2.3441,
      "step": 6775000
    },
    {
      "epoch": 830.07,
      "learning_rate": 2.925594698824682e-05,
      "loss": 2.3584,
      "step": 6780000
    },
    {
      "epoch": 830.68,
      "learning_rate": 2.924064336434868e-05,
      "loss": 2.3386,
      "step": 6785000
    },
    {
      "epoch": 831.29,
      "learning_rate": 2.922534280117532e-05,
      "loss": 2.3496,
      "step": 6790000
    },
    {
      "epoch": 831.9,
      "learning_rate": 2.92100514201763e-05,
      "loss": 2.3534,
      "step": 6795000
    },
    {
      "epoch": 832.52,
      "learning_rate": 2.9194756978452498e-05,
      "loss": 2.3417,
      "step": 6800000
    },
    {
      "epoch": 833.13,
      "learning_rate": 2.917945641527914e-05,
      "loss": 2.349,
      "step": 6805000
    },
    {
      "epoch": 833.74,
      "learning_rate": 2.9164155852105778e-05,
      "loss": 2.3468,
      "step": 6810000
    },
    {
      "epoch": 834.35,
      "learning_rate": 2.914885528893242e-05,
      "loss": 2.3409,
      "step": 6815000
    },
    {
      "epoch": 834.97,
      "learning_rate": 2.9133557786483838e-05,
      "loss": 2.3545,
      "step": 6820000
    },
    {
      "epoch": 835.58,
      "learning_rate": 2.911825722331048e-05,
      "loss": 2.3378,
      "step": 6825000
    },
    {
      "epoch": 836.19,
      "learning_rate": 2.9102965842311457e-05,
      "loss": 2.3533,
      "step": 6830000
    },
    {
      "epoch": 836.8,
      "learning_rate": 2.908767140058766e-05,
      "loss": 2.3438,
      "step": 6835000
    },
    {
      "epoch": 837.41,
      "learning_rate": 2.9072370837414303e-05,
      "loss": 2.3376,
      "step": 6840000
    },
    {
      "epoch": 838.03,
      "learning_rate": 2.9057073334965724e-05,
      "loss": 2.3536,
      "step": 6845000
    },
    {
      "epoch": 838.64,
      "learning_rate": 2.9041772771792363e-05,
      "loss": 2.3323,
      "step": 6850000
    },
    {
      "epoch": 839.25,
      "learning_rate": 2.9026472208619005e-05,
      "loss": 2.3443,
      "step": 6855000
    },
    {
      "epoch": 839.86,
      "learning_rate": 2.9011180827619982e-05,
      "loss": 2.3505,
      "step": 6860000
    },
    {
      "epoch": 840.48,
      "learning_rate": 2.8995886385896183e-05,
      "loss": 2.337,
      "step": 6865000
    },
    {
      "epoch": 841.09,
      "learning_rate": 2.898058276199804e-05,
      "loss": 2.3503,
      "step": 6870000
    },
    {
      "epoch": 841.7,
      "learning_rate": 2.8965288320274242e-05,
      "loss": 2.3423,
      "step": 6875000
    },
    {
      "epoch": 842.31,
      "learning_rate": 2.894999081782566e-05,
      "loss": 2.3405,
      "step": 6880000
    },
    {
      "epoch": 842.92,
      "learning_rate": 2.893469637610186e-05,
      "loss": 2.3482,
      "step": 6885000
    },
    {
      "epoch": 843.54,
      "learning_rate": 2.891939887365328e-05,
      "loss": 2.3346,
      "step": 6890000
    },
    {
      "epoch": 844.15,
      "learning_rate": 2.890409831047992e-05,
      "loss": 2.3466,
      "step": 6895000
    },
    {
      "epoch": 844.76,
      "learning_rate": 2.8888800808031343e-05,
      "loss": 2.3347,
      "step": 6900000
    },
    {
      "epoch": 845.37,
      "learning_rate": 2.887350024485798e-05,
      "loss": 2.3301,
      "step": 6905000
    },
    {
      "epoch": 845.98,
      "learning_rate": 2.8858196620959843e-05,
      "loss": 2.3464,
      "step": 6910000
    },
    {
      "epoch": 846.6,
      "learning_rate": 2.884290217923604e-05,
      "loss": 2.33,
      "step": 6915000
    },
    {
      "epoch": 847.21,
      "learning_rate": 2.8827601616062683e-05,
      "loss": 2.3365,
      "step": 6920000
    },
    {
      "epoch": 847.82,
      "learning_rate": 2.8812304113614104e-05,
      "loss": 2.3416,
      "step": 6925000
    },
    {
      "epoch": 848.43,
      "learning_rate": 2.879700661116553e-05,
      "loss": 2.3283,
      "step": 6930000
    },
    {
      "epoch": 849.05,
      "learning_rate": 2.8781712169441726e-05,
      "loss": 2.3455,
      "step": 6935000
    },
    {
      "epoch": 849.66,
      "learning_rate": 2.876641160626837e-05,
      "loss": 2.3321,
      "step": 6940000
    },
    {
      "epoch": 850.27,
      "learning_rate": 2.8751111043095007e-05,
      "loss": 2.3343,
      "step": 6945000
    },
    {
      "epoch": 850.88,
      "learning_rate": 2.8735819662095987e-05,
      "loss": 2.3439,
      "step": 6950000
    },
    {
      "epoch": 851.49,
      "learning_rate": 2.8720519098922626e-05,
      "loss": 2.3255,
      "step": 6955000
    },
    {
      "epoch": 852.11,
      "learning_rate": 2.8705215475024488e-05,
      "loss": 2.3398,
      "step": 6960000
    },
    {
      "epoch": 852.72,
      "learning_rate": 2.8689924094025465e-05,
      "loss": 2.3312,
      "step": 6965000
    },
    {
      "epoch": 853.33,
      "learning_rate": 2.8674623530852107e-05,
      "loss": 2.3299,
      "step": 6970000
    },
    {
      "epoch": 853.94,
      "learning_rate": 2.8659335210577863e-05,
      "loss": 2.3384,
      "step": 6975000
    },
    {
      "epoch": 854.55,
      "learning_rate": 2.8644031586679726e-05,
      "loss": 2.3298,
      "step": 6980000
    },
    {
      "epoch": 855.17,
      "learning_rate": 2.8628734084231147e-05,
      "loss": 2.3401,
      "step": 6985000
    },
    {
      "epoch": 855.78,
      "learning_rate": 2.8613433521057786e-05,
      "loss": 2.3294,
      "step": 6990000
    },
    {
      "epoch": 856.39,
      "learning_rate": 2.8598136018609207e-05,
      "loss": 2.3297,
      "step": 6995000
    },
    {
      "epoch": 857.0,
      "learning_rate": 2.8582838516160625e-05,
      "loss": 2.3461,
      "step": 7000000
    },
    {
      "epoch": 857.62,
      "learning_rate": 2.8567541013712046e-05,
      "loss": 2.3211,
      "step": 7005000
    },
    {
      "epoch": 858.23,
      "learning_rate": 2.855223738981391e-05,
      "loss": 2.3308,
      "step": 7010000
    },
    {
      "epoch": 858.84,
      "learning_rate": 2.8536936826640547e-05,
      "loss": 2.3337,
      "step": 7015000
    },
    {
      "epoch": 859.45,
      "learning_rate": 2.8521642384916748e-05,
      "loss": 2.3233,
      "step": 7020000
    },
    {
      "epoch": 860.06,
      "learning_rate": 2.8506344882468173e-05,
      "loss": 2.336,
      "step": 7025000
    },
    {
      "epoch": 860.68,
      "learning_rate": 2.849104431929481e-05,
      "loss": 2.3227,
      "step": 7030000
    },
    {
      "epoch": 861.29,
      "learning_rate": 2.8475746816846233e-05,
      "loss": 2.3293,
      "step": 7035000
    },
    {
      "epoch": 861.9,
      "learning_rate": 2.846044931439765e-05,
      "loss": 2.3272,
      "step": 7040000
    },
    {
      "epoch": 862.51,
      "learning_rate": 2.844515793339863e-05,
      "loss": 2.3144,
      "step": 7045000
    },
    {
      "epoch": 863.12,
      "learning_rate": 2.842985737022527e-05,
      "loss": 2.3412,
      "step": 7050000
    },
    {
      "epoch": 863.74,
      "learning_rate": 2.841456292850147e-05,
      "loss": 2.3218,
      "step": 7055000
    },
    {
      "epoch": 864.35,
      "learning_rate": 2.8399262365328113e-05,
      "loss": 2.3274,
      "step": 7060000
    },
    {
      "epoch": 864.96,
      "learning_rate": 2.838396180215475e-05,
      "loss": 2.3329,
      "step": 7065000
    },
    {
      "epoch": 865.57,
      "learning_rate": 2.8368661238981393e-05,
      "loss": 2.3171,
      "step": 7070000
    },
    {
      "epoch": 866.19,
      "learning_rate": 2.8353357615083255e-05,
      "loss": 2.3246,
      "step": 7075000
    },
    {
      "epoch": 866.8,
      "learning_rate": 2.8338060112634673e-05,
      "loss": 2.3247,
      "step": 7080000
    },
    {
      "epoch": 867.41,
      "learning_rate": 2.8322762610186095e-05,
      "loss": 2.318,
      "step": 7085000
    },
    {
      "epoch": 868.02,
      "learning_rate": 2.8307465107737513e-05,
      "loss": 2.3293,
      "step": 7090000
    },
    {
      "epoch": 868.63,
      "learning_rate": 2.8292164544564155e-05,
      "loss": 2.3164,
      "step": 7095000
    },
    {
      "epoch": 869.25,
      "learning_rate": 2.827687316356513e-05,
      "loss": 2.3248,
      "step": 7100000
    },
    {
      "epoch": 869.86,
      "learning_rate": 2.8261575661116553e-05,
      "loss": 2.3268,
      "step": 7105000
    },
    {
      "epoch": 870.47,
      "learning_rate": 2.824627815866797e-05,
      "loss": 2.3141,
      "step": 7110000
    },
    {
      "epoch": 871.08,
      "learning_rate": 2.8230983716944175e-05,
      "loss": 2.3349,
      "step": 7115000
    },
    {
      "epoch": 871.69,
      "learning_rate": 2.8215689275220376e-05,
      "loss": 2.3193,
      "step": 7120000
    },
    {
      "epoch": 872.31,
      "learning_rate": 2.8200388712047015e-05,
      "loss": 2.3265,
      "step": 7125000
    },
    {
      "epoch": 872.92,
      "learning_rate": 2.8185088148873656e-05,
      "loss": 2.3295,
      "step": 7130000
    },
    {
      "epoch": 873.53,
      "learning_rate": 2.816978452497552e-05,
      "loss": 2.3126,
      "step": 7135000
    },
    {
      "epoch": 874.14,
      "learning_rate": 2.8154493143976496e-05,
      "loss": 2.3191,
      "step": 7140000
    },
    {
      "epoch": 874.76,
      "learning_rate": 2.8139192580803138e-05,
      "loss": 2.3169,
      "step": 7145000
    },
    {
      "epoch": 875.37,
      "learning_rate": 2.8123892017629776e-05,
      "loss": 2.3177,
      "step": 7150000
    },
    {
      "epoch": 875.98,
      "learning_rate": 2.8108591454456418e-05,
      "loss": 2.3232,
      "step": 7155000
    },
    {
      "epoch": 876.59,
      "learning_rate": 2.8093297012732616e-05,
      "loss": 2.3114,
      "step": 7160000
    },
    {
      "epoch": 877.2,
      "learning_rate": 2.8077999510284037e-05,
      "loss": 2.3164,
      "step": 7165000
    },
    {
      "epoch": 877.82,
      "learning_rate": 2.806269894711068e-05,
      "loss": 2.3183,
      "step": 7170000
    },
    {
      "epoch": 878.43,
      "learning_rate": 2.8047404505386876e-05,
      "loss": 2.3159,
      "step": 7175000
    },
    {
      "epoch": 879.04,
      "learning_rate": 2.8032107002938294e-05,
      "loss": 2.3231,
      "step": 7180000
    },
    {
      "epoch": 879.65,
      "learning_rate": 2.8016803379040157e-05,
      "loss": 2.3103,
      "step": 7185000
    },
    {
      "epoch": 880.26,
      "learning_rate": 2.8001511998041137e-05,
      "loss": 2.3264,
      "step": 7190000
    },
    {
      "epoch": 880.88,
      "learning_rate": 2.7986208374142996e-05,
      "loss": 2.3274,
      "step": 7195000
    },
    {
      "epoch": 881.49,
      "learning_rate": 2.7970910871694417e-05,
      "loss": 2.3106,
      "step": 7200000
    },
    {
      "epoch": 882.1,
      "learning_rate": 2.7955616429970615e-05,
      "loss": 2.3243,
      "step": 7205000
    },
    {
      "epoch": 882.71,
      "learning_rate": 2.794032198824682e-05,
      "loss": 2.3094,
      "step": 7210000
    },
    {
      "epoch": 883.33,
      "learning_rate": 2.792502142507346e-05,
      "loss": 2.3149,
      "step": 7215000
    },
    {
      "epoch": 883.94,
      "learning_rate": 2.7909720861900103e-05,
      "loss": 2.3242,
      "step": 7220000
    },
    {
      "epoch": 884.55,
      "learning_rate": 2.789442029872674e-05,
      "loss": 2.3056,
      "step": 7225000
    },
    {
      "epoch": 885.16,
      "learning_rate": 2.7879119735553383e-05,
      "loss": 2.3197,
      "step": 7230000
    },
    {
      "epoch": 885.77,
      "learning_rate": 2.78638222331048e-05,
      "loss": 2.3091,
      "step": 7235000
    },
    {
      "epoch": 886.39,
      "learning_rate": 2.7848518609206664e-05,
      "loss": 2.3103,
      "step": 7240000
    },
    {
      "epoch": 887.0,
      "learning_rate": 2.7833221106758085e-05,
      "loss": 2.3203,
      "step": 7245000
    },
    {
      "epoch": 887.61,
      "learning_rate": 2.7817926665034283e-05,
      "loss": 2.3032,
      "step": 7250000
    },
    {
      "epoch": 888.22,
      "learning_rate": 2.7802629162585704e-05,
      "loss": 2.3123,
      "step": 7255000
    },
    {
      "epoch": 888.83,
      "learning_rate": 2.778733778158668e-05,
      "loss": 2.3158,
      "step": 7260000
    },
    {
      "epoch": 889.45,
      "learning_rate": 2.7772037218413323e-05,
      "loss": 2.3068,
      "step": 7265000
    },
    {
      "epoch": 890.06,
      "learning_rate": 2.775673971596474e-05,
      "loss": 2.3156,
      "step": 7270000
    },
    {
      "epoch": 890.67,
      "learning_rate": 2.7741442213516162e-05,
      "loss": 2.3068,
      "step": 7275000
    },
    {
      "epoch": 891.28,
      "learning_rate": 2.772614471106758e-05,
      "loss": 2.3085,
      "step": 7280000
    },
    {
      "epoch": 891.9,
      "learning_rate": 2.7710844147894222e-05,
      "loss": 2.3148,
      "step": 7285000
    },
    {
      "epoch": 892.51,
      "learning_rate": 2.769554664544564e-05,
      "loss": 2.3036,
      "step": 7290000
    },
    {
      "epoch": 893.12,
      "learning_rate": 2.768024914299706e-05,
      "loss": 2.3198,
      "step": 7295000
    },
    {
      "epoch": 893.73,
      "learning_rate": 2.7664948579823703e-05,
      "loss": 2.3036,
      "step": 7300000
    },
    {
      "epoch": 894.34,
      "learning_rate": 2.7649644955925562e-05,
      "loss": 2.3076,
      "step": 7305000
    },
    {
      "epoch": 894.96,
      "learning_rate": 2.7634350514201763e-05,
      "loss": 2.3175,
      "step": 7310000
    },
    {
      "epoch": 895.57,
      "learning_rate": 2.76190499510284e-05,
      "loss": 2.2993,
      "step": 7315000
    },
    {
      "epoch": 896.18,
      "learning_rate": 2.7603749387855044e-05,
      "loss": 2.3105,
      "step": 7320000
    },
    {
      "epoch": 896.79,
      "learning_rate": 2.7588458006856027e-05,
      "loss": 2.3144,
      "step": 7325000
    },
    {
      "epoch": 897.4,
      "learning_rate": 2.7573154382957883e-05,
      "loss": 2.3077,
      "step": 7330000
    },
    {
      "epoch": 898.02,
      "learning_rate": 2.7557856880509308e-05,
      "loss": 2.3133,
      "step": 7335000
    },
    {
      "epoch": 898.63,
      "learning_rate": 2.754256243878551e-05,
      "loss": 2.2986,
      "step": 7340000
    },
    {
      "epoch": 899.24,
      "learning_rate": 2.7527261875612147e-05,
      "loss": 2.3075,
      "step": 7345000
    },
    {
      "epoch": 899.85,
      "learning_rate": 2.751196437316357e-05,
      "loss": 2.307,
      "step": 7350000
    },
    {
      "epoch": 900.47,
      "learning_rate": 2.7496666870714986e-05,
      "loss": 2.2994,
      "step": 7355000
    },
    {
      "epoch": 901.08,
      "learning_rate": 2.7481369368266408e-05,
      "loss": 2.3134,
      "step": 7360000
    },
    {
      "epoch": 901.69,
      "learning_rate": 2.746606880509305e-05,
      "loss": 2.3011,
      "step": 7365000
    },
    {
      "epoch": 902.3,
      "learning_rate": 2.7450774363369247e-05,
      "loss": 2.306,
      "step": 7370000
    },
    {
      "epoch": 902.91,
      "learning_rate": 2.743547380019589e-05,
      "loss": 2.311,
      "step": 7375000
    },
    {
      "epoch": 903.53,
      "learning_rate": 2.7420176297747307e-05,
      "loss": 2.2983,
      "step": 7380000
    },
    {
      "epoch": 904.14,
      "learning_rate": 2.7404881856023508e-05,
      "loss": 2.3095,
      "step": 7385000
    },
    {
      "epoch": 904.75,
      "learning_rate": 2.7389581292850146e-05,
      "loss": 2.3008,
      "step": 7390000
    },
    {
      "epoch": 905.36,
      "learning_rate": 2.7374280729676788e-05,
      "loss": 2.3037,
      "step": 7395000
    },
    {
      "epoch": 905.97,
      "learning_rate": 2.7358986287952986e-05,
      "loss": 2.3159,
      "step": 7400000
    },
    {
      "epoch": 906.59,
      "learning_rate": 2.7343688785504407e-05,
      "loss": 2.2934,
      "step": 7405000
    },
    {
      "epoch": 907.2,
      "learning_rate": 2.7328388222331046e-05,
      "loss": 2.3097,
      "step": 7410000
    },
    {
      "epoch": 907.81,
      "learning_rate": 2.7313087659157688e-05,
      "loss": 2.3041,
      "step": 7415000
    },
    {
      "epoch": 908.42,
      "learning_rate": 2.729778709598433e-05,
      "loss": 2.3003,
      "step": 7420000
    },
    {
      "epoch": 909.04,
      "learning_rate": 2.7282489593535747e-05,
      "loss": 2.3057,
      "step": 7425000
    },
    {
      "epoch": 909.65,
      "learning_rate": 2.726718903036239e-05,
      "loss": 2.2909,
      "step": 7430000
    },
    {
      "epoch": 910.26,
      "learning_rate": 2.725188846718903e-05,
      "loss": 2.2985,
      "step": 7435000
    },
    {
      "epoch": 910.87,
      "learning_rate": 2.7236594025465235e-05,
      "loss": 2.3005,
      "step": 7440000
    },
    {
      "epoch": 911.48,
      "learning_rate": 2.722129040156709e-05,
      "loss": 2.2891,
      "step": 7445000
    },
    {
      "epoch": 912.1,
      "learning_rate": 2.7205999020568075e-05,
      "loss": 2.3037,
      "step": 7450000
    },
    {
      "epoch": 912.71,
      "learning_rate": 2.7190698457394713e-05,
      "loss": 2.2938,
      "step": 7455000
    },
    {
      "epoch": 913.32,
      "learning_rate": 2.7175400954946135e-05,
      "loss": 2.3004,
      "step": 7460000
    },
    {
      "epoch": 913.93,
      "learning_rate": 2.7160106513222332e-05,
      "loss": 2.307,
      "step": 7465000
    },
    {
      "epoch": 914.54,
      "learning_rate": 2.7144805950048974e-05,
      "loss": 2.2941,
      "step": 7470000
    },
    {
      "epoch": 915.16,
      "learning_rate": 2.712951150832517e-05,
      "loss": 2.3184,
      "step": 7475000
    },
    {
      "epoch": 915.77,
      "learning_rate": 2.7114207884427034e-05,
      "loss": 2.2997,
      "step": 7480000
    },
    {
      "epoch": 916.38,
      "learning_rate": 2.7098910381978455e-05,
      "loss": 2.2925,
      "step": 7485000
    },
    {
      "epoch": 916.99,
      "learning_rate": 2.7083609818805094e-05,
      "loss": 2.3098,
      "step": 7490000
    },
    {
      "epoch": 917.61,
      "learning_rate": 2.706832149853085e-05,
      "loss": 2.2947,
      "step": 7495000
    },
    {
      "epoch": 918.22,
      "learning_rate": 2.7053020935357492e-05,
      "loss": 2.3033,
      "step": 7500000
    },
    {
      "epoch": 918.83,
      "learning_rate": 2.7037723432908914e-05,
      "loss": 2.3009,
      "step": 7505000
    },
    {
      "epoch": 919.44,
      "learning_rate": 2.7022419809010773e-05,
      "loss": 2.2929,
      "step": 7510000
    },
    {
      "epoch": 920.05,
      "learning_rate": 2.7007119245837414e-05,
      "loss": 2.3005,
      "step": 7515000
    },
    {
      "epoch": 920.67,
      "learning_rate": 2.6991818682664056e-05,
      "loss": 2.2834,
      "step": 7520000
    },
    {
      "epoch": 921.28,
      "learning_rate": 2.6976521180215474e-05,
      "loss": 2.293,
      "step": 7525000
    },
    {
      "epoch": 921.89,
      "learning_rate": 2.6961217556317337e-05,
      "loss": 2.2983,
      "step": 7530000
    },
    {
      "epoch": 922.5,
      "learning_rate": 2.694591699314398e-05,
      "loss": 2.2825,
      "step": 7535000
    },
    {
      "epoch": 923.11,
      "learning_rate": 2.6930622551420176e-05,
      "loss": 2.2944,
      "step": 7540000
    },
    {
      "epoch": 923.73,
      "learning_rate": 2.691533423114594e-05,
      "loss": 2.2891,
      "step": 7545000
    },
    {
      "epoch": 924.34,
      "learning_rate": 2.6900030607247802e-05,
      "loss": 2.2904,
      "step": 7550000
    },
    {
      "epoch": 924.95,
      "learning_rate": 2.6884730044074437e-05,
      "loss": 2.2981,
      "step": 7555000
    },
    {
      "epoch": 925.56,
      "learning_rate": 2.686943560235064e-05,
      "loss": 2.2839,
      "step": 7560000
    },
    {
      "epoch": 926.18,
      "learning_rate": 2.685413809990206e-05,
      "loss": 2.297,
      "step": 7565000
    },
    {
      "epoch": 926.79,
      "learning_rate": 2.683884671890304e-05,
      "loss": 2.2891,
      "step": 7570000
    },
    {
      "epoch": 927.4,
      "learning_rate": 2.6823549216454457e-05,
      "loss": 2.2836,
      "step": 7575000
    },
    {
      "epoch": 928.01,
      "learning_rate": 2.68082486532811e-05,
      "loss": 2.2966,
      "step": 7580000
    },
    {
      "epoch": 928.62,
      "learning_rate": 2.6792948090107738e-05,
      "loss": 2.282,
      "step": 7585000
    },
    {
      "epoch": 929.24,
      "learning_rate": 2.677765058765916e-05,
      "loss": 2.2914,
      "step": 7590000
    },
    {
      "epoch": 929.85,
      "learning_rate": 2.676234696376102e-05,
      "loss": 2.2875,
      "step": 7595000
    },
    {
      "epoch": 930.46,
      "learning_rate": 2.674704640058766e-05,
      "loss": 2.2832,
      "step": 7600000
    },
    {
      "epoch": 931.07,
      "learning_rate": 2.673175195886386e-05,
      "loss": 2.2939,
      "step": 7605000
    },
    {
      "epoch": 931.68,
      "learning_rate": 2.67164513956905e-05,
      "loss": 2.2801,
      "step": 7610000
    },
    {
      "epoch": 932.3,
      "learning_rate": 2.67011569539667e-05,
      "loss": 2.2826,
      "step": 7615000
    },
    {
      "epoch": 932.91,
      "learning_rate": 2.668585333006856e-05,
      "loss": 2.2939,
      "step": 7620000
    },
    {
      "epoch": 933.52,
      "learning_rate": 2.667055582761998e-05,
      "loss": 2.2762,
      "step": 7625000
    },
    {
      "epoch": 934.13,
      "learning_rate": 2.6655261385896178e-05,
      "loss": 2.2884,
      "step": 7630000
    },
    {
      "epoch": 934.75,
      "learning_rate": 2.66399638834476e-05,
      "loss": 2.2804,
      "step": 7635000
    },
    {
      "epoch": 935.36,
      "learning_rate": 2.662466332027424e-05,
      "loss": 2.2804,
      "step": 7640000
    },
    {
      "epoch": 935.97,
      "learning_rate": 2.660936581782566e-05,
      "loss": 2.291,
      "step": 7645000
    },
    {
      "epoch": 936.58,
      "learning_rate": 2.6594074436826643e-05,
      "loss": 2.2695,
      "step": 7650000
    },
    {
      "epoch": 937.19,
      "learning_rate": 2.6578776934378065e-05,
      "loss": 2.2872,
      "step": 7655000
    },
    {
      "epoch": 937.81,
      "learning_rate": 2.6563473310479924e-05,
      "loss": 2.2821,
      "step": 7660000
    },
    {
      "epoch": 938.42,
      "learning_rate": 2.6548175808031345e-05,
      "loss": 2.2781,
      "step": 7665000
    },
    {
      "epoch": 939.03,
      "learning_rate": 2.6532875244857987e-05,
      "loss": 2.2862,
      "step": 7670000
    },
    {
      "epoch": 939.64,
      "learning_rate": 2.6517577742409405e-05,
      "loss": 2.2741,
      "step": 7675000
    },
    {
      "epoch": 940.25,
      "learning_rate": 2.6502280239960826e-05,
      "loss": 2.28,
      "step": 7680000
    },
    {
      "epoch": 940.87,
      "learning_rate": 2.6486985798237024e-05,
      "loss": 2.2851,
      "step": 7685000
    },
    {
      "epoch": 941.48,
      "learning_rate": 2.6471685235063666e-05,
      "loss": 2.2704,
      "step": 7690000
    },
    {
      "epoch": 942.09,
      "learning_rate": 2.6456381611165525e-05,
      "loss": 2.2858,
      "step": 7695000
    },
    {
      "epoch": 942.7,
      "learning_rate": 2.6441087169441725e-05,
      "loss": 2.2774,
      "step": 7700000
    },
    {
      "epoch": 948.82,
      "learning_rate": 2.628811520568071e-05,
      "loss": 2.2768,
      "step": 7750000
    },
    {
      "epoch": 954.95,
      "learning_rate": 2.6135140181194905e-05,
      "loss": 2.2781,
      "step": 7800000
    },
    {
      "epoch": 961.07,
      "learning_rate": 2.5982152913809995e-05,
      "loss": 2.2735,
      "step": 7850000
    },
    {
      "epoch": 967.19,
      "learning_rate": 2.582917788932419e-05,
      "loss": 2.2821,
      "step": 7900000
    },
    {
      "epoch": 973.31,
      "learning_rate": 2.5676184500489718e-05,
      "loss": 2.2672,
      "step": 7950000
    },
    {
      "epoch": 979.43,
      "learning_rate": 2.552320335455436e-05,
      "loss": 2.2622,
      "step": 8000000
    },
    {
      "epoch": 985.55,
      "learning_rate": 2.5370213026444662e-05,
      "loss": 2.2601,
      "step": 8050000
    },
    {
      "epoch": 991.67,
      "learning_rate": 2.5217238001958866e-05,
      "loss": 2.255,
      "step": 8100000
    },
    {
      "epoch": 997.8,
      "learning_rate": 2.506426603819785e-05,
      "loss": 2.2529,
      "step": 8150000
    },
    {
      "epoch": 1003.92,
      "learning_rate": 2.491128795298727e-05,
      "loss": 2.4927,
      "step": 8200000
    },
    {
      "epoch": 1010.04,
      "learning_rate": 2.475830680705191e-05,
      "loss": 2.2682,
      "step": 8250000
    },
    {
      "epoch": 1016.16,
      "learning_rate": 2.4605325661116555e-05,
      "loss": 2.251,
      "step": 8300000
    },
    {
      "epoch": 1022.28,
      "learning_rate": 2.4452338393731634e-05,
      "loss": 2.2416,
      "step": 8350000
    },
    {
      "epoch": 1028.4,
      "learning_rate": 2.4299366429970617e-05,
      "loss": 2.2388,
      "step": 8400000
    },
    {
      "epoch": 1034.52,
      "learning_rate": 2.4146382223310483e-05,
      "loss": 2.2387,
      "step": 8450000
    },
    {
      "epoch": 1040.65,
      "learning_rate": 2.3993401077375124e-05,
      "loss": 2.2364,
      "step": 8500000
    },
    {
      "epoch": 1046.77,
      "learning_rate": 2.384041687071499e-05,
      "loss": 2.2304,
      "step": 8550000
    },
    {
      "epoch": 1052.89,
      "learning_rate": 2.368743572477963e-05,
      "loss": 2.2267,
      "step": 8600000
    },
    {
      "epoch": 1059.01,
      "learning_rate": 2.353446070029383e-05,
      "loss": 2.226,
      "step": 8650000
    },
    {
      "epoch": 1065.13,
      "learning_rate": 2.3381473432908916e-05,
      "loss": 2.2199,
      "step": 8700000
    },
    {
      "epoch": 1071.25,
      "learning_rate": 2.3228492286973557e-05,
      "loss": 2.2153,
      "step": 8750000
    },
    {
      "epoch": 1077.38,
      "learning_rate": 2.307550808031342e-05,
      "loss": 2.2126,
      "step": 8800000
    },
    {
      "epoch": 1083.5,
      "learning_rate": 2.29225208129285e-05,
      "loss": 2.205,
      "step": 8850000
    },
    {
      "epoch": 1089.62,
      "learning_rate": 2.2769536606268367e-05,
      "loss": 2.2032,
      "step": 8900000
    },
    {
      "epoch": 1095.74,
      "learning_rate": 2.2616558521057787e-05,
      "loss": 2.2001,
      "step": 8950000
    },
    {
      "epoch": 1101.86,
      "learning_rate": 2.246357737512243e-05,
      "loss": 2.1972,
      "step": 9000000
    },
    {
      "epoch": 1107.98,
      "learning_rate": 2.2310590107737514e-05,
      "loss": 2.1927,
      "step": 9050000
    },
    {
      "epoch": 1114.1,
      "learning_rate": 2.2157612022526935e-05,
      "loss": 2.1912,
      "step": 9100000
    },
    {
      "epoch": 1120.23,
      "learning_rate": 2.200463087659158e-05,
      "loss": 2.1887,
      "step": 9150000
    },
    {
      "epoch": 1126.35,
      "learning_rate": 2.185165585210578e-05,
      "loss": 2.1895,
      "step": 9200000
    },
    {
      "epoch": 1132.47,
      "learning_rate": 2.169867164544564e-05,
      "loss": 2.181,
      "step": 9250000
    },
    {
      "epoch": 1138.59,
      "learning_rate": 2.1545690499510286e-05,
      "loss": 2.1769,
      "step": 9300000
    },
    {
      "epoch": 1144.71,
      "learning_rate": 2.1392724657198825e-05,
      "loss": 2.1754,
      "step": 9350000
    },
    {
      "epoch": 1150.83,
      "learning_rate": 2.1239734329089128e-05,
      "loss": 2.1716,
      "step": 9400000
    },
    {
      "epoch": 1156.95,
      "learning_rate": 2.108675930460333e-05,
      "loss": 2.1675,
      "step": 9450000
    },
    {
      "epoch": 1163.08,
      "learning_rate": 2.0933781219392752e-05,
      "loss": 2.1628,
      "step": 9500000
    },
    {
      "epoch": 1169.2,
      "learning_rate": 2.0780800073457397e-05,
      "loss": 2.1598,
      "step": 9550000
    },
    {
      "epoch": 1175.32,
      "learning_rate": 2.0627818927522038e-05,
      "loss": 2.1574,
      "step": 9600000
    },
    {
      "epoch": 1181.44,
      "learning_rate": 2.0474831660137124e-05,
      "loss": 2.1559,
      "step": 9650000
    },
    {
      "epoch": 1187.56,
      "learning_rate": 2.0321847453476982e-05,
      "loss": 2.1514,
      "step": 9700000
    },
    {
      "epoch": 1193.68,
      "learning_rate": 2.0168863246816847e-05,
      "loss": 2.1485,
      "step": 9750000
    },
    {
      "epoch": 1199.8,
      "learning_rate": 2.0015885161606268e-05,
      "loss": 2.1454,
      "step": 9800000
    },
    {
      "epoch": 1205.93,
      "learning_rate": 1.986290401567091e-05,
      "loss": 2.1429,
      "step": 9850000
    },
    {
      "epoch": 1212.05,
      "learning_rate": 1.9709922869735554e-05,
      "loss": 2.1391,
      "step": 9900000
    },
    {
      "epoch": 1218.17,
      "learning_rate": 1.9556941723800195e-05,
      "loss": 2.1356,
      "step": 9950000
    },
    {
      "epoch": 1224.29,
      "learning_rate": 1.940395751714006e-05,
      "loss": 2.1343,
      "step": 10000000
    },
    {
      "epoch": 1230.41,
      "learning_rate": 1.9250970249755143e-05,
      "loss": 2.1311,
      "step": 10050000
    },
    {
      "epoch": 1236.53,
      "learning_rate": 1.9097986043095008e-05,
      "loss": 2.1277,
      "step": 10100000
    },
    {
      "epoch": 1242.65,
      "learning_rate": 1.894500795788443e-05,
      "loss": 2.1255,
      "step": 10150000
    },
    {
      "epoch": 1248.78,
      "learning_rate": 1.879202069049951e-05,
      "loss": 2.1225,
      "step": 10200000
    },
    {
      "epoch": 1254.9,
      "learning_rate": 1.8639039544564155e-05,
      "loss": 2.1202,
      "step": 10250000
    },
    {
      "epoch": 1261.02,
      "learning_rate": 1.8486064520078356e-05,
      "loss": 2.1173,
      "step": 10300000
    },
    {
      "epoch": 1267.14,
      "learning_rate": 1.8333080313418217e-05,
      "loss": 2.1145,
      "step": 10350000
    },
    {
      "epoch": 1273.26,
      "learning_rate": 1.8180096106758082e-05,
      "loss": 2.1112,
      "step": 10400000
    },
    {
      "epoch": 1279.38,
      "learning_rate": 1.8027127203721842e-05,
      "loss": 2.1307,
      "step": 10450000
    },
    {
      "epoch": 1285.5,
      "learning_rate": 1.7874149118511263e-05,
      "loss": 2.1295,
      "step": 10500000
    },
    {
      "epoch": 1291.63,
      "learning_rate": 1.7721161851126348e-05,
      "loss": 2.167,
      "step": 10550000
    }
  ],
  "max_steps": 16336000,
  "num_train_epochs": 2000,
  "total_flos": 1.8569047592292696e+19,
  "trial_name": null,
  "trial_params": null
}
