{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12e46f-23c8-4181-9e24-a0276dc12dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy==1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da4c2c-e801-4fa6-8676-c04e551ee88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.12\n",
    "!pip install pyarabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b7f2d-e4a6-4dc1-9a9f-eb0d99dc95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd9b83-c345-489a-ba9d-c27dc601972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c51d229-d74c-4ce9-9910-786a65f81dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd46459-397c-4680-aa71-61f421963385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 20:09:20.906226: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 20:09:21.346551: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 20:09:21.890890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2090907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# cell-1  \n",
    "#load and clean the data (removing diacritics and unwanted text)\n",
    "\n",
    "df = pd.read_csv('AraPoems_Dataset.csv')\n",
    "df.fillna('', inplace=True)\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "def remove_diacritics(a):    \n",
    "    return araby.strip_diacritics(a)\n",
    "\n",
    "df['first_hemistich'] = df['first_hemistich'].apply(remove_diacritics)\n",
    "df['second_hemistich'] = df['second_hemistich'].apply(remove_diacritics)\n",
    "\n",
    "def normalizeBeforeTraining(df):\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('النابغـة: ', '')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('الـربيع: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('عبيــد: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('امـرؤ القيسـ: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('امرؤ القيس: ', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(جلال الــــدين الــــرومي):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(لـوك الفيلسـوف الإنكليزي):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(كانت الفيلسوف الألماني ):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(بركســــــــــــــــون):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الحـــــــــــــــور):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الشــــــــــــــاعر):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الإنســـــــــــــــان):', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('العلم):', '', regex=False)\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(العشــــــــــــــــق):', '', regex=False)\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('(الزهــــــــــــــــــرة):', '', regex=False)\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('التوأم اليشكري: ', '', regex=False)  \n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('آ', 'أ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('آ', 'أ')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('[/\":?،؟]', '')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('[/\":?،؟]', '')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('  ', ' ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('  ', ' ')\n",
    "    df['first_hemistich'] = df['first_hemistich'].str.replace('  ', ' ')\n",
    "    df['second_hemistich'] = df['second_hemistich'].str.replace('  ', ' ')\n",
    "\n",
    "\n",
    "normalizeBeforeTraining(df)\n",
    "df.drop(df[(df['first_hemistich'] == '') & (df['second_hemistich'] == '')].index, inplace=True)\n",
    "\n",
    "#if first_hemistich == '', then copy the text from second_hemistich. then delete the text in the second_hemistich\n",
    "df['first_hemistich'] = df.apply(lambda x: x['second_hemistich'] if x['first_hemistich'] == '' else x['first_hemistich'], axis=1)\n",
    "df['second_hemistich'] = df.apply(lambda x: '' if x['first_hemistich'] == x['second_hemistich'] else x['second_hemistich'], axis=1)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(len(df))\n",
    "# display(df[:10])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e68754b-15f2-4e08-b38a-ea0ccd974d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1911853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1529482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "382371"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell-2 \n",
    "# preparing data for finetuning\n",
    "\n",
    "\n",
    "df['second_hemistich'].replace('', 'E', inplace=True)\n",
    "dfc = df[['first_hemistich', 'second_hemistich', 'meter', 'link']].copy()\n",
    "dfc['text'] = dfc['first_hemistich'] + ' S ' + dfc['second_hemistich']\n",
    "\n",
    "#removing verses without a meter\n",
    "dfc = dfc[dfc['meter'] != ''] \n",
    "dfc = dfc[dfc['meter'] != 'unspecified']\n",
    "dfc = dfc[dfc['meter'] != 'mixed']\n",
    "\n",
    "\n",
    "\n",
    "classic = ['taweel', 'kamel', 'baseet', 'khafif', 'wafer', 'rajaz', 'ramel', 'mutaqarib',\n",
    "           'saree', 'munsarih', 'mujtath', 'hazaj', 'madeed', 'mutadarak', 'muqtadab', 'mudari'] \n",
    "\n",
    "#including only verses with classical meters\n",
    "# dfc = dfc[dfc['meter'].isin(classic)]\n",
    "\n",
    "dfc.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfc['meter'] = dfc['meter'].astype('category')\n",
    "# display(dfc['meter'].unique())\n",
    "\n",
    "dfc['label'] = dfc['meter'].cat.codes #assign cat_value for each meter type\n",
    "dftrain, dftest = train_test_split(dfc, test_size=0.20, random_state=42, stratify=dfc['label'])\n",
    "ytrain = to_categorical(dftrain['label']).astype('int32')\n",
    "ytest = to_categorical(dftest['label']).astype('int32')\n",
    "\n",
    "max_sequence_length = 32\n",
    "train_batch_size = 256\n",
    "classes_num = len(dfc['meter'].unique())\n",
    "\n",
    "display(len(dfc))\n",
    "display(len(dftrain))\n",
    "display(len(dftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdae2e7c-370e-407c-a87a-2e61f782f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 20:10:01.400625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:01.520974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:01.521161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:01.523083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:01.523240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:01.523360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:02.551604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:02.551734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:02.551824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 20:10:02.551898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21654 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-09-14 20:10:03.502125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#cell-3\n",
    "#loading the tokenizer and the model\n",
    "\n",
    "from transformers import AutoTokenizer,TFBertModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('UBC-NLP/ARBERT')\n",
    "bert = TFBertModel.from_pretrained('UBC-NLP/ARBERT', from_pt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd261fd0-0b55-46b6-8f5a-67f213baeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell-4\n",
    "#tokenizing the data\n",
    "\n",
    "xtrain = tokenizer(\n",
    "    text=dftrain['text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_sequence_length,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "xtest = tokenizer(\n",
    "    text=dftest['text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_sequence_length,\n",
    "    truncation=True,\n",
    "    padding='max_length', \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8e3243-381f-4745-8b60-4f96974f7336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       "array([    2,  2914,   277,   151,  2890,  1110,    83, 31553,  8365,\n",
       "           9, 25033,   122,    85,  4147,  5444,   678,   321, 40125,\n",
       "           3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0], dtype=int32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(xtest)\n",
    "display(xtest['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac648a8-7bf9-40b6-bc13-9f2aeaddf783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  162841344   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 32,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 28)           21532       ['tf_bert_model[0][1]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 162,862,876\n",
      "Trainable params: 162,862,876\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#cell-5\n",
    "# building classifier model\n",
    "\n",
    "input_ids = Input(shape=(max_sequence_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_sequence_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "output = bert([input_ids, input_mask])[1] #pooled_output\n",
    "output = tf.keras.layers.Dense(classes_num, activation='softmax', name='output')(output)\n",
    "   \n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=output)\n",
    "\n",
    "optimizer = Adam(learning_rate=5e-05)\n",
    "\n",
    "\n",
    "loss =CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy('balanced_accuracy'),\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c8469d-06ca-4f95-8dfc-8d72bc656a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_990955/403206910.py:1: experimental_run_functions_eagerly (from tensorflow.python.eager.polymorphic_function.quarantine) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a65491c-3faf-48ce-9e1a-750781892ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "5975/5975 [==============================] - 1911s 320ms/step - loss: 0.3424 - balanced_accuracy: 0.8956 - val_loss: 0.1627 - val_balanced_accuracy: 0.9556\n",
      "Epoch 2/6\n",
      "5975/5975 [==============================] - 1912s 320ms/step - loss: 0.1406 - balanced_accuracy: 0.9612 - val_loss: 0.1360 - val_balanced_accuracy: 0.9630\n",
      "Epoch 3/6\n",
      "5975/5975 [==============================] - 1914s 320ms/step - loss: 0.1074 - balanced_accuracy: 0.9708 - val_loss: 0.1326 - val_balanced_accuracy: 0.9642\n",
      "Epoch 4/6\n",
      "5975/5975 [==============================] - 1934s 324ms/step - loss: 0.0867 - balanced_accuracy: 0.9768 - val_loss: 0.1305 - val_balanced_accuracy: 0.9659\n",
      "Epoch 5/6\n",
      "5975/5975 [==============================] - 1964s 329ms/step - loss: 0.0710 - balanced_accuracy: 0.9815 - val_loss: 0.1438 - val_balanced_accuracy: 0.9651\n",
      "Epoch 6/6\n",
      "5975/5975 [==============================] - 1975s 331ms/step - loss: 0.0594 - balanced_accuracy: 0.9847 - val_loss: 0.1553 - val_balanced_accuracy: 0.9634\n"
     ]
    }
   ],
   "source": [
    "#train the model (all meters)\n",
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':xtrain['input_ids'],'attention_mask':xtrain['attention_mask']}, y = ytrain,\n",
    "    validation_data = ({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']}, \n",
    "    ytest), epochs=6, batch_size=train_batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c3f32b-4936-4324-b48b-a7f4eb0f03f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11950/11950 [==============================] - 670s 56ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9843    0.9907    0.9875     53009\n",
      "           1     0.7030    0.5311    0.6051      1480\n",
      "           2     0.8790    0.8790    0.8790       587\n",
      "           3     0.8552    0.7183    0.7808      1686\n",
      "           4     1.0000    0.1000    0.1818        10\n",
      "           5     0.8020    0.8331    0.8172      1833\n",
      "           6     0.9813    0.9750    0.9781     81382\n",
      "           7     0.0000    0.0000    0.0000        12\n",
      "           8     0.9740    0.9864    0.9802     34821\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "          10     0.8093    0.8946    0.8498      1755\n",
      "          11     0.7465    0.2062    0.3232       257\n",
      "          12     0.5789    0.3793    0.4583       377\n",
      "          13     0.7643    0.5436    0.6353      7682\n",
      "          14     0.4286    0.2917    0.3471        72\n",
      "          15     0.8655    0.9525    0.9069      3871\n",
      "          16     0.9415    0.9620    0.9516      5973\n",
      "          17     0.8788    0.7632    0.8169       190\n",
      "          18     0.7326    0.8741    0.7971      1326\n",
      "          19     0.9731    0.9745    0.9738     13905\n",
      "          20     0.8798    0.9364    0.9072     22267\n",
      "          21     0.9247    0.9489    0.9366     17971\n",
      "          22     0.0000    0.0000    0.0000         3\n",
      "          23     0.9350    0.9585    0.9466     12252\n",
      "          24     0.5685    0.4392    0.4955       189\n",
      "          25     0.9943    0.9910    0.9927     88553\n",
      "          26     0.9815    0.9836    0.9826     30891\n",
      "          27     0.0000    0.0000    0.0000        16\n",
      "\n",
      "   micro avg     0.9634    0.9634    0.9634    382371\n",
      "   macro avg     0.7208    0.6469    0.6618    382371\n",
      "weighted avg     0.9623    0.9634    0.9621    382371\n",
      " samples avg     0.9634    0.9634    0.9634    382371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation (all meters)\n",
    "\n",
    "pred = model.predict({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']})\n",
    "\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "y_pred = to_categorical(y_pred, num_classes=classes_num).astype('int32')\n",
    "\n",
    "print(classification_report(ytest, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9fd3a-da11-415d-9f69-27e33f7dce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fa1f45-ca47-499a-be0c-80a552c0539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "5783/5783 [==============================] - 1861s 322ms/step - loss: 0.2653 - balanced_accuracy: 0.9154 - val_loss: 0.1084 - val_balanced_accuracy: 0.9701\n",
      "Epoch 2/6\n",
      "5783/5783 [==============================] - 1883s 326ms/step - loss: 0.0891 - balanced_accuracy: 0.9755 - val_loss: 0.0820 - val_balanced_accuracy: 0.9787\n",
      "Epoch 3/6\n",
      "5783/5783 [==============================] - 1884s 326ms/step - loss: 0.0669 - balanced_accuracy: 0.9826 - val_loss: 0.0840 - val_balanced_accuracy: 0.9783\n",
      "Epoch 4/6\n",
      "5783/5783 [==============================] - 1897s 328ms/step - loss: 0.0551 - balanced_accuracy: 0.9864 - val_loss: 0.0783 - val_balanced_accuracy: 0.9804\n",
      "Epoch 5/6\n",
      "5783/5783 [==============================] - 1905s 329ms/step - loss: 0.0472 - balanced_accuracy: 0.9886 - val_loss: 0.0806 - val_balanced_accuracy: 0.9803\n",
      "Epoch 6/6\n",
      "5783/5783 [==============================] - 1904s 329ms/step - loss: 0.0410 - balanced_accuracy: 0.9904 - val_loss: 0.0825 - val_balanced_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "#train the model (classical meters)\n",
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':xtrain['input_ids'],'attention_mask':xtrain['attention_mask']}, y = ytrain,\n",
    "    validation_data = ({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']}, \n",
    "    ytest), epochs=6, batch_size=train_batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150ba65a-e966-4b63-b3ec-e8f04bb33de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11565/11565 [==============================] - 615s 53ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9903    0.9918    0.9911     53009\n",
      "           1     0.8393    0.8603    0.8497      1833\n",
      "           2     0.9826    0.9837    0.9832     81382\n",
      "           3     0.9868    0.9862    0.9865     34821\n",
      "           4     0.9395    0.8496    0.8923      1755\n",
      "           5     0.7391    0.2361    0.3579        72\n",
      "           6     0.9563    0.9380    0.9471      3871\n",
      "           7     0.9287    0.9675    0.9477      5973\n",
      "           8     0.8596    0.8053    0.8315       190\n",
      "           9     0.8705    0.8824    0.8764      1326\n",
      "          10     0.9759    0.9816    0.9787     13905\n",
      "          11     0.9429    0.9210    0.9318     22267\n",
      "          12     0.9624    0.9768    0.9696     17971\n",
      "          13     0.9596    0.9533    0.9564     12252\n",
      "          14     0.9937    0.9953    0.9945     88553\n",
      "          15     0.9875    0.9859    0.9867     30891\n",
      "\n",
      "   micro avg     0.9803    0.9803    0.9803    370071\n",
      "   macro avg     0.9322    0.8947    0.9051    370071\n",
      "weighted avg     0.9802    0.9803    0.9802    370071\n",
      " samples avg     0.9803    0.9803    0.9803    370071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation (classical meters)\n",
    "\n",
    "pred = model.predict({'input_ids':xtest['input_ids'],'attention_mask':xtest['attention_mask']})\n",
    "\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "y_pred = to_categorical(y_pred, num_classes=classes_num).astype('int32')\n",
    "\n",
    "print(classification_report(ytest, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4547a78-e197-4212-8211-700f28a017c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b334a-63ed-4bf2-a31c-7b78073be5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea7339e2-eb16-4e53-b7e8-d61654aa18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# classifier_path = 'finetuned/classic_meters_classifierTF_arbert.h5'\n",
    "classifier_path = 'finetuned/all_meters_classifierTF_arbert.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5185399-536e-4687-aa72-093cdcc76c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving finetuned model locally\n",
    "\n",
    "model.save_weights(classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7cc85-d431-483b-9ceb-f0eb0c12f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a11ab3-0772-4547-aac4-14b9753f9864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
